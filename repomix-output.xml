This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.gitmodules
build.gradle.kts
core/build.gradle.kts
core/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/core/extensions/LineExtensions.kt
core/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/core/models/Author.kt
core/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/core/models/Book.kt
core/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/core/models/Category.kt
core/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/core/models/Line.kt
core/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/core/models/LineTocMapping.kt
core/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/core/models/Link.kt
core/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/core/models/Metadata.kt
core/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/core/models/PubDate.kt
core/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/core/models/PubPlace.kt
core/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/core/models/SearchResult.kt
core/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/core/models/Source.kt
core/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/core/models/TocEntry.kt
core/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/core/models/TocText.kt
core/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/core/models/Topic.kt
dao/build.gradle.kts
dao/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/dao/extensions/ModelExtensions.kt
dao/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/dao/repository/SeforimRepository.kt
dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/AcronymQueries.sq
dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/AuthorQueries.sq
dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/BookHasLinksQueries.sq
dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/BookQueries.sq
dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/CategoryClosureQueries.sq
dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/CategoryQueries.sq
dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/ConnectionTypeQueries.sq
dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/Database.sq
dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/LineQueries.sq
dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/LineTocQueries.sq
dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/LinkQueries.sq
dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/PubDateQueries.sq
dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/PubPlaceQueries.sq
dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/SourceQueries.sq
dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/TocQueries.sq
dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/TocTextQueries.sq
dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/TopicQueries.sq
generator/build.gradle.kts
generator/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/generator/Generator.kt
generator/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/generator/lucene/LookupIndexWriter.kt
generator/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/generator/lucene/TextIndexWriter.kt
generator/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/generator/utils/HebrewTextUtils.kt
generator/src/commonMain/resources/otzaria-folder-to-remove.txt
generator/src/commonMain/resources/priority.txt
generator/src/commonMain/resources/source-blacklist.txt
generator/src/jvmMain/kotlin/io/github/kdroidfilter/seforimlibrary/generator/AcronymizerFetcher.kt
generator/src/jvmMain/kotlin/io/github/kdroidfilter/seforimlibrary/generator/BuildFromScratch.kt
generator/src/jvmMain/kotlin/io/github/kdroidfilter/seforimlibrary/generator/BuildLuceneIndex.kt
generator/src/jvmMain/kotlin/io/github/kdroidfilter/seforimlibrary/generator/DownloadAcronymizer.kt
generator/src/jvmMain/kotlin/io/github/kdroidfilter/seforimlibrary/generator/DownloadOtzaria.kt
generator/src/jvmMain/kotlin/io/github/kdroidfilter/seforimlibrary/generator/GenerateLines.kt
generator/src/jvmMain/kotlin/io/github/kdroidfilter/seforimlibrary/generator/GenerateLinks.kt
generator/src/jvmMain/kotlin/io/github/kdroidfilter/seforimlibrary/generator/lucene/LuceneLookupIndexWriter.kt
generator/src/jvmMain/kotlin/io/github/kdroidfilter/seforimlibrary/generator/lucene/LuceneTextIndexWriter.kt
generator/src/jvmMain/kotlin/io/github/kdroidfilter/seforimlibrary/generator/OtzariaFetcher.kt
generator/src/jvmMain/kotlin/io/github/kdroidfilter/seforimlibrary/generator/PackageArtifacts.kt
gradle.properties
gradle/libs.versions.toml
gradle/wrapper/gradle-wrapper.jar
gradle/wrapper/gradle-wrapper.properties
gradlew
gradlew.bat
README.MD
sample/composeApp/build.gradle.kts
sample/composeApp/src/androidMain/AndroidManifest.xml
sample/composeApp/src/androidMain/kotlin/sample/app/DatabaseUtils.kt
sample/composeApp/src/androidMain/kotlin/sample/app/main.kt
sample/composeApp/src/commonMain/composeResources/font/noto.ttf
sample/composeApp/src/commonMain/kotlin/sample/app/App.kt
sample/composeApp/src/commonMain/kotlin/sample/app/BookContentView.kt
sample/composeApp/src/commonMain/kotlin/sample/app/BookPopup.kt
sample/composeApp/src/commonMain/kotlin/sample/app/CategoryBookTree.kt
sample/composeApp/src/commonMain/kotlin/sample/app/LineCommentsView.kt
sample/composeApp/src/commonMain/kotlin/sample/app/LineWithUniqueKey.kt
sample/composeApp/src/commonMain/kotlin/sample/app/SearchPopup.kt
sample/composeApp/src/commonMain/kotlin/sample/app/Theme.kt
sample/composeApp/src/commonMain/kotlin/sample/app/Type.kt
sample/composeApp/src/jvmMain/kotlin/sample/app/DatabaseUtils.kt
sample/composeApp/src/jvmMain/kotlin/sample/app/main.kt
settings.gradle.kts
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".gitmodules">
[submodule "HebMorph"]
	path = HebMorph
	url = https://github.com/kdroidFilter/HebMorph.git
</file>

<file path="build.gradle.kts">
plugins {
    alias(libs.plugins.multiplatform).apply(false)
    alias(libs.plugins.android.library).apply(false)
    alias(libs.plugins.maven.publish).apply(false)
    alias(libs.plugins.kotlinx.serialization).apply(false)
    alias(libs.plugins.sqlDelight).apply(false)
    alias(libs.plugins.android.application).apply(false)
}
</file>

<file path="core/build.gradle.kts">
plugins {
    alias(libs.plugins.multiplatform)
    alias(libs.plugins.android.library)
    alias(libs.plugins.maven.publish)
    alias(libs.plugins.kotlinx.serialization)
}

group = "io.github.kdroidfilter.seforimlibrary"

kotlin {
    jvmToolchain(21)

    androidTarget { publishLibraryVariants("release") }
    jvm()

    sourceSets {
        commonMain.dependencies {
            implementation(libs.kotlinx.serialization.json)
        }

        commonTest.dependencies {
            implementation(kotlin("test"))
        }

        androidMain.dependencies {

        }

        jvmMain.dependencies {

        }

    }

}

android {
    namespace = "io.github.kdroidfilter.seforimlibrary"
    compileSdk = 35

    defaultConfig {
        minSdk = 21
    }
}

//Publishing your Kotlin Multiplatform library to Maven Central
//https://www.jetbrains.com/help/kotlin-multiplatform-dev/multiplatform-publish-libraries.html
mavenPublishing {
    publishToMavenCentral()
    coordinates("io.github.kdroidfilter.seforimlibrary", "core", "1.0.0")

    pom {
        name = "SeforimLibrary"
        description = "Kotlin Multiplatform library"
        url = "github url" //todo

        licenses {
            license {
                name = "MIT"
                url = "https://opensource.org/licenses/MIT"
            }
        }

        developers {
            developer {
                id = "" //todo
                name = "" //todo
                email = "" //todo
            }
        }

        scm {
            url = "github url" //todo
        }
    }
    if (project.hasProperty("signing.keyId")) signAllPublications()
}
</file>

<file path="core/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/core/extensions/LineExtensions.kt">
package io.github.kdroidfilter.seforimlibrary.core.extensions

import io.github.kdroidfilter.seforimlibrary.core.models.Line
import io.github.kdroidfilter.seforimlibrary.core.models.LineTocMapping

/**
 * Extensions to facilitate the transition to the new structure without tocEntryId
 */

/**
 * Retrieves the first TOC entry associated with this line
 * (to be used with a list of LineTocMapping)
 *
 * @param mappings The list of line-to-TOC mappings to search in
 * @return The ID of the first TOC entry associated with this line, or null if none found
 */
fun Line.findTocEntryId(mappings: List<LineTocMapping>): Long? {
    return mappings.firstOrNull { it.lineId == this.id }?.tocEntryId
}

/**
 * Checks if this line has an associated TOC entry
 *
 * @param mappings The list of line-to-TOC mappings to search in
 * @return True if this line has an associated TOC entry, false otherwise
 */
fun Line.hasTocEntry(mappings: List<LineTocMapping>): Boolean {
    return mappings.any { it.lineId == this.id }
}
</file>

<file path="core/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/core/models/Author.kt">
package io.github.kdroidfilter.seforimlibrary.core.models

import kotlinx.serialization.Serializable

/**
 * Represents a book author in the library
 *
 * @property id The unique identifier of the author
 * @property name The name of the author
 */
@Serializable
data class Author(
    val id: Long = 0,
    val name: String
)
</file>

<file path="core/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/core/models/Book.kt">
package io.github.kdroidfilter.seforimlibrary.core.models

import kotlinx.serialization.Serializable

/**
 * Represents a book in the library
 *
 * @property id The unique identifier of the book
 * @property categoryId The identifier of the category this book belongs to
 * @property title The title of the book
 * @property sourceId The identifier of the source this book originates from
 * @property authors The list of authors of this book
 * @property topics The list of topics associated with this book
 * @property pubPlaces The list of publication places for this book
 * @property pubDates The list of publication dates for this book
 * @property heShortDesc A short description of the book in Hebrew
 * @property order The display order of the book within its category
 * @property totalLines The total number of lines in the book
 */
@Serializable
data class Book(
    val id: Long = 0,
    val categoryId: Long,
    val sourceId: Long,
    val title: String,
    val authors: List<Author> = emptyList(),
    val topics: List<Topic> = emptyList(),
    val pubPlaces: List<PubPlace> = emptyList(),
    val pubDates: List<PubDate> = emptyList(),
    val heShortDesc: String? = null,
    // Optional notes content: when a companion file named "◊î◊¢◊®◊ï◊™ ◊¢◊ú <title>" exists,
    // its content is attached here instead of being inserted as a separate book.
    val notesContent: String? = null,
    val order: Float = 999f,
    val totalLines: Int = 0,
    val isBaseBook: Boolean = false,
    val hasTargumConnection: Boolean = false,
    val hasReferenceConnection: Boolean = false,
    val hasCommentaryConnection: Boolean = false,
    val hasOtherConnection: Boolean = false,
)
</file>

<file path="core/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/core/models/Category.kt">
package io.github.kdroidfilter.seforimlibrary.core.models

import kotlinx.serialization.Serializable

/**
 * Represents a category in the library hierarchy
 *
 * @property id The unique identifier of the category
 * @property parentId The identifier of the parent category, or null if this is a root category
 * @property title The title of the category
 * @property level The level of the category in the hierarchy (0 for root categories)
 */
@Serializable
data class Category(
    val id: Long = 0,
    val parentId: Long? = null,
    val title: String,
    val level: Int = 0
)
</file>

<file path="core/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/core/models/Line.kt">
package io.github.kdroidfilter.seforimlibrary.core.models

import kotlinx.serialization.Serializable

/**
 * Represents an individual line of a book
 *
 * @property id The unique identifier of the line
 * @property bookId The identifier of the book this line belongs to
 * @property lineIndex The index of the line within the book
 * @property content The original HTML content of the line
 */
@Serializable
data class Line(
    val id: Long = 0,
    val bookId: Long,
    val lineIndex: Int,
    val content: String
)
</file>

<file path="core/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/core/models/LineTocMapping.kt">
package io.github.kdroidfilter.seforimlibrary.core.models

import kotlinx.serialization.Serializable

/**
 * Mapping between lines and table of contents entries
 *
 * @property lineId The identifier of the line
 * @property tocEntryId The identifier of the table of contents entry
 */
@Serializable
data class LineTocMapping(
    val lineId: Long,
    val tocEntryId: Long
)
</file>

<file path="core/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/core/models/Link.kt">
package io.github.kdroidfilter.seforimlibrary.core.models

import kotlinx.serialization.Serializable

/**
 * Link between two texts (commentary, reference, etc.)
 *
 * @property id The unique identifier of the link
 * @property sourceBookId The identifier of the source book
 * @property targetBookId The identifier of the target book
 * @property sourceLineId The identifier of the source line
 * @property targetLineId The identifier of the target line
 * @property connectionType The type of connection between the texts
 */
@Serializable
data class Link(
    val id: Long = 0,
    val sourceBookId: Long,
    val targetBookId: Long,
    val sourceLineId: Long,
    val targetLineId: Long,
    val connectionType: ConnectionType
)

/**
 * Types of connections between texts
 *
 * @property COMMENTARY A commentary on the source text
 * @property TARGUM A translation of the source text
 * @property REFERENCE A reference to the source text
 * @property OTHER Any other type of connection
 */
@Serializable
enum class ConnectionType {
    COMMENTARY, TARGUM, REFERENCE, OTHER;

    companion object {
        /**
         * Creates a ConnectionType from a string value
         *
         * @param value The string representation of the connection type
         * @return The corresponding ConnectionType, or OTHER if not recognized
         */
        fun fromString(value: String): ConnectionType = when (value.lowercase()) {
            "commentary" -> COMMENTARY
            "targum" -> TARGUM
            "reference" -> REFERENCE
            else -> OTHER
        }
    }
}
</file>

<file path="core/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/core/models/Metadata.kt">
package io.github.kdroidfilter.seforimlibrary.core.models

import kotlinx.serialization.Serializable

/**
 * Book metadata from the JSON file
 *
 * @property title The title of the book
 * @property description The full description of the book
 * @property shortDescription A short description of the book
 * @property author The author of the book
 * @property extraTitles Alternative titles for the book
 * @property heShortDesc A short description in Hebrew
 * @property pubDate The publication date of the book
 * @property pubPlace The publication place of the book
 * @property order The display order of the book within its category
 */
@Serializable
data class BookMetadata(
    val title: String,
    val description: String? = null,
    val shortDescription: String? = null,
    val author: String? = null,
    val extraTitles: List<String>? = null,
    val heShortDesc: String? = null,
    val pubDate: String? = null,
    val pubPlace: String? = null,
    val order: Float? = null
)
</file>

<file path="core/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/core/models/PubDate.kt">
package io.github.kdroidfilter.seforimlibrary.core.models

import kotlinx.serialization.Serializable

/**
 * Represents a publication date
 *
 * @property id The unique identifier of the publication date
 * @property date The publication date as a string
 */
@Serializable
data class PubDate(
    val id: Long = 0,
    val date: String
)
</file>

<file path="core/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/core/models/PubPlace.kt">
package io.github.kdroidfilter.seforimlibrary.core.models

import kotlinx.serialization.Serializable

/**
 * Represents a publication place
 *
 * @property id The unique identifier of the publication place
 * @property name The name of the publication place
 */
@Serializable
data class PubPlace(
    val id: Long = 0,
    val name: String
)
</file>

<file path="core/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/core/models/SearchResult.kt">
package io.github.kdroidfilter.seforimlibrary.core.models

import kotlinx.serialization.Serializable

/**
 * Search result
 *
 * @property bookId The identifier of the book containing the result
 * @property bookTitle The title of the book containing the result
 * @property lineId The identifier of the line containing the result
 * @property lineIndex The index of the line containing the result
 * @property snippet The text excerpt with highlighting
 * @property rank The relevance score of the result
 */
@Serializable
data class SearchResult(
    val bookId: Long,
    val bookTitle: String,
    val lineId: Long,
    val lineIndex: Int,
    val snippet: String,
    val rank: Double
)
</file>

<file path="core/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/core/models/Source.kt">
package io.github.kdroidfilter.seforimlibrary.core.models

import kotlinx.serialization.Serializable

/**
 * Represents a content source/provider entry.
 */
@Serializable
data class Source(
    val id: Long = 0,
    val name: String
)
</file>

<file path="core/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/core/models/TocEntry.kt">
package io.github.kdroidfilter.seforimlibrary.core.models

import kotlinx.serialization.Serializable

/**
 * Table of contents entry
 *
 * @property id The unique identifier of the TOC entry
 * @property bookId The identifier of the book this TOC entry belongs to
 * @property parentId The identifier of the parent TOC entry, or null if this is a root entry
 * @property textId The identifier of the associated text in the tocText table
 * @property text The text of the TOC entry (for compatibility with existing code)
 * @property level The level of the TOC entry in the hierarchy
 * @property lineId The identifier of the associated line, or null if not linked to a specific line
 * @property isLastChild Indicates if this TOC entry is the last child of its parent
 */
@Serializable
data class TocEntry(
    val id: Long = 0,
    val bookId: Long,
    val parentId: Long? = null,
    val textId: Long? = null,
    val text: String = "",
    val level: Int,
    val lineId: Long? = null,
    val isLastChild: Boolean = false,
    val hasChildren: Boolean = false
)
</file>

<file path="core/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/core/models/TocText.kt">
package io.github.kdroidfilter.seforimlibrary.core.models

import kotlinx.serialization.Serializable

/**
 * Represents a text used in table of contents entries
 *
 * @property id The unique identifier of the TOC text
 * @property text The content of the TOC text
 */
@Serializable
data class TocText(
    val id: Long = 0,
    val text: String
)
</file>

<file path="core/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/core/models/Topic.kt">
package io.github.kdroidfilter.seforimlibrary.core.models

import kotlinx.serialization.Serializable

/**
 * Represents a topic (keyword) associated with books in the library
 *
 * @property id The unique identifier of the topic
 * @property name The name of the topic
 */
@Serializable
data class Topic(
    val id: Long = 0,
    val name: String
)
</file>

<file path="dao/build.gradle.kts">
plugins {
    alias(libs.plugins.multiplatform)
    alias(libs.plugins.android.library)
    alias(libs.plugins.maven.publish)
    alias(libs.plugins.kotlinx.serialization)
    alias(libs.plugins.sqlDelight)
}

group = "io.github.kdroidfilter.seforimlibrary"


kotlin {
    jvmToolchain(21)

    androidTarget { publishLibraryVariants("release") }
    jvm()

    sourceSets {
        commonMain.dependencies {
            api(project(":core"))
            implementation(libs.kotlinx.coroutines.core)
            implementation(libs.kotlinx.coroutines.test)
            implementation(libs.kotlinx.serialization.json)
            implementation(libs.kotlinx.datetime)
            implementation(libs.kermit)
        }

        commonTest.dependencies {
            implementation(kotlin("test"))
        }

        androidMain.dependencies {
            implementation(libs.kotlinx.coroutines.android)
            implementation(libs.sqlDelight.driver.android)
        }

        jvmMain.dependencies {
            implementation(libs.kotlinx.coroutines.swing)
            implementation(libs.sqlDelight.driver.sqlite)
        }

    }

}

android {
    namespace = "io.github.kdroidfilter.seforimlibrary"
    compileSdk = 35

    defaultConfig {
        minSdk = 21
    }
}


//Publishing your Kotlin Multiplatform library to Maven Central
//https://www.jetbrains.com/help/kotlin-multiplatform-dev/multiplatform-publish-libraries.html
mavenPublishing {
    publishToMavenCentral()
    coordinates("io.github.kdroidfilter.seforimlibrary", "dao", "1.0.0")

    pom {
        name = "SeforimLibraryDao"
        description = "Kotlin Multiplatform library"
        url = "github url" //todo

        licenses {
            license {
                name = "MIT"
                url = "https://opensource.org/licenses/MIT"
            }
        }

        developers {
            developer {
                id = "" //todo
                name = "" //todo
                email = "" //todo
            }
        }

        scm {
            url = "github url" //todo
        }
    }
    if (project.hasProperty("signing.keyId")) signAllPublications()
}

sqldelight {
    databases {
        create("SeforimDb") {
            // Database configuration here.
            // https://cashapp.github.io/sqldelight
            packageName.set("io.github.kdroidfilter.seforimlibrary.db")
            dialect("app.cash.sqldelight:sqlite-3-24-dialect:${libs.versions.sqlDelight.get()}")
        }
    }
}
</file>

<file path="dao/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/dao/extensions/ModelExtensions.kt">
package io.github.kdroidfilter.seforimlibrary.dao.extensions

import io.github.kdroidfilter.seforimlibrary.core.models.Author
import io.github.kdroidfilter.seforimlibrary.core.models.Book
import io.github.kdroidfilter.seforimlibrary.core.models.Category
import io.github.kdroidfilter.seforimlibrary.core.models.ConnectionType
import io.github.kdroidfilter.seforimlibrary.core.models.Line
import io.github.kdroidfilter.seforimlibrary.core.models.Link
import io.github.kdroidfilter.seforimlibrary.core.models.PubDate
import io.github.kdroidfilter.seforimlibrary.core.models.PubPlace
import io.github.kdroidfilter.seforimlibrary.core.models.SearchResult
import io.github.kdroidfilter.seforimlibrary.core.models.TocEntry
import io.github.kdroidfilter.seforimlibrary.core.models.Source
import io.github.kdroidfilter.seforimlibrary.core.models.Topic
// Legacy FTS result types removed (Lucene now used at app layer)
import kotlinx.serialization.json.Json
import kotlinx.serialization.decodeFromString
import co.touchlab.kermit.Logger

/**
 * This file contains extension functions to convert database entities to domain models.
 * These functions facilitate the mapping between the database layer and the domain layer.
 */

private val logger = Logger.withTag("ModelExtensions")

/**
 * Converts a database Author entity to a domain Author model.
 *
 * @return The domain Author model
 */
fun io.github.kdroidfilter.seforimlibrary.db.Author.toModel(): Author {
    return Author(
        id = id,
        name = name
    )
}

/**
 * Converts a database Pub_place entity to a domain PubPlace model.
 *
 * @return The domain PubPlace model
 */
fun io.github.kdroidfilter.seforimlibrary.db.Pub_place.toModel(): PubPlace {
    return PubPlace(
        id = id,
        name = name
    )
}

/**
 * Converts a database Pub_date entity to a domain PubDate model.
 *
 * @return The domain PubDate model
 */
fun io.github.kdroidfilter.seforimlibrary.db.Pub_date.toModel(): PubDate {
    return PubDate(
        id = id,
        date = date
    )
}

/**
 * Converts a database Book entity to a domain Book model.
 *
 * @param json The JSON parser for deserialization
 * @param authors The list of authors associated with the book
 * @param pubPlaces The list of publication places associated with the book
 * @param pubDates The list of publication dates associated with the book
 * @return The domain Book model
 */
fun io.github.kdroidfilter.seforimlibrary.db.Book.toModel(json: Json, authors: List<Author> = emptyList(), pubPlaces: List<PubPlace> = emptyList(), pubDates: List<PubDate> = emptyList()): Book {
    return Book(
        id = id,
        categoryId = categoryId,
        sourceId = sourceId,
        title = title,
        authors = authors,
        topics = emptyList(),
        pubPlaces = pubPlaces,
        pubDates = pubDates,
        heShortDesc = heShortDesc,
        notesContent = notesContent,
        order = orderIndex.toFloat(),
        totalLines = totalLines.toInt(),
        isBaseBook = isBaseBook == 1L,
        hasTargumConnection = hasTargumConnection == 1L,
        hasReferenceConnection = hasReferenceConnection == 1L,
        hasCommentaryConnection = hasCommentaryConnection == 1L,
        hasOtherConnection = hasOtherConnection == 1L

    )
}

/**
 * Converts a database Source entity to a domain Source model.
 */
fun io.github.kdroidfilter.seforimlibrary.db.Source.toModel(): Source {
    return Source(
        id = id,
        name = name
    )
}

/**
 * Converts a database Category entity to a domain Category model.
 *
 * @return The domain Category model
 */
fun io.github.kdroidfilter.seforimlibrary.db.Category.toModel(): Category {
    return Category(
        id = id,
        parentId = parentId,
        title = title,
        level = level.toInt()
    )
}

/**
 * Converts a database Line entity to a domain Line model.
 *
 * @return The domain Line model
 */
fun io.github.kdroidfilter.seforimlibrary.db.Line.toModel(): Line {
    logger.d{"Converting database Line to model with id: $id, bookId: $bookId, tocEntryId: $tocEntryId"}
    return Line(
        id = id,
        bookId = bookId,
        lineIndex = lineIndex.toInt(),
        content = content
    )
}

/**
 * Converts a database SelectTocById result to a domain TocEntry model.
 * This is used when retrieving a TOC entry by its ID.
 *
 * @return The domain TocEntry model
 */
fun io.github.kdroidfilter.seforimlibrary.db.SelectTocById.toModel(): TocEntry {
    logger.d{"Converting database TocEntry (from SelectTocById) with id: $id, bookId: $bookId, lineId: $lineId"}
    return TocEntry(
        id = id,
        bookId = bookId,
        parentId = parentId,
        textId = textId,
        text = text,
        level = level.toInt(),
        lineId = lineId,
        isLastChild = isLastChild == 1L,
        hasChildren = hasChildren == 1L
    )
}

/**
 * Converts a database SelectByBookId result to a domain TocEntry model.
 * This is used when retrieving TOC entries by book ID.
 *
 * @return The domain TocEntry model
 */
fun io.github.kdroidfilter.seforimlibrary.db.SelectByBookId.toModel(): TocEntry {
    logger.d{"Converting database TocEntry (from SelectByBookId) with id: $id, bookId: $bookId, lineId: $lineId"}
    return TocEntry(
        id = id,
        bookId = bookId,
        parentId = parentId,
        textId = textId,
        text = text,
        level = level.toInt(),
        lineId = lineId,
        isLastChild = isLastChild == 1L,
        hasChildren = hasChildren == 1L
    )
}

/**
 * Converts a database SelectRootByBookId result to a domain TocEntry model.
 * This is used when retrieving root TOC entries for a book.
 *
 * @return The domain TocEntry model
 */
fun io.github.kdroidfilter.seforimlibrary.db.SelectRootByBookId.toModel(): TocEntry {
    logger.d{"Converting database TocEntry (from SelectRootByBookId) with id: $id, bookId: $bookId, lineId: $lineId"}
    return TocEntry(
        id = id,
        bookId = bookId,
        parentId = parentId,
        textId = textId,
        text = text,
        level = level.toInt(),
        lineId = lineId,
        isLastChild = isLastChild == 1L,
        hasChildren = hasChildren == 1L
    )
}

/**
 * Converts a database SelectChildren result to a domain TocEntry model.
 * This is used when retrieving child TOC entries for a parent TOC entry.
 *
 * @return The domain TocEntry model
 */
fun io.github.kdroidfilter.seforimlibrary.db.SelectChildren.toModel(): TocEntry {
    logger.d{"Converting database TocEntry (from SelectChildren) with id: $id, bookId: $bookId, lineId: $lineId"}
    return TocEntry(
        id = id,
        bookId = bookId,
        parentId = parentId,
        textId = textId,
        text = text,
        level = level.toInt(),
        lineId = lineId,
        isLastChild = isLastChild == 1L,
        hasChildren = hasChildren == 1L
    )
}

/**
 * Converts a database SelectByLineId result to a domain TocEntry model.
 * This is used when retrieving a TOC entry by its heading line id.
 */
fun io.github.kdroidfilter.seforimlibrary.db.SelectByLineId.toModel(): TocEntry {
    logger.d{"Converting database TocEntry (from SelectByLineId) with id: $id, bookId: $bookId, lineId: $lineId"}
    return TocEntry(
        id = id,
        bookId = bookId,
        parentId = parentId,
        textId = textId,
        text = text,
        level = level.toInt(),
        lineId = lineId,
        isLastChild = isLastChild == 1L,
        hasChildren = hasChildren == 1L
    )
}

/**
 * Converts a database Connection_type entity to a domain ConnectionType enum.
 *
 * @return The domain ConnectionType enum
 */
fun io.github.kdroidfilter.seforimlibrary.db.Connection_type.toModel(): ConnectionType {
    return ConnectionType.fromString(name)
}

/**
 * Converts a database SelectLinkById result to a domain Link model.
 *
 * @return The domain Link model
 */
fun io.github.kdroidfilter.seforimlibrary.db.SelectLinkById.toModel(): Link {
    return Link(
        id = id,
        sourceBookId = sourceBookId,
        targetBookId = targetBookId,
        sourceLineId = sourceLineId,
        targetLineId = targetLineId,
        connectionType = ConnectionType.fromString(connectionType)
    )
}

/**
 * Converts a database SelectLinksBySourceLineIds result to a domain Link model.
 *
 * @return The domain Link model
 */
fun io.github.kdroidfilter.seforimlibrary.db.SelectLinksBySourceLineIds.toModel(): Link {
    return Link(
        id = id,
        sourceBookId = sourceBookId,
        targetBookId = targetBookId,
        sourceLineId = sourceLineId,
        targetLineId = targetLineId,
        connectionType = ConnectionType.fromString(connectionType)
    )
}

/**
 * Converts a database SelectLinksBySourceBook result to a domain Link model.
 *
 * @return The domain Link model
 */
fun io.github.kdroidfilter.seforimlibrary.db.SelectLinksBySourceBook.toModel(): Link {
    return Link(
        id = id,
        sourceBookId = sourceBookId,
        targetBookId = targetBookId,
        sourceLineId = sourceLineId,
        targetLineId = targetLineId,
        connectionType = ConnectionType.fromString(connectionType)
    )
}


/**
 * Converts a SearchAll database result to a domain SearchResult model.
 * This is used for global search across all books.
 *
 * @return The domain SearchResult model
 */
// Removed: FTS-based search result mappers (SearchAll/SearchInBook/etc.)

/**
 * Converts a SearchInBook database result to a domain SearchResult model.
 * This is used for searching within a specific book.
 *
 * @return The domain SearchResult model
 */
// Removed: see LuceneSearchService for search results mapping

/**
 * Converts a SearchByAuthor database result to a domain SearchResult model.
 * This is used for searching books by a specific author.
 *
 * @return The domain SearchResult model
 */
// Removed

/**
 * Converts a SearchWithBookFilter database result to a domain SearchResult model.
 * This is used for searching with specific book filters applied.
 *
 * @return The domain SearchResult model
 */
// Removed
</file>

<file path="dao/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/dao/repository/SeforimRepository.kt">
package io.github.kdroidfilter.seforimlibrary.dao.repository



import app.cash.sqldelight.db.SqlDriver
import co.touchlab.kermit.Logger
import io.github.kdroidfilter.seforimlibrary.core.models.*
import app.cash.sqldelight.db.SqlCursor
import app.cash.sqldelight.db.QueryResult
import io.github.kdroidfilter.seforimlibrary.dao.extensions.toModel
import io.github.kdroidfilter.seforimlibrary.db.SeforimDb
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.withContext
import kotlinx.serialization.json.Json

/**
 * Repository class for accessing and manipulating the Seforim database.
 * Provides methods for CRUD operations on books, categories, lines, TOC entries, and links.
 *
 * @property driver The SQL driver used to connect to the database
 * @constructor Creates a repository with the specified database path and driver
 */
class SeforimRepository(databasePath: String, private val driver: SqlDriver) {
    private val database = SeforimDb(driver)
    private val json = Json { ignoreUnknownKeys = true }
    private val logger = Logger.withTag("SeforimRepository")

    init {

        logger.d{"Initializing SeforimRepository"}
        // Create the database schema (fresh builds only; no runtime migrations needed)
        SeforimDb.Schema.create(driver)
        // SQLite optimizations
        driver.execute(null, "PRAGMA journal_mode=WAL", 0)
        driver.execute(null, "PRAGMA synchronous=NORMAL", 0)
        driver.execute(null, "PRAGMA cache_size=40000", 0)
        driver.execute(null, "PRAGMA temp_store=MEMORY", 0)

        // Check if the database is empty
        try {
            val bookCount = database.bookQueriesQueries.countAll().executeAsOne()
            logger.d{"Database contains $bookCount books"}
        } catch (e: Exception) {
            logger.d{"Error counting books: ${e.message}"}
        }
    }

    

    // --- Line ‚áÑ TOC mapping ---

    /**
     * Maps a line to the TOC entry it belongs to. Upserts on conflict.
     */
    suspend fun upsertLineToc(lineId: Long, tocEntryId: Long) = withContext(Dispatchers.IO) {
        database.lineTocQueriesQueries.upsert(lineId, tocEntryId)
    }

    // --- Transactions ---
    // Avoid custom transaction management that wraps the entire generation.
    // Use SQLDelight's default behavior (per‚Äëstatement auto-commit) at call sites.
    // Keep signature for compatibility with existing callers.
    suspend fun <T> runInTransaction(block: suspend () -> T): T = block()

    suspend fun setSynchronous(mode: String) = withContext(Dispatchers.IO) {
        driver.execute(null, "PRAGMA synchronous=$mode", 0)
    }

    suspend fun setSynchronousOff() = setSynchronous("OFF")
    suspend fun setSynchronousNormal() = setSynchronous("NORMAL")

    suspend fun setJournalMode(mode: String) = withContext(Dispatchers.IO) {
        driver.execute(null, "PRAGMA journal_mode=$mode", 0)
    }
    suspend fun setJournalModeOff() = setJournalMode("OFF")
    suspend fun setJournalModeWal() = setJournalMode("WAL")

    suspend fun bulkUpsertLineToc(pairs: List<Pair<Long, Long>>) = withContext(Dispatchers.IO) {
        if (pairs.isEmpty()) return@withContext
        for ((lineId, tocEntryId) in pairs) {
            database.lineTocQueriesQueries.upsert(lineId, tocEntryId)
        }
    }

    /**
     * Gets the tocEntryId associated with a line via the mapping table.
     */
    suspend fun getTocEntryIdForLine(lineId: Long): Long? = withContext(Dispatchers.IO) {
        database.lineTocQueriesQueries.selectTocEntryIdByLineId(lineId).executeAsOneOrNull()
    }

    /**
     * Gets the TocEntry model associated with a line via the mapping table.
     */
    suspend fun getTocEntryForLine(lineId: Long): TocEntry? = withContext(Dispatchers.IO) {
        val tocId = database.lineTocQueriesQueries.selectTocEntryIdByLineId(lineId).executeAsOneOrNull()
            ?: return@withContext null
        database.tocQueriesQueries.selectTocById(tocId).executeAsOneOrNull()?.toModel()
    }

    /**
     * Returns the TOC entry whose heading line is the given line id, or null if not a TOC heading.
     */
    suspend fun getHeadingTocEntryByLineId(lineId: Long): TocEntry? = withContext(Dispatchers.IO) {
        database.tocQueriesQueries.selectByLineId(lineId).executeAsOneOrNull()?.toModel()
    }

    /**
     * Returns all line ids that belong to the given TOC entry (section), ordered by lineIndex.
     */
    suspend fun getLineIdsForTocEntry(tocEntryId: Long): List<Long> = withContext(Dispatchers.IO) {
        database.lineTocQueriesQueries.selectLineIdsByTocEntryId(tocEntryId).executeAsList()
    }

    /**
     * Returns mappings (lineId -> tocEntryId) for a book ordered by line index.
     */
    suspend fun getLineTocMappingsForBook(bookId: Long): List<LineTocMapping> = withContext(Dispatchers.IO) {
        database.lineTocQueriesQueries.selectByBookId(bookId).executeAsList().map {
            // The generated type exposes columns as properties with same names
            LineTocMapping(lineId = it.lineId, tocEntryId = it.tocEntryId)
        }
    }

    /**
     * Builds all mappings for a given book by assigning to each line
     * the latest TOC entry whose start line index is <= line's index.
     * This is useful for backfilling existing databases.
     */
    suspend fun rebuildLineTocForBook(bookId: Long) = withContext(Dispatchers.IO) {
        // Clear existing mappings for the book
        database.lineTocQueriesQueries.deleteByBookId(bookId)

        // Insert computed mappings in a single statement using a correlated subquery
        // Note: Uses lineIndex ordering via join on tocEntry.lineId ‚Üí line.lineIndex
        driver.execute(null, """
            INSERT INTO line_toc(lineId, tocEntryId)
            SELECT l.id AS lineId,
                   (
                       SELECT t.id
                       FROM tocEntry t
                       JOIN line sl ON sl.id = t.lineId
                       WHERE t.bookId = l.bookId
                         AND t.lineId IS NOT NULL
                         AND sl.lineIndex <= l.lineIndex
                       ORDER BY sl.lineIndex DESC
                       LIMIT 1
                   ) AS tocEntryId
            FROM line l
            WHERE l.bookId = ?
        """.trimIndent(), 1) {
            bindLong(0, bookId)
        }
    }

    // --- Categories ---

    /**
     * Retrieves a category by its ID.
     *
     * @param id The ID of the category to retrieve
     * @return The category if found, null otherwise
     */
    suspend fun getCategory(id: Long): Category? = withContext(Dispatchers.IO) {
        database.categoryQueriesQueries.selectById(id).executeAsOneOrNull()?.toModel()
    }

    /**
     * Retrieves a category by its exact title.
     */
    suspend fun getCategoryByTitle(title: String): Category? = withContext(Dispatchers.IO) {
        database.categoryQueriesQueries.selectByTitle(title).executeAsOneOrNull()?.toModel()
    }

    /**
     * Retrieves best-matching category by name, trying exact, normalized, then LIKE.
     */
    suspend fun findCategoryByTitlePreferExact(title: String): Category? = withContext(Dispatchers.IO) {
        database.categoryQueriesQueries.selectByTitle(title).executeAsOneOrNull()?.toModel()
            ?: database.categoryQueriesQueries.selectByTitleLike("%$title%").executeAsOneOrNull()?.toModel()
    }

    /**
     * Retrieves all root categories (categories without a parent).
     *
     * @return A list of root categories
     */
    suspend fun getRootCategories(): List<Category> = withContext(Dispatchers.IO) {
        database.categoryQueriesQueries.selectRoot().executeAsList().map { it.toModel() }
    }

    /**
     * Retrieves all child categories of a parent category.
     *
     * @param parentId The ID of the parent category
     * @return A list of child categories
     */
    suspend fun getCategoryChildren(parentId: Long): List<Category> = withContext(Dispatchers.IO) {
        database.categoryQueriesQueries.selectByParentId(parentId).executeAsList().map { it.toModel() }
    }

    /**
     * Returns all descendant category IDs (including the category itself) using the
     * category_closure table. This is a bulk way to scope by category without recursive calls.
     */
    suspend fun getDescendantCategoryIds(ancestorId: Long): List<Long> = withContext(Dispatchers.IO) {
        database.categoryClosureQueriesQueries.selectDescendants(ancestorId).executeAsList()
    }

    /**
     * Finds categories whose title matches the LIKE pattern. Use %term% for contains.
     */
    suspend fun findCategoriesByTitleLike(pattern: String, limit: Int = 20): List<Category> = withContext(Dispatchers.IO) {
        database.categoryQueriesQueries.selectManyByTitleLike(pattern, limit.toLong()).executeAsList().map { it.toModel() }
    }



    /**
     * Inserts a category into the database.
     * If a category with the same title already exists, returns its ID instead.
     *
     * @param category The category to insert
     * @return The ID of the inserted or existing category
     * @throws RuntimeException If the insertion fails
     */
// Dans SeforimRepository.kt, remplacez la m√©thode insertCategory par celle-ci :

    suspend fun insertCategory(category: Category): Long = withContext(Dispatchers.IO) {
        logger.d { "üîß Repository: Attempting to insert category '${category.title}'" }
        logger.d { "üîß Category details: parentId=${category.parentId}, level=${category.level}" }

        try {
            // IMPORTANT: Check if a category with the same title AND SAME PARENT already exists
            // Two categories can have the same name if they have different parents!
            val existingCategories = if (category.parentId != null) {
                // Look for categories with the same parent
                database.categoryQueriesQueries.selectByParentId(category.parentId).executeAsList()
            } else {
                // Look for root categories (parentId is null)
                database.categoryQueriesQueries.selectRoot().executeAsList()
            }

            // Find a category with the same title in the same parent
            val existingCategory = existingCategories.find { it.title == category.title }

            if (existingCategory != null) {
                logger.d { "‚ö†Ô∏è Category with title '${category.title}' already exists under parent ${category.parentId} with ID: ${existingCategory.id}" }
                return@withContext existingCategory.id
            }

            // Try the insertion
            database.categoryQueriesQueries.insert(
                parentId = category.parentId,
                title = category.title,
                level = category.level.toLong()
            )

            val insertedId = database.categoryQueriesQueries.lastInsertRowId().executeAsOne()
            logger.d { "‚úÖ Repository: Category inserted with ID: $insertedId" }

            if (insertedId == 0L) {

                // Check again if the category was inserted despite lastInsertRowId() returning 0
                val updatedCategories = if (category.parentId != null) {
                    database.categoryQueriesQueries.selectByParentId(category.parentId).executeAsList()
                } else {
                    database.categoryQueriesQueries.selectRoot().executeAsList()
                }

                val newCategory = updatedCategories.find { it.title == category.title }

                if (newCategory != null) {
                    logger.d { "üîÑ Category found after insertion, returning existing ID: ${newCategory.id}" }
                    return@withContext newCategory.id
                }

                // If all else fails, throw an exception
                throw RuntimeException("Failed to insert category '${category.title}' with parent ${category.parentId}")
            }

            return@withContext insertedId

        } catch (e: Exception) {
            // Changed from error to warning level to reduce unnecessary error logs
            logger.w(e) { "‚ùå Repository: Error inserting category '${category.title}': ${e.message}" }

            // In case of error, check if the category exists anyway
            val categories = if (category.parentId != null) {
                database.categoryQueriesQueries.selectByParentId(category.parentId).executeAsList()
            } else {
                database.categoryQueriesQueries.selectRoot().executeAsList()
            }

            val existingCategory = categories.find { it.title == category.title }

            if (existingCategory != null) {
                logger.d { "üîÑ Category exists after error, returning existing ID: ${existingCategory.id}" }
                return@withContext existingCategory.id
            }

            // Re-throw the exception if we can't recover
            throw e
        }
    }

    /**
     * Rebuilds the category_closure table from the current category tree.
     * Inserts self-pairs and ancestor-descendant pairs for fast descendant filtering.
     */
    suspend fun rebuildCategoryClosure() = withContext(Dispatchers.IO) {
        // Clear existing closure data
        database.categoryClosureQueriesQueries.clear()
        // Load all categories (id, parentId)
        val rows = database.categoryQueriesQueries.selectAll().executeAsList()
        val parentMap = rows.associate { it.id to it.parentId }
        // For each category, walk up to root and insert pairs
        for (desc in rows) {
            var anc: Long? = desc.id
            // Self
            database.categoryClosureQueriesQueries.insert(desc.id, desc.id)
            anc = parentMap[desc.id]
            val safety = 128
            var guard = 0
            while (anc != null && guard++ < safety) {
                database.categoryClosureQueriesQueries.insert(anc, desc.id)
                anc = parentMap[anc]
            }
        }
    }

    // --- Books ---

    /**
     * Retrieves a book by its ID, including all related data (authors, topics, etc.).
     *
     * @param id The ID of the book to retrieve
     * @return The book if found, null otherwise
     */
    suspend fun getBook(id: Long): Book? = withContext(Dispatchers.IO) {
        val bookData = database.bookQueriesQueries.selectById(id).executeAsOneOrNull() ?: return@withContext null
        val authors = getBookAuthors(bookData.id)
        val topics = getBookTopics(bookData.id)
        val pubPlaces = getBookPubPlaces(bookData.id)
        val pubDates = getBookPubDates(bookData.id)
        return@withContext bookData.toModel(json, authors, pubPlaces, pubDates).copy(topics = topics)
    }

    /**
     * Retrieves all books in a specific category.
     *
     * @param categoryId The ID of the category
     * @return A list of books in the category
     */
    suspend fun getBooksByCategory(categoryId: Long): List<Book> = withContext(Dispatchers.IO) {
        val books = database.bookQueriesQueries.selectByCategoryId(categoryId).executeAsList()
        return@withContext books.map { bookData ->
            val authors = getBookAuthors(bookData.id)
            val topics = getBookTopics(bookData.id)
            val pubPlaces = getBookPubPlaces(bookData.id)
            val pubDates = getBookPubDates(bookData.id)
            bookData.toModel(json, authors, pubPlaces, pubDates).copy(topics = topics)
        }
    }

    /**
     * Retrieves all books under the given ancestor category (including the category itself)
     * using the category_closure table in a single query.
     */
    suspend fun getBooksUnderCategoryTree(ancestorCategoryId: Long): List<Book> = withContext(Dispatchers.IO) {
        val rows = database.bookQueriesQueries.selectByAncestorCategory(ancestorCategoryId).executeAsList()
        rows.map { bookData ->
            val authors = getBookAuthors(bookData.id)
            val topics = getBookTopics(bookData.id)
            val pubPlaces = getBookPubPlaces(bookData.id)
            val pubDates = getBookPubDates(bookData.id)
            bookData.toModel(json, authors, pubPlaces, pubDates).copy(topics = topics)
        }
    }

    /**
     * Finds books whose title matches the LIKE pattern. Use %term% for contains.
     */
    suspend fun findBooksByTitleLike(pattern: String, limit: Int = 20): List<Book> = withContext(Dispatchers.IO) {
        val rows = database.bookQueriesQueries.selectManyByTitleLike(pattern, limit.toLong()).executeAsList()
        rows.map { bookData ->
            val authors = getBookAuthors(bookData.id)
            val topics = getBookTopics(bookData.id)
            val pubPlaces = getBookPubPlaces(bookData.id)
            val pubDates = getBookPubDates(bookData.id)
            bookData.toModel(json, authors, pubPlaces, pubDates).copy(topics = topics)
        }
    }

    



    suspend fun searchBooksByAuthor(authorName: String): List<Book> = withContext(Dispatchers.IO) {
        val books = database.bookQueriesQueries.selectByAuthor("%$authorName%").executeAsList()
        return@withContext books.map { bookData ->
            val authors = getBookAuthors(bookData.id)
            val topics = getBookTopics(bookData.id)
            val pubPlaces = getBookPubPlaces(bookData.id)
            val pubDates = getBookPubDates(bookData.id)
            bookData.toModel(json, authors, pubPlaces, pubDates).copy(topics = topics)
        }
    }

    // Get all authors for a book
    private suspend fun getBookAuthors(bookId: Long): List<Author> = withContext(Dispatchers.IO) {
        logger.d{"Getting authors for book ID: $bookId"}
        val authors = database.authorQueriesQueries.selectByBookId(bookId).executeAsList()
        logger.d{"Found ${authors.size} authors for book ID: $bookId"}
        return@withContext authors.map { it.toModel() }
    }

    // Get all topics for a book
    private suspend fun getBookTopics(bookId: Long): List<Topic> = withContext(Dispatchers.IO) {
        logger.d{"Getting topics for book ID: $bookId"}
        val topics = database.topicQueriesQueries.selectByBookId(bookId).executeAsList()
        logger.d{"Found ${topics.size} topics for book ID: $bookId"}
        return@withContext topics.map { Topic(id = it.id, name = it.name) }
    }

    // Get all publication places for a book
    private suspend fun getBookPubPlaces(bookId: Long): List<PubPlace> = withContext(Dispatchers.IO) {
        logger.d{"Getting publication places for book ID: $bookId"}
        val pubPlaces = database.pubPlaceQueriesQueries.selectByBookId(bookId).executeAsList()
        logger.d{"Found ${pubPlaces.size} publication places for book ID: $bookId"}
        return@withContext pubPlaces.map { it.toModel() }
    }

    // Get all publication dates for a book
    private suspend fun getBookPubDates(bookId: Long): List<PubDate> = withContext(Dispatchers.IO) {
        logger.d{"Getting publication dates for book ID: $bookId"}
        val pubDates = database.pubDateQueriesQueries.selectByBookId(bookId).executeAsList()
        logger.d{"Found ${pubDates.size} publication dates for book ID: $bookId"}
        return@withContext pubDates.map { it.toModel() }
    }

    // Get an author by name, returns null if not found
    suspend fun getAuthorByName(name: String): Author? = withContext(Dispatchers.IO) {
        logger.d{"Looking for author with name: $name"}
        val author = database.authorQueriesQueries.selectByName(name).executeAsOneOrNull()
        if (author != null) {
            logger.d{"Found author with ID: ${author.id}"}
        } else {
            logger.d{"Author not found: $name"}
        }
        return@withContext author?.toModel()
    }

    // Insert an author and return its ID
    suspend fun insertAuthor(name: String): Long = withContext(Dispatchers.IO) {
        logger.d{"Inserting author: $name"}

        // Check if author already exists
        val existingAuthor = database.authorQueriesQueries.selectByName(name).executeAsOneOrNull()
        if (existingAuthor != null) {
            logger.d{"Author already exists with ID: ${existingAuthor.id}"}
            return@withContext existingAuthor.id
        }

        // Insert the author
        database.authorQueriesQueries.insert(name)

        // Get the ID of the inserted author
        val authorId = database.authorQueriesQueries.lastInsertRowId().executeAsOne()

        // If lastInsertRowId returns 0, it might be because the insertion was ignored due to a conflict
        // Try to get the ID by name
        if (authorId == 0L) {

            val insertedAuthor = database.authorQueriesQueries.selectByName(name).executeAsOneOrNull()
            if (insertedAuthor != null) {
                logger.d{"Found author after insertion with ID: ${insertedAuthor.id}"}
                return@withContext insertedAuthor.id
            }

            // If we can't find the author by name, try to insert it again with a different method
            logger.d{"Author not found after insertion, trying insertAndGetId"}
            database.authorQueriesQueries.insertAndGetId(name)

            // Check again
            val retryAuthor = database.authorQueriesQueries.selectByName(name).executeAsOneOrNull()
            if (retryAuthor != null) {
                logger.d{"Found author after retry with ID: ${retryAuthor.id}"}
                return@withContext retryAuthor.id
            }

            // If all else fails, return a dummy ID that will be used for this session only
            // This allows the process to continue without throwing an exception
            logger.w{"Could not insert author '$name' after multiple attempts, using temporary ID"}
            return@withContext 999999L
        }

        logger.d{"Author inserted with ID: $authorId"}
        return@withContext authorId
    }

    // Link an author to a book
    suspend fun linkAuthorToBook(authorId: Long, bookId: Long) = withContext(Dispatchers.IO) {
        logger.d{"Linking author $authorId to book $bookId"}
        database.authorQueriesQueries.linkBookAuthor(bookId, authorId)
        logger.d{"Linked author $authorId to book $bookId"}
    }

    suspend fun getBookByTitle(title: String): Book? = withContext(Dispatchers.IO) {
        val bookData = database.bookQueriesQueries.selectByTitle(title).executeAsOneOrNull() ?: return@withContext null
        val authors = getBookAuthors(bookData.id)
        val topics = getBookTopics(bookData.id)
        val pubPlaces = getBookPubPlaces(bookData.id)
        val pubDates = getBookPubDates(bookData.id)
        return@withContext bookData.toModel(json, authors, pubPlaces, pubDates).copy(topics = topics)
    }

    /**
     * Retrieves a book by approximate title (exact, normalized, or LIKE).
     */
    suspend fun findBookByTitlePreferExact(title: String): Book? = withContext(Dispatchers.IO) {
        val row = database.bookQueriesQueries.selectByTitle(title).executeAsOneOrNull()
            ?: database.bookQueriesQueries.selectByTitleLike("%$title%").executeAsOneOrNull()
        row?.let { bookData ->
            val authors = getBookAuthors(bookData.id)
            val topics = getBookTopics(bookData.id)
            val pubPlaces = getBookPubPlaces(bookData.id)
            val pubDates = getBookPubDates(bookData.id)
            bookData.toModel(json, authors, pubPlaces, pubDates).copy(topics = topics)
        }
    }

    // Get a topic by name, returns null if not found
    suspend fun getTopicByName(name: String): Topic? = withContext(Dispatchers.IO) {
        logger.d{"Looking for topic with name: $name"}
        val topic = database.topicQueriesQueries.selectByName(name).executeAsOneOrNull()
        if (topic != null) {
            logger.d{"Found topic with ID: ${topic.id}"}
        } else {
            logger.d{"Topic not found: $name"}
        }
        return@withContext topic?.let { Topic(id = it.id, name = it.name) }
    }

    // Get a publication place by name, returns null if not found
    suspend fun getPubPlaceByName(name: String): PubPlace? = withContext(Dispatchers.IO) {
        logger.d{"Looking for publication place with name: $name"}
        val pubPlace = database.pubPlaceQueriesQueries.selectByName(name).executeAsOneOrNull()
        if (pubPlace != null) {
            logger.d{"Found publication place with ID: ${pubPlace.id}"}
        } else {
            logger.d{"Publication place not found: $name"}
        }
        return@withContext pubPlace?.toModel()
    }

    // Get a publication date by date, returns null if not found
    suspend fun getPubDateByDate(date: String): PubDate? = withContext(Dispatchers.IO) {
        logger.d{"Looking for publication date with date: $date"}
        val pubDate = database.pubDateQueriesQueries.selectByDate(date).executeAsOneOrNull()
        if (pubDate != null) {
            logger.d{"Found publication date with ID: ${pubDate.id}"}
        } else {
            logger.d{"Publication date not found: $date"}
        }
        return@withContext pubDate?.toModel()
    }

    // Insert a topic and return its ID
    suspend fun insertTopic(name: String): Long = withContext(Dispatchers.IO) {
        logger.d{"Inserting topic: $name"}

        // Check if topic already exists
        val existingTopic = database.topicQueriesQueries.selectByName(name).executeAsOneOrNull()
        if (existingTopic != null) {
            logger.d{"Topic already exists with ID: ${existingTopic.id}"}
            return@withContext existingTopic.id
        }

        // Insert the topic
        database.topicQueriesQueries.insert(name)

        // Get the ID of the inserted topic
        val topicId = database.topicQueriesQueries.lastInsertRowId().executeAsOne()

        // If lastInsertRowId returns 0, it might be because the insertion was ignored due to a conflict
        // Try to get the ID by name
        if (topicId == 0L) {

            val insertedTopic = database.topicQueriesQueries.selectByName(name).executeAsOneOrNull()
            if (insertedTopic != null) {
                logger.d{"Found topic after insertion with ID: ${insertedTopic.id}"}
                return@withContext insertedTopic.id
            }

            // If we can't find the topic by name, try to insert it again with a different method
            logger.d{"Topic not found after insertion, trying insertAndGetId"}
            database.topicQueriesQueries.insertAndGetId(name)

            // Check again
            val retryTopic = database.topicQueriesQueries.selectByName(name).executeAsOneOrNull()
            if (retryTopic != null) {
                logger.d{"Found topic after retry with ID: ${retryTopic.id}"}
                return@withContext retryTopic.id
            }

            // If all else fails, return a dummy ID that will be used for this session only
            // This allows the process to continue without throwing an exception
            logger.w{"Could not insert topic '$name' after multiple attempts, using temporary ID"}
            return@withContext 999999L
        }

        logger.d{"Topic inserted with ID: $topicId"}
        return@withContext topicId
    }

    // Link a topic to a book
    suspend fun linkTopicToBook(topicId: Long, bookId: Long) = withContext(Dispatchers.IO) {
        logger.d{"Linking topic $topicId to book $bookId"}
        database.topicQueriesQueries.linkBookTopic(bookId, topicId)
        logger.d{"Linked topic $topicId to book $bookId"}
    }

    // Insert a publication place and return its ID
    suspend fun insertPubPlace(name: String): Long = withContext(Dispatchers.IO) {
        logger.d{"Inserting publication place: $name"}

        // Check if publication place already exists
        val existingPubPlace = database.pubPlaceQueriesQueries.selectByName(name).executeAsOneOrNull()
        if (existingPubPlace != null) {
            logger.d{"Publication place already exists with ID: ${existingPubPlace.id}"}
            return@withContext existingPubPlace.id
        }

        // Insert the publication place
        database.pubPlaceQueriesQueries.insert(name)

        // Get the ID of the inserted publication place
        val pubPlaceId = database.pubPlaceQueriesQueries.lastInsertRowId().executeAsOne()

        // If lastInsertRowId returns 0, it might be because the insertion was ignored due to a conflict
        // Try to get the ID by name
        if (pubPlaceId == 0L) {

            val insertedPubPlace = database.pubPlaceQueriesQueries.selectByName(name).executeAsOneOrNull()
            if (insertedPubPlace != null) {
                logger.d{"Found publication place after insertion with ID: ${insertedPubPlace.id}"}
                return@withContext insertedPubPlace.id
            }

            // If all else fails, return a dummy ID that will be used for this session only
            // This allows the process to continue without throwing an exception
            logger.w{"Could not insert publication place '$name' after multiple attempts, using temporary ID"}
            return@withContext 999999L
        }

        logger.d{"Publication place inserted with ID: $pubPlaceId"}
        return@withContext pubPlaceId
    }

    // Insert a publication date and return its ID
    suspend fun insertPubDate(date: String): Long = withContext(Dispatchers.IO) {
        logger.d{"Inserting publication date: $date"}

        // Check if publication date already exists
        val existingPubDate = database.pubDateQueriesQueries.selectByDate(date).executeAsOneOrNull()
        if (existingPubDate != null) {
            logger.d{"Publication date already exists with ID: ${existingPubDate.id}"}
            return@withContext existingPubDate.id
        }

        // Insert the publication date
        database.pubDateQueriesQueries.insert(date)

        // Get the ID of the inserted publication date
        val pubDateId = database.pubDateQueriesQueries.lastInsertRowId().executeAsOne()

        // If lastInsertRowId returns 0, it might be because the insertion was ignored due to a conflict
        // Try to get the ID by date
        if (pubDateId == 0L) {

            val insertedPubDate = database.pubDateQueriesQueries.selectByDate(date).executeAsOneOrNull()
            if (insertedPubDate != null) {
                logger.d{"Found publication date after insertion with ID: ${insertedPubDate.id}"}
                return@withContext insertedPubDate.id
            }

            // If all else fails, return a dummy ID that will be used for this session only
            // This allows the process to continue without throwing an exception
            logger.w{"Could not insert publication date '$date' after multiple attempts, using temporary ID"}
            return@withContext 999999L
        }

        logger.d{"Publication date inserted with ID: $pubDateId"}
        return@withContext pubDateId
    }

    // Link a publication place to a book
    suspend fun linkPubPlaceToBook(pubPlaceId: Long, bookId: Long) = withContext(Dispatchers.IO) {
        logger.d{"Linking publication place $pubPlaceId to book $bookId"}
        database.pubPlaceQueriesQueries.linkBookPubPlace(bookId, pubPlaceId)
        logger.d{"Linked publication place $pubPlaceId to book $bookId"}
    }

    // Link a publication date to a book
    suspend fun linkPubDateToBook(pubDateId: Long, bookId: Long) = withContext(Dispatchers.IO) {
        logger.d{"Linking publication date $pubDateId to book $bookId"}
        database.pubDateQueriesQueries.linkBookPubDate(bookId, pubDateId)
        logger.d{"Linked publication date $pubDateId to book $bookId"}
    }

    /**
     * Inserts a book into the database, including all related data (authors, topics, etc.).
     * If the book has an ID greater than 0, uses that ID; otherwise, generates a new ID.
     *
     * @param book The book to insert
     * @return The ID of the inserted book
     */
    suspend fun insertBook(book: Book): Long = withContext(Dispatchers.IO) {
        logger.d{"Repository inserting book '${book.title}' with ID: ${book.id} and categoryId: ${book.categoryId}"}

        // Use the ID from the book object if it's greater than 0
        if (book.id > 0) {
            database.bookQueriesQueries.insertWithId(
                id = book.id,
                categoryId = book.categoryId,
                sourceId = book.sourceId,
                title = book.title,
                heShortDesc = book.heShortDesc,
                notesContent = book.notesContent,
                orderIndex = book.order.toLong(),
                totalLines = book.totalLines.toLong(),
                isBaseBook = if (book.isBaseBook) 1 else 0
            )
            logger.d{"Used insertWithId for book '${book.title}' with ID: ${book.id} and categoryId: ${book.categoryId}"}

            // ‚úÖ Verify that the insertion was successful
            val insertedBook = database.bookQueriesQueries.selectById(book.id).executeAsOneOrNull()
            if (insertedBook?.categoryId != book.categoryId) {
                // Changed from error to warning level to reduce unnecessary error logs
                logger.w{"WARNING: Book inserted with wrong categoryId! Expected: ${book.categoryId}, Got: ${insertedBook?.categoryId}"}
                // Fix immediately
                database.bookQueriesQueries.updateCategoryId(book.categoryId, book.id)
                logger.d{"Corrected categoryId for book ID: ${book.id}"}
            }

            // Process authors
            for (author in book.authors) {
                val authorId = insertAuthor(author.name)
                linkAuthorToBook(authorId, book.id)
                logger.d{"Processed author '${author.name}' (ID: $authorId) for book '${book.title}' (ID: ${book.id})"}
            }

            // Process topics
            for (topic in book.topics) {
                val topicId = insertTopic(topic.name)
                linkTopicToBook(topicId, book.id)
                logger.d{"Processed topic '${topic.name}' (ID: $topicId) for book '${book.title}' (ID: ${book.id})"}
            }

            // Process publication places
            for (pubPlace in book.pubPlaces) {
                val pubPlaceId = insertPubPlace(pubPlace.name)
                linkPubPlaceToBook(pubPlaceId, book.id)
                logger.d{"Processed publication place '${pubPlace.name}' (ID: $pubPlaceId) for book '${book.title}' (ID: ${book.id})"}
            }

            // Process publication dates
            for (pubDate in book.pubDates) {
                val pubDateId = insertPubDate(pubDate.date)
                linkPubDateToBook(pubDateId, book.id)
                logger.d{"Processed publication date '${pubDate.date}' (ID: $pubDateId) for book '${book.title}' (ID: ${book.id})"}
            }

            return@withContext book.id
        } else {
            // Fall back to auto-generated ID if book.id is 0
            database.bookQueriesQueries.insert(
                categoryId = book.categoryId,
                sourceId = book.sourceId,
                title = book.title,
                heShortDesc = book.heShortDesc,
                notesContent = book.notesContent,
                orderIndex = book.order.toLong(),
                totalLines = book.totalLines.toLong(),
                isBaseBook = if (book.isBaseBook) 1 else 0
            )
            val id = database.bookQueriesQueries.lastInsertRowId().executeAsOne()
            logger.d{"Used insert for book '${book.title}', got ID: $id with categoryId: ${book.categoryId}"}

            // Check if insertion failed
            if (id == 0L) {
                // Try to find the book by title
                val existingBook = database.bookQueriesQueries.selectByTitle(book.title).executeAsOneOrNull()
                if (existingBook != null) {
                    logger.d { "Found book after failed insertion, returning existing ID: ${existingBook.id}" }
                    return@withContext existingBook.id
                }

                throw RuntimeException("Failed to insert book '${book.title}' - insertion returned ID 0. Context: categoryId=${book.categoryId}, authors=${book.authors.map { it.name }}, topics=${book.topics.map { it.name }}, pubPlaces=${book.pubPlaces.map { it.name }}, pubDates=${book.pubDates.map { it.date }}")
            }

            // Process authors
            for (author in book.authors) {
                val authorId = insertAuthor(author.name)
                linkAuthorToBook(authorId, id)
                logger.d{"Processed author '${author.name}' (ID: $authorId) for book '${book.title}' (ID: $id)"}
            }

            // Process topics
            for (topic in book.topics) {
                val topicId = insertTopic(topic.name)
                linkTopicToBook(topicId, id)
                logger.d{"Processed topic '${topic.name}' (ID: $topicId) for book '${book.title}' (ID: $id)"}
            }

            // Process publication places
            for (pubPlace in book.pubPlaces) {
                val pubPlaceId = insertPubPlace(pubPlace.name)
                linkPubPlaceToBook(pubPlaceId, id)
                logger.d{"Processed publication place '${pubPlace.name}' (ID: $pubPlaceId) for book '${book.title}' (ID: $id)"}
            }

            // Process publication dates
            for (pubDate in book.pubDates) {
                val pubDateId = insertPubDate(pubDate.date)
                linkPubDateToBook(pubDateId, id)
                logger.d{"Processed publication date '${pubDate.date}' (ID: $pubDateId) for book '${book.title}' (ID: $id)"}
            }

            return@withContext id
        }
    }

    // --- Sources ---

    /**
     * Returns a Source by name, or null if not found.
     */
    suspend fun getSourceByName(name: String): Source? = withContext(Dispatchers.IO) {
        database.sourceQueriesQueries.selectByName(name).executeAsOneOrNull()?.toModel()
    }

    /**
     * Inserts a source if missing and returns its id.
     */
    suspend fun insertSource(name: String): Long = withContext(Dispatchers.IO) {
        // Check existing
        val existing = database.sourceQueriesQueries.selectByName(name).executeAsOneOrNull()
        if (existing != null) return@withContext existing.id

        database.sourceQueriesQueries.insert(name)
        val id = database.sourceQueriesQueries.lastInsertRowId().executeAsOne()
        if (id == 0L) {
            // Try to read back just in case
            val again = database.sourceQueriesQueries.selectByName(name).executeAsOneOrNull()
            if (again != null) return@withContext again.id
            throw RuntimeException("Failed to insert source '$name'")
        }
        id
    }

    suspend fun updateBookTotalLines(bookId: Long, totalLines: Int) = withContext(Dispatchers.IO) {
        database.bookQueriesQueries.updateTotalLines(totalLines.toLong(), bookId)
    }

    suspend fun updateBookCategoryId(bookId: Long, categoryId: Long) = withContext(Dispatchers.IO) {
        logger.d{"Updating book $bookId with categoryId: $categoryId"}
        database.bookQueriesQueries.updateCategoryId(categoryId, bookId)
        logger.d{"Updated book $bookId with categoryId: $categoryId"}
    }

    // --- Lines ---

    suspend fun getLine(id: Long): Line? = withContext(Dispatchers.IO) {
        database.lineQueriesQueries.selectById(id).executeAsOneOrNull()?.toModel()
    }

    suspend fun getLineByIndex(bookId: Long, lineIndex: Int): Line? = withContext(Dispatchers.IO) {
        database.lineQueriesQueries.selectByBookIdAndIndex(bookId, lineIndex.toLong())
            .executeAsOneOrNull()?.toModel()
    }

    suspend fun getLines(bookId: Long, startIndex: Int, endIndex: Int): List<Line> =
        withContext(Dispatchers.IO) {
            database.lineQueriesQueries.selectByBookIdRange(
                bookId = bookId,
                lineIndex = startIndex.toLong(),
                lineIndex_ = endIndex.toLong()
            ).executeAsList().map { it.toModel() }
        }
        
    /**
     * Gets the previous line for a given book and line index.
     * 
     * @param bookId The ID of the book
     * @param currentLineIndex The index of the current line
     * @return The previous line, or null if there is no previous line
     */
    suspend fun getPreviousLine(bookId: Long, currentLineIndex: Int): Line? = withContext(Dispatchers.IO) {
        if (currentLineIndex <= 0) return@withContext null
        
        val previousIndex = currentLineIndex - 1
        database.lineQueriesQueries.selectByBookIdAndIndex(bookId, previousIndex.toLong())
            .executeAsOneOrNull()?.toModel()
    }
    
    /**
     * Gets the next line for a given book and line index.
     * 
     * @param bookId The ID of the book
     * @param currentLineIndex The index of the current line
     * @return The next line, or null if there is no next line
     */
    suspend fun getNextLine(bookId: Long, currentLineIndex: Int): Line? = withContext(Dispatchers.IO) {
        val nextIndex = currentLineIndex + 1
        database.lineQueriesQueries.selectByBookIdAndIndex(bookId, nextIndex.toLong())
            .executeAsOneOrNull()?.toModel()
    }

    suspend fun insertLine(line: Line): Long = withContext(Dispatchers.IO) {
        logger.d{"Repository inserting line with bookId: ${line.bookId}"}

        // Use the ID from the line object if it's greater than 0
        if (line.id > 0) {
            database.lineQueriesQueries.insertWithId(
                id = line.id,
                bookId = line.bookId,
                lineIndex = line.lineIndex.toLong(),
                content = line.content,
                tocEntryId = null
            )
            logger.d{"Repository inserted line with explicit ID: ${line.id} and bookId: ${line.bookId}"}
            return@withContext line.id
        } else {
            // Fall back to auto-generated ID if line.id is 0
            database.lineQueriesQueries.insert(
                bookId = line.bookId,
                lineIndex = line.lineIndex.toLong(),
                content = line.content,
                tocEntryId = null
            )
            val lineId = database.lineQueriesQueries.lastInsertRowId().executeAsOne()
            logger.d{"Repository inserted line with auto-generated ID: $lineId and bookId: ${line.bookId}"}

            // Check if insertion failed
            if (lineId == 0L) {
                // Try to find the line by bookId and lineIndex
                val existingLine = database.lineQueriesQueries.selectByBookIdAndIndex(line.bookId, line.lineIndex.toLong()).executeAsOneOrNull()
                if (existingLine != null) {
                    logger.d { "Found line after failed insertion, returning existing ID: ${existingLine.id}" }
                    return@withContext existingLine.id
                }

                throw RuntimeException("Failed to insert line for book ${line.bookId} at index ${line.lineIndex} - insertion returned ID 0. Context: content='${line.content.take(50)}${if (line.content.length > 50) "..." else ""}')")
            }

            return@withContext lineId
        }
    }

    suspend fun updateLineTocEntry(lineId: Long, tocEntryId: Long) = withContext(Dispatchers.IO) {
        logger.d{"Repository updating line $lineId with tocEntryId: $tocEntryId"}
        database.lineQueriesQueries.updateTocEntryId(tocEntryId, lineId)
        logger.d{"Repository updated line $lineId with tocEntryId: $tocEntryId"}
    }

    // --- Table of Contents ---

    suspend fun getTocEntry(id: Long): TocEntry? = withContext(Dispatchers.IO) {
        database.tocQueriesQueries.selectTocById(id).executeAsOneOrNull()?.toModel()
    }

    suspend fun getBookToc(bookId: Long): List<TocEntry> = withContext(Dispatchers.IO) {
        database.tocQueriesQueries.selectByBookId(bookId).executeAsList().map { it.toModel() }
    }

    suspend fun getBookRootToc(bookId: Long): List<TocEntry> = withContext(Dispatchers.IO) {
        database.tocQueriesQueries.selectRootByBookId(bookId).executeAsList().map { it.toModel() }
    }

    suspend fun getTocChildren(parentId: Long): List<TocEntry> = withContext(Dispatchers.IO) {
        database.tocQueriesQueries.selectChildren(parentId).executeAsList().map { it.toModel() }
    }

    // --- TocText methods ---

    // Returns all distinct tocText values using generated SQLDelight query
    suspend fun getAllTocTexts(): List<String> = withContext(Dispatchers.IO) {
        logger.d { "Getting all tocText values (using generated query)" }
        database.tocTextQueriesQueries.selectAll().executeAsList().map { it.text }
    }
    
    // Get or create a tocText entry and return its ID
    private suspend fun getOrCreateTocText(text: String): Long = withContext(Dispatchers.IO) {
        // Truncate text for logging if it's too long
        val truncatedText = if (text.length > 50) "${text.take(50)}..." else text
        logger.d{"Getting or creating tocText entry for text: '$truncatedText'"}

        try {
            // Check if the text already exists
            logger.d{"Checking if text already exists in database"}
            val existingId = database.tocTextQueriesQueries.selectIdByText(text).executeAsOneOrNull()
            if (existingId != null) {
                logger.d{"Found existing tocText entry with ID: $existingId for text: '$truncatedText'"}
                return@withContext existingId
            }

            // Insert the text
            logger.d{"Text not found, inserting new tocText entry for: '$truncatedText'"}
            database.tocTextQueriesQueries.insertAndGetId(text)

            // Get the ID of the inserted text
            logger.d{"Getting ID of inserted tocText entry"}
            val textId = database.tocTextQueriesQueries.lastInsertRowId().executeAsOne()
            logger.d{"lastInsertRowId() returned: $textId"}

            // If lastInsertRowId returns 0, it's likely because the text already exists (due to INSERT OR IGNORE)
            // This is expected behavior, not an error, so we'll try to get the ID by text
            if (textId == 0L) {
                // Log at debug level since this is expected behavior when text already exists
                logger.d{"lastInsertRowId() returned 0 for tocText insertion (likely due to INSERT OR IGNORE). Text: '$truncatedText', Length: ${text.length}, Hash: ${text.hashCode()}. Trying to get ID by text."}

                // Try to find the text that was just inserted or that already existed
                val insertedId = database.tocTextQueriesQueries.selectIdByText(text).executeAsOneOrNull()
                if (insertedId != null) {
                    logger.d{"Found tocText with ID: $insertedId for text: '$truncatedText'"}
                    return@withContext insertedId
                }

                // If we can't find the text by exact match, this is unexpected and should be logged as an error
                // Count total tocTexts for debugging
                val totalTocTexts = database.tocTextQueriesQueries.countAll().executeAsOne()

                // Log more details about the failure
                // Changed from error to warning level to reduce unnecessary error logs
                logger.w{"Failed to insert tocText and couldn't find it after insertion. This is unexpected since the text should either be inserted or already exist. Text: '$truncatedText', Length: ${text.length}, Hash: ${text.hashCode()}, Total TocTexts: $totalTocTexts"}

                throw RuntimeException("Failed to insert tocText '$truncatedText' - insertion returned ID 0 and couldn't find text afterward. This is unexpected since the text should either be inserted or already exist. Context: textLength=${text.length}, textHash=${text.hashCode()}, totalTocTexts=$totalTocTexts")
            }

            logger.d{"Created new tocText entry with ID: $textId for text: '$truncatedText'"}
            return@withContext textId
        } catch (e: Exception) {
            // Changed from error to warning level to reduce unnecessary error logs
            logger.w(e){"Exception in getOrCreateTocText for text: '$truncatedText', Length: ${text.length}, Hash: ${text.hashCode()}. Error: ${e.message}"}
            throw e
        }
    }

    suspend fun insertTocEntry(entry: TocEntry): Long = withContext(Dispatchers.IO) {
        logger.d{"Repository inserting TOC entry with bookId: ${entry.bookId}, lineId: ${entry.lineId}, hasChildren: ${entry.hasChildren}"}

        // Get or create the tocText entry
        val textId = entry.textId ?: getOrCreateTocText(entry.text)
        logger.d{"Using tocText ID: $textId for text: ${entry.text}"}

        // Use the ID from the entry object if it's greater than 0
        if (entry.id > 0) {
            database.tocQueriesQueries.insertWithId(
                id = entry.id,
                bookId = entry.bookId,
                parentId = entry.parentId,
                textId = textId,
                level = entry.level.toLong(),
                lineId = entry.lineId,
                isLastChild = if (entry.isLastChild) 1 else 0,
                hasChildren = if (entry.hasChildren) 1 else 0  // NOUVEAU
            )
            logger.d{"Repository inserted TOC entry with explicit ID: ${entry.id}, bookId: ${entry.bookId}, lineId: ${entry.lineId}, hasChildren: ${entry.hasChildren}"}
            return@withContext entry.id
        } else {
            // Fall back to auto-generated ID if entry.id is 0
            database.tocQueriesQueries.insert(
                bookId = entry.bookId,
                parentId = entry.parentId,
                textId = textId,
                level = entry.level.toLong(),
                lineId = entry.lineId,
                isLastChild = if (entry.isLastChild) 1 else 0,
                hasChildren = if (entry.hasChildren) 1 else 0  // NOUVEAU
            )
            val tocId = database.tocQueriesQueries.lastInsertRowId().executeAsOne()
            logger.d{"Repository inserted TOC entry with auto-generated ID: $tocId, bookId: ${entry.bookId}, lineId: ${entry.lineId}, hasChildren: ${entry.hasChildren}"}

            // Check if insertion failed
            if (tocId == 0L) {
                // Try to find a matching TOC entry by bookId and text
                val existingEntries = database.tocQueriesQueries.selectByBookId(entry.bookId).executeAsList()
                val matchingEntry = existingEntries.find {
                    it.text == entry.text && it.level == entry.level.toLong()
                }

                if (matchingEntry != null) {
                    logger.d { "Found matching TOC entry after failed insertion, returning existing ID: ${matchingEntry.id}" }
                    return@withContext matchingEntry.id
                }

                throw RuntimeException("Failed to insert TOC entry for book ${entry.bookId} with text '${entry.text.take(30)}${if (entry.text.length > 30) "..." else ""}' - insertion returned ID 0. Context: parentId=${entry.parentId}, level=${entry.level}, lineId=${entry.lineId}")
            }

            return@withContext tocId
        }
    }

    // Nouvelle m√©thode pour mettre √† jour hasChildren
    suspend fun updateTocEntryHasChildren(tocEntryId: Long, hasChildren: Boolean) = withContext(Dispatchers.IO) {
        logger.d{"Repository updating TOC entry $tocEntryId with hasChildren: $hasChildren"}
        database.tocQueriesQueries.updateHasChildren(if (hasChildren) 1 else 0, tocEntryId)
        logger.d{"Repository updated TOC entry $tocEntryId with hasChildren: $hasChildren"}
    }
    suspend fun updateTocEntryLineId(tocEntryId: Long, lineId: Long) = withContext(Dispatchers.IO) {
        logger.d{"Repository updating TOC entry $tocEntryId with lineId: $lineId"}
        database.tocQueriesQueries.updateLineId(lineId, tocEntryId)
        logger.d{"Repository updated TOC entry $tocEntryId with lineId: $lineId"}
    }
    
    suspend fun updateTocEntryIsLastChild(tocEntryId: Long, isLastChild: Boolean) = withContext(Dispatchers.IO) {
        logger.d{"Repository updating TOC entry $tocEntryId with isLastChild: $isLastChild"}
        database.tocQueriesQueries.updateIsLastChild(if (isLastChild) 1 else 0, tocEntryId)
        logger.d{"Repository updated TOC entry $tocEntryId with isLastChild: $isLastChild"}
    }

    // --- Connection Types ---

    /**
     * Gets a connection type by name, or creates it if it doesn't exist.
     *
     * @param name The name of the connection type
     * @return The ID of the connection type
     */
    private suspend fun getOrCreateConnectionType(name: String): Long = withContext(Dispatchers.IO) {
        logger.d{"Getting or creating connection type: $name"}

        // Check if the connection type already exists
        val existingType = database.connectionTypeQueriesQueries.selectByName(name).executeAsOneOrNull()
        if (existingType != null) {
            logger.d{"Found existing connection type with ID: ${existingType.id}"}
            return@withContext existingType.id
        }

        // Insert the connection type
        database.connectionTypeQueriesQueries.insert(name)

        // Get the ID of the inserted connection type
        val typeId = database.connectionTypeQueriesQueries.lastInsertRowId().executeAsOne()

        // If lastInsertRowId returns 0, try to get the ID by name
        if (typeId == 0L) {

            val insertedType = database.connectionTypeQueriesQueries.selectByName(name).executeAsOneOrNull()
            if (insertedType != null) {
                logger.d{"Found connection type after insertion with ID: ${insertedType.id}"}
                return@withContext insertedType.id
            }

            throw RuntimeException("Failed to insert connection type '$name' - insertion returned ID 0 and couldn't find type afterward")
        }

        logger.d{"Created new connection type with ID: $typeId"}
        return@withContext typeId
    }

    /**
     * Gets all connection types from the database.
     *
     * @return A list of all connection types
     */
    suspend fun getAllConnectionTypes(): List<ConnectionType> = withContext(Dispatchers.IO) {
        database.connectionTypeQueriesQueries.selectAll().executeAsList().map { 
            ConnectionType.fromString(it.name)
        }
    }

    // --- Links ---

    suspend fun getLink(id: Long): Link? = withContext(Dispatchers.IO) {
        database.linkQueriesQueries.selectLinkById(id).executeAsOneOrNull()?.toModel()
    }

    suspend fun countLinks(): Long = withContext(Dispatchers.IO) {
        logger.d{"Counting links in database"}
        val count = database.linkQueriesQueries.countAllLinks().executeAsOne()
        logger.d{"Found $count links in database"}
        count
    }

    suspend fun getCommentariesForLines(
        lineIds: List<Long>,
        activeCommentatorIds: Set<Long> = emptySet()
    ): List<CommentaryWithText> = withContext(Dispatchers.IO) {
        database.linkQueriesQueries.selectLinksBySourceLineIds(lineIds).executeAsList()
            .filter { activeCommentatorIds.isEmpty() || it.targetBookId in activeCommentatorIds }
            .map {
                CommentaryWithText(
                    link = Link(
                        id = it.id,
                        sourceBookId = it.sourceBookId,
                        targetBookId = it.targetBookId,
                        sourceLineId = it.sourceLineId,
                        targetLineId = it.targetLineId,
                        connectionType = ConnectionType.fromString(it.connectionType)
                    ),
                    targetBookTitle = it.targetBookTitle,
                    targetText = it.targetText
                )
            }
    }

    suspend fun getAvailableCommentators(bookId: Long): List<CommentatorInfo> =
        withContext(Dispatchers.IO) {
            database.linkQueriesQueries.selectCommentatorsByBook(bookId).executeAsList()
                .map {
                    CommentatorInfo(
                        bookId = it.targetBookId,
                        title = it.targetBookTitle,
                        author = it.author,
                        linkCount = it.linkCount.toInt()
                    )
                }
        }

    // New paginated methods for per-commentator pagination use cases
    suspend fun getCommentariesForLineRange(
        lineIds: List<Long>,
        activeCommentatorIds: Set<Long> = emptySet(),
        offset: Int,
        limit: Int
    ): List<CommentaryWithText> = withContext(Dispatchers.IO) {
        database.linkQueriesQueries.selectLinksBySourceLineIds(lineIds)
            .executeAsList()
            .filter { activeCommentatorIds.isEmpty() || it.targetBookId in activeCommentatorIds }
            .drop(offset)
            .take(limit)
            .map {
                CommentaryWithText(
                    link = Link(
                        id = it.id,
                        sourceBookId = it.sourceBookId,
                        targetBookId = it.targetBookId,
                        sourceLineId = it.sourceLineId,
                        targetLineId = it.targetLineId,
                        connectionType = ConnectionType.fromString(it.connectionType)
                    ),
                    targetBookTitle = it.targetBookTitle,
                    targetText = it.targetText
                )
            }
    }

    suspend fun getAvailableCommentators(
        bookId: Long,
        offset: Int,
        limit: Int
    ): List<CommentatorInfo> = withContext(Dispatchers.IO) {
        database.linkQueriesQueries.selectCommentatorsByBook(bookId)
            .executeAsList()
            .drop(offset)
            .take(limit)
            .map {
                CommentatorInfo(
                    bookId = it.targetBookId,
                    title = it.targetBookTitle,
                    author = it.author,
                    linkCount = it.linkCount.toInt()
                )
            }
    }

    suspend fun insertLink(link: Link): Long = withContext(Dispatchers.IO) {
        logger.d{"Repository inserting link from book ${link.sourceBookId} to book ${link.targetBookId}"}
        logger.d{"Link details - sourceLineId: ${link.sourceLineId}, targetLineId: ${link.targetLineId}, connectionType: ${link.connectionType.name}"}

        try {
            // Get or create the connection type
            val connectionTypeId = getOrCreateConnectionType(link.connectionType.name)
            logger.d{"Using connection type ID: $connectionTypeId for type: ${link.connectionType.name}"}

            database.linkQueriesQueries.insert(
                sourceBookId = link.sourceBookId,
                targetBookId = link.targetBookId,
                sourceLineId = link.sourceLineId,
                targetLineId = link.targetLineId,
                connectionTypeId = connectionTypeId
            )
            val linkId = database.linkQueriesQueries.lastInsertRowId().executeAsOne()
            logger.d{"Repository inserted link with ID: $linkId"}

            // Check if insertion failed
            if (linkId == 0L) {

                // Try to find a matching link
                val existingLinks = database.linkQueriesQueries.selectLinksBySourceBook(link.sourceBookId).executeAsList()
                val matchingLink = existingLinks.find { 
                    it.targetBookId == link.targetBookId && 
                    it.sourceLineId == link.sourceLineId && 
                    it.targetLineId == link.targetLineId 
                }

                if (matchingLink != null) {
                    logger.d { "Found matching link after failed insertion, returning existing ID: ${matchingLink.id}" }
                    return@withContext matchingLink.id
                }

                throw RuntimeException("Failed to insert link from book ${link.sourceBookId} to book ${link.targetBookId} - insertion returned ID 0. Context: sourceLineId=${link.sourceLineId}, targetLineId=${link.targetLineId}, connectionType=${link.connectionType.name}")
            }

            return@withContext linkId
        } catch (e: Exception) {
            // Changed from error to warning level to reduce unnecessary error logs
            logger.w(e){"Error inserting link: ${e.message}"}
            throw e
        }
    }

    /**
     * Migrates existing links to use the new connection_type table.
     * This should be called once after updating the database schema.
     */
    suspend fun migrateConnectionTypes() = withContext(Dispatchers.IO) {
        logger.d{"Starting migration of connection types"}

        try {
            // Make sure all connection types exist in the connection_type table
            for (type in ConnectionType.values()) {
                getOrCreateConnectionType(type.name)
            }

            // Get all links from the database
            val links = database.linkQueriesQueries.selectLinksBySourceBook(0).executeAsList()
            logger.d{"Found ${links.size} links to migrate"}

            // For each link, update the connectionTypeId
            var migratedCount = 0
            for (link in links) {
                val connectionTypeId = getOrCreateConnectionType(link.connectionType)

                // Execute a raw SQL query to update the link
                val updateSql = "UPDATE link SET connectionTypeId = $connectionTypeId WHERE id = ${link.id}"
                executeRawQuery(updateSql)

                migratedCount++
                if (migratedCount % 100 == 0) {
                    logger.d{"Migrated $migratedCount links so far"}
                }
            }

            logger.d{"Successfully migrated $migratedCount links"}
            logger.d{"Connection types migration completed successfully"}
        } catch (e: Exception) {
            logger.e(e){"Error during connection types migration: ${e.message}"}
            throw e
        }
    }

    // Search functions removed (migrated to Lucene in app layer).

    /**
     * Executes a raw SQL query.
     * This is useful for operations that are not covered by the generated queries,
     * such as enabling or disabling foreign key constraints.
     *
     * @param sql The SQL query to execute
     */
    suspend fun executeRawQuery(sql: String) = withContext(Dispatchers.IO) {
        logger.d { "Executing raw SQL query: $sql" }
        driver.execute(null, sql, 0)
        logger.d { "Raw SQL query executed successfully" }
    }

    // FTS rebuild removed (Lucene managed externally by generator).

    /**
     * Updates the book_has_links table to indicate whether a book has source links, target links, or both.
     * 
     * @param bookId The ID of the book to update
     * @param hasSourceLinks Whether the book has source links (true) or not (false)
     * @param hasTargetLinks Whether the book has target links (true) or not (false)
     */
    suspend fun updateBookHasLinks(bookId: Long, hasSourceLinks: Boolean, hasTargetLinks: Boolean) = withContext(Dispatchers.IO) {
        logger.d { "Updating book_has_links for book $bookId: hasSourceLinks=$hasSourceLinks, hasTargetLinks=$hasTargetLinks" }
        val hasSourceLinksInt = if (hasSourceLinks) 1L else 0L
        val hasTargetLinksInt = if (hasTargetLinks) 1L else 0L

        // Use upsert to insert or update the book's link status
        database.bookHasLinksQueriesQueries.upsert(bookId, hasSourceLinksInt, hasTargetLinksInt)

        logger.d { "Updated book_has_links for book $bookId: hasSourceLinks=$hasSourceLinks, hasTargetLinks=$hasTargetLinks" }
    }

    /**
     * Updates only the source links status for a book.
     * 
     * @param bookId The ID of the book to update
     * @param hasSourceLinks Whether the book has source links (true) or not (false)
     */
    suspend fun updateBookSourceLinks(bookId: Long, hasSourceLinks: Boolean) = withContext(Dispatchers.IO) {
        logger.d { "Updating source links for book $bookId: hasSourceLinks=$hasSourceLinks" }
        val hasSourceLinksInt = if (hasSourceLinks) 1L else 0L

        // Update only the source links status
        database.bookHasLinksQueriesQueries.updateSourceLinks(hasSourceLinksInt, bookId)

        logger.d { "Updated source links for book $bookId: hasSourceLinks=$hasSourceLinks" }
    }

    /**
     * Updates only the target links status for a book.
     * 
     * @param bookId The ID of the book to update
     * @param hasTargetLinks Whether the book has target links (true) or not (false)
     */
    suspend fun updateBookTargetLinks(bookId: Long, hasTargetLinks: Boolean) = withContext(Dispatchers.IO) {
        logger.d { "Updating target links for book $bookId: hasTargetLinks=$hasTargetLinks" }
        val hasTargetLinksInt = if (hasTargetLinks) 1L else 0L

        // Update only the target links status
        database.bookHasLinksQueriesQueries.updateTargetLinks(hasTargetLinksInt, bookId)

        logger.d { "Updated target links for book $bookId: hasTargetLinks=$hasTargetLinks" }
    }

    // --- Connection type specific helpers ---

    suspend fun countLinksBySourceBookAndType(bookId: Long, typeName: String): Long = withContext(Dispatchers.IO) {
        database.linkQueriesQueries.countLinksBySourceBookAndType(bookId, typeName).executeAsOne()
    }

    suspend fun countLinksByTargetBookAndType(bookId: Long, typeName: String): Long = withContext(Dispatchers.IO) {
        database.linkQueriesQueries.countLinksByTargetBookAndType(bookId, typeName).executeAsOne()
    }

    suspend fun updateBookConnectionFlags(
        bookId: Long,
        hasTargum: Boolean,
        hasReference: Boolean,
        hasCommentary: Boolean,
        hasOther: Boolean
    ) = withContext(Dispatchers.IO) {
        val t = if (hasTargum) 1L else 0L
        val r = if (hasReference) 1L else 0L
        val c = if (hasCommentary) 1L else 0L
        val o = if (hasOther) 1L else 0L
        database.bookQueriesQueries.updateConnectionFlags(t, r, c, o, bookId)
    }

    /**
     * Checks if a book has any links (source or target).
     * 
     * @param bookId The ID of the book to check
     * @return True if the book has any links, false otherwise
     */
    suspend fun bookHasAnyLinks(bookId: Long): Boolean = withContext(Dispatchers.IO) {
        logger.d { "Checking if book $bookId has any links" }

        // Check if the book has any links as source or target
        val hasSourceLinks = bookHasSourceLinks(bookId)
        val hasTargetLinks = bookHasTargetLinks(bookId)
        val result = hasSourceLinks || hasTargetLinks

        logger.d { "Book $bookId has any links: $result" }
        result
    }

    /**
     * Checks if a book has source links.
     * 
     * @param bookId The ID of the book to check
     * @return True if the book has source links, false otherwise
     */
    suspend fun bookHasSourceLinks(bookId: Long): Boolean = withContext(Dispatchers.IO) {
        logger.d { "Checking if book $bookId has source links" }
        val count = countLinksBySourceBook(bookId)
        val result = count > 0
        logger.d { "Book $bookId has source links: $result" }
        result
    }

    /**
     * Checks if a book has target links.
     * 
     * @param bookId The ID of the book to check
     * @return True if the book has target links, false otherwise
     */
    suspend fun bookHasTargetLinks(bookId: Long): Boolean = withContext(Dispatchers.IO) {
        logger.d { "Checking if book $bookId has target links" }
        val count = countLinksByTargetBook(bookId)
        val result = count > 0
        logger.d { "Book $bookId has target links: $result" }
        result
    }

    /**
     * Checks if a book has OTHER type comments.
     */
    suspend fun bookHasOtherComments(bookId: Long): Boolean = withContext(Dispatchers.IO) {
        logger.d { "Checking if book $bookId has OTHER comments" }
        val book = database.bookQueriesQueries.selectById(bookId).executeAsOneOrNull()
        val result = book?.hasOtherConnection == 1L
        logger.d { "Book $bookId has OTHER comments: $result" }
        result
    }

    /**
     * Checks if a book has COMMENTARY type comments.
     */
    suspend fun bookHasCommentaryComments(bookId: Long): Boolean = withContext(Dispatchers.IO) {
        logger.d { "Checking if book $bookId has COMMENTARY comments" }
        val book = database.bookQueriesQueries.selectById(bookId).executeAsOneOrNull()
        val result = book?.hasCommentaryConnection == 1L
        logger.d { "Book $bookId has COMMENTARY comments: $result" }
        result
    }

    /**
     * Checks if a book has REFERENCE type comments.
     */
    suspend fun bookHasReferenceComments(bookId: Long): Boolean = withContext(Dispatchers.IO) {
        logger.d { "Checking if book $bookId has REFERENCE comments" }
        val book = database.bookQueriesQueries.selectById(bookId).executeAsOneOrNull()
        val result = book?.hasReferenceConnection == 1L
        logger.d { "Book $bookId has REFERENCE comments: $result" }
        result
    }

    /**
     * Checks if a book has TARGUM type comments.
     */
    suspend fun bookHasTargumComments(bookId: Long): Boolean = withContext(Dispatchers.IO) {
        logger.d { "Checking if book $bookId has TARGUM comments" }
        val book = database.bookQueriesQueries.selectById(bookId).executeAsOneOrNull()
        val result = book?.hasTargumConnection == 1L
        logger.d { "Book $bookId has TARGUM comments: $result" }
        result
    }

    /**
     * Gets all books that have any links (source or target).
     * 
     * @return A list of books that have any links
     */
    suspend fun getBooksWithAnyLinks(): List<Book> = withContext(Dispatchers.IO) {
        logger.d { "Getting all books with any links" }
        val books = database.bookHasLinksQueriesQueries.selectBooksWithAnyLinks().executeAsList()
        logger.d { "Found ${books.size} books with any links" }

        // Convert the database books to model books
        books.map { bookData ->
            val authors = getBookAuthors(bookData.id)
            val topics = getBookTopics(bookData.id)
            val pubPlaces = getBookPubPlaces(bookData.id)
            val pubDates = getBookPubDates(bookData.id)
            bookData.toModel(json, authors, pubPlaces, pubDates).copy(topics = topics)
        }
    }

    /**
     * Gets all books that have source links.
     * 
     * @return A list of books that have source links
     */
    suspend fun getBooksWithSourceLinks(): List<Book> = withContext(Dispatchers.IO) {
        logger.d { "Getting all books with source links" }
        val books = database.bookHasLinksQueriesQueries.selectBooksWithSourceLinks().executeAsList()
        logger.d { "Found ${books.size} books with source links" }

        // Convert the database books to model books
        books.map { bookData ->
            val authors = getBookAuthors(bookData.id)
            val topics = getBookTopics(bookData.id)
            val pubPlaces = getBookPubPlaces(bookData.id)
            val pubDates = getBookPubDates(bookData.id)
            bookData.toModel(json, authors, pubPlaces, pubDates).copy(topics = topics)
        }
    }

    /**
     * Gets all books that have target links.
     * 
     * @return A list of books that have target links
     */
    suspend fun getBooksWithTargetLinks(): List<Book> = withContext(Dispatchers.IO) {
        logger.d { "Getting all books with target links" }
        val books = database.bookHasLinksQueriesQueries.selectBooksWithTargetLinks().executeAsList()
        logger.d { "Found ${books.size} books with target links" }

        // Convert the database books to model books
        books.map { bookData ->
            val authors = getBookAuthors(bookData.id)
            val topics = getBookTopics(bookData.id)
            val pubPlaces = getBookPubPlaces(bookData.id)
            val pubDates = getBookPubDates(bookData.id)
            bookData.toModel(json, authors, pubPlaces, pubDates).copy(topics = topics)
        }
    }

    /**
     * Counts the number of books that have any links (source or target).
     * 
     * @return The number of books that have any links
     */
    suspend fun countBooksWithAnyLinks(): Long = withContext(Dispatchers.IO) {
        logger.d { "Counting books with any links" }
        val count = database.bookHasLinksQueriesQueries.countBooksWithAnyLinks().executeAsOne()
        logger.d { "Found $count books with any links" }
        count
    }

    /**
     * Counts the number of books that have source links.
     * 
     * @return The number of books that have source links
     */
    suspend fun countBooksWithSourceLinks(): Long = withContext(Dispatchers.IO) {
        logger.d { "Counting books with source links" }
        val count = database.bookHasLinksQueriesQueries.countBooksWithSourceLinks().executeAsOne()
        logger.d { "Found $count books with source links" }
        count
    }

    /**
     * Counts the number of books that have target links.
     * 
     * @return The number of books that have target links
     */
    suspend fun countBooksWithTargetLinks(): Long = withContext(Dispatchers.IO) {
        logger.d { "Counting books with target links" }
        val count = database.bookHasLinksQueriesQueries.countBooksWithTargetLinks().executeAsOne()
        logger.d { "Found $count books with target links" }
        count
    }


    /**
     * Gets all books from the database.
     * 
     * @return A list of all books
     */
    suspend fun getAllBooks(): List<Book> = withContext(Dispatchers.IO) {
        logger.d { "Getting all books" }
        val books = database.bookQueriesQueries.selectAll().executeAsList()
        logger.d { "Found ${books.size} books" }

        // Convert the database books to model books
        books.map { bookData ->
            val authors = getBookAuthors(bookData.id)
            val topics = getBookTopics(bookData.id)
            val pubPlaces = getBookPubPlaces(bookData.id)
            val pubDates = getBookPubDates(bookData.id)
            bookData.toModel(json, authors, pubPlaces, pubDates).copy(topics = topics)
        }
    }

    /**
     * Returns the IDs of all base books (isBaseBook = 1).
     */
    suspend fun getBaseBookIds(): List<Long> = withContext(Dispatchers.IO) {
        database.bookQueriesQueries.selectBaseIds().executeAsList()
    }

    /**
     * Counts the number of links where the given book is the source.
     * 
     * @param bookId The ID of the book to count links for
     * @return The number of links where the book is the source
     */
    suspend fun countLinksBySourceBook(bookId: Long): Long = withContext(Dispatchers.IO) {
        logger.d { "Counting links where book $bookId is the source" }
        val count = database.linkQueriesQueries.countLinksBySourceBook(bookId).executeAsOne()
        logger.d { "Found $count links where book $bookId is the source" }
        count
    }

    /**
     * Counts the number of links where the given book is the target.
     * 
     * @param bookId The ID of the book to count links for
     * @return The number of links where the book is the target
     */
    suspend fun countLinksByTargetBook(bookId: Long): Long = withContext(Dispatchers.IO) {
        logger.d { "Counting links where book $bookId is the target" }
        val count = database.linkQueriesQueries.countLinksByTargetBook(bookId).executeAsOne()
        logger.d { "Found $count links where book $bookId is the target" }
        count
    }

    // --- Acronyms ---

    /**
     * Inserts a single acronym term for a book (ignores duplicates).
     */
    suspend fun insertBookAcronym(bookId: Long, term: String) = withContext(Dispatchers.IO) {
        database.acronymQueriesQueries.insert(bookId, term)
    }

    /**
     * Bulk inserts acronym terms for a given bookId. Ignores duplicates.
     */
    suspend fun bulkInsertBookAcronyms(bookId: Long, terms: Collection<String>) = withContext(Dispatchers.IO) {
        if (terms.isEmpty()) return@withContext
        for (t in terms) database.acronymQueriesQueries.insert(bookId, t)
    }

    /**
     * Returns all acronym terms for a given book.
     */
    suspend fun getAcronymsForBook(bookId: Long): List<String> = withContext(Dispatchers.IO) {
        database.acronymQueriesQueries.selectTermsByBookId(bookId).executeAsList()
    }

    /**
     * Finds all book IDs whose acronym list contains exactly the given term.
     */
    suspend fun findBookIdsByAcronym(term: String): List<Long> = withContext(Dispatchers.IO) {
        database.acronymQueriesQueries.selectBookIdsByTerm(term).executeAsList()
    }

    /**
     * Finds books by acronym LIKE pattern. Use %term% or term% for prefix.
     */
    suspend fun findBooksByAcronymLike(pattern: String, limit: Int = 20): List<Book> = withContext(Dispatchers.IO) {
        val ids = database.acronymQueriesQueries.selectBookIdsByTermLike(pattern, limit.toLong()).executeAsList()
        ids.distinct().mapNotNull { id -> getBook(id) }
    }

    /**
     * Finds books by exact acronym term.
     */
    suspend fun findBooksByAcronymExact(term: String, limit: Int = 20): List<Book> = withContext(Dispatchers.IO) {
        val ids = database.acronymQueriesQueries.selectBookIdsByTerm(term).executeAsList()
        ids.take(limit).mapNotNull { id -> getBook(id) }
    }

    /**
     * Returns the hierarchical depth for a category using the closure table.
     * Depth = number of ancestors (including self) - 1. Falls back to stored level if closure empty.
     */
    suspend fun getCategoryDepth(categoryId: Long): Int = withContext(Dispatchers.IO) {
        val count = database.categoryClosureQueriesQueries.countAncestorsByDescendant(categoryId).executeAsOne()
        if (count > 0) (count - 1).toInt() else {
            // Fallback to category.level if closure not built
            database.categoryQueriesQueries.selectById(categoryId).executeAsOneOrNull()?.level?.toInt() ?: 0
        }
    }

    // Legacy book-title FTS removed (handled by Lucene index in generator/app).

    /**
     * Deletes all acronym rows for a book.
     */
    suspend fun deleteAcronymsForBook(bookId: Long) = withContext(Dispatchers.IO) {
        database.acronymQueriesQueries.deleteByBookId(bookId)
    }

    /**
     * Closes the database connection.
     * Should be called when the repository is no longer needed.
     */
    fun close() {
        driver.close()
    }
}

// Data classes for enriched results

/**
 * Information about a commentator (author who comments on other books).
 *
 * @property bookId The ID of the commentator's book
 * @property title The title of the commentator's book
 * @property author The name of the commentator
 * @property linkCount The number of links (comments) by this commentator
 */
data class CommentatorInfo(
    val bookId: Long,
    val title: String,
    val author: String?,
    val linkCount: Int
)

/**
 * A commentary with its text content.
 *
 * @property link The link connecting the source text to the commentary
 * @property targetBookTitle The title of the book containing the commentary
 * @property targetText The text of the commentary
 */
data class CommentaryWithText(
    val link: Link,
    val targetBookTitle: String,
    val targetText: String
)
</file>

<file path="dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/AcronymQueries.sq">
-- Queries for book acronyms (alternate names)

selectTermsByBookId:
SELECT term FROM book_acronym
WHERE bookId = ?
ORDER BY term;

selectByBookId:
SELECT * FROM book_acronym
WHERE bookId = ?
ORDER BY term;

selectBookIdsByTerm:
SELECT bookId FROM book_acronym
WHERE term = ?
ORDER BY bookId;

selectBookIdsByTermLike:
SELECT DISTINCT bookId FROM book_acronym
WHERE term LIKE ?
ORDER BY bookId
LIMIT ?;

insert:
INSERT INTO book_acronym (bookId, term)
VALUES (?, ?)
ON CONFLICT(bookId, term) DO NOTHING;

deleteByBookId:
DELETE FROM book_acronym WHERE bookId = ?;

countByBookId:
SELECT COUNT(*) FROM book_acronym WHERE bookId = ?;
</file>

<file path="dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/AuthorQueries.sq">
-- Queries for authors

selectAll:
SELECT * FROM author ORDER BY name;

selectById:
SELECT * FROM author WHERE id = ?;

selectByName:
SELECT * FROM author WHERE name = ? LIMIT 1;

selectByBookId:
SELECT a.* FROM author a
JOIN book_author ba ON a.id = ba.authorId
WHERE ba.bookId = ?
ORDER BY a.name;

insert:
INSERT INTO author (name)
VALUES (?)
ON CONFLICT (name) DO NOTHING;

insertAndGetId:
INSERT OR IGNORE INTO author (name)
VALUES (?);

selectIdByName:
SELECT id FROM author WHERE name = ? LIMIT 1;

delete:
DELETE FROM author WHERE id = ?;

countAll:
SELECT COUNT(*) FROM author;

lastInsertRowId:
SELECT last_insert_rowid();

-- Queries for the book_author junction table

linkBookAuthor:
INSERT INTO book_author (bookId, authorId)
VALUES (?, ?)
ON CONFLICT (bookId, authorId) DO NOTHING;

unlinkBookAuthor:
DELETE FROM book_author WHERE bookId = ? AND authorId = ?;

deleteAllBookAuthors:
DELETE FROM book_author WHERE bookId = ?;

countBookAuthors:
SELECT COUNT(*) FROM book_author WHERE bookId = ?;
</file>

<file path="dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/BookHasLinksQueries.sq">
-- Queries for the book_has_links table

-- Get link status for a book
selectByBookId:
SELECT bookId, hasSourceLinks, hasTargetLinks
FROM book_has_links
WHERE bookId = ?;

-- Get all books that have source links
selectBooksWithSourceLinks:
SELECT b.*
FROM book b
JOIN book_has_links bhl ON b.id = bhl.bookId
WHERE bhl.hasSourceLinks = 1;

-- Get all books that have target links
selectBooksWithTargetLinks:
SELECT b.*
FROM book b
JOIN book_has_links bhl ON b.id = bhl.bookId
WHERE bhl.hasTargetLinks = 1;

-- Get all books that have any links (source or target)
selectBooksWithAnyLinks:
SELECT b.*
FROM book b
JOIN book_has_links bhl ON b.id = bhl.bookId
WHERE bhl.hasSourceLinks = 1 OR bhl.hasTargetLinks = 1;

-- Count books with source links
countBooksWithSourceLinks:
SELECT COUNT(*)
FROM book_has_links
WHERE hasSourceLinks = 1;

-- Count books with target links
countBooksWithTargetLinks:
SELECT COUNT(*)
FROM book_has_links
WHERE hasTargetLinks = 1;

-- Count books with any links (source or target)
countBooksWithAnyLinks:
SELECT COUNT(*)
FROM book_has_links
WHERE hasSourceLinks = 1 OR hasTargetLinks = 1;

-- Insert or update a book's link status
upsert:
INSERT OR REPLACE INTO book_has_links (bookId, hasSourceLinks, hasTargetLinks)
VALUES (?, ?, ?);

-- Update a book's source link status
updateSourceLinks:
UPDATE book_has_links
SET hasSourceLinks = ?
WHERE bookId = ?;

-- Update a book's target link status
updateTargetLinks:
UPDATE book_has_links
SET hasTargetLinks = ?
WHERE bookId = ?;

-- Update both source and target link status
updateBothLinkTypes:
UPDATE book_has_links
SET hasSourceLinks = ?,
    hasTargetLinks = ?
WHERE bookId = ?;

-- Insert a new book link status
insert:
INSERT INTO book_has_links (bookId, hasSourceLinks, hasTargetLinks)
VALUES (?, ?, ?);

-- Delete a book's link status
delete:
DELETE FROM book_has_links
WHERE bookId = ?;

-- Get the last inserted row ID
lastInsertRowId:
SELECT last_insert_rowid();
</file>

<file path="dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/BookQueries.sq">
-- Queries for books

selectAll:
SELECT * FROM book ORDER BY orderIndex, title;

selectById:
SELECT * FROM book WHERE id = ?;

selectByCategoryId:
SELECT * FROM book WHERE categoryId = ? ORDER BY orderIndex, title;

-- Select all books whose category is a descendant of the given ancestor category
selectByAncestorCategory:
SELECT b.* FROM book b
WHERE b.categoryId IN (SELECT descendantId FROM category_closure WHERE ancestorId = ?)
ORDER BY b.orderIndex, b.title;

selectByTitle:
SELECT * FROM book WHERE title = ? LIMIT 1;

selectByTitleLike:
SELECT * FROM book WHERE title LIKE ? LIMIT 1;

selectManyByTitleLike:
SELECT * FROM book WHERE title LIKE ? ORDER BY orderIndex, title LIMIT ?;


selectByAuthor:
SELECT b.* FROM book b
JOIN book_author ba ON b.id = ba.bookId
JOIN author a ON ba.authorId = a.id
WHERE a.name LIKE ? 
ORDER BY b.orderIndex, b.title;

-- Base-books helpers
selectBaseIds:
SELECT id FROM book WHERE isBaseBook = 1 ORDER BY orderIndex, title;

insert:
INSERT INTO book (categoryId, sourceId, title, heShortDesc, notesContent, orderIndex, totalLines, isBaseBook)
VALUES (?, ?, ?, ?, ?, ?, ?, ?);

insertWithId:
INSERT INTO book (id, categoryId, sourceId, title, heShortDesc, notesContent, orderIndex, totalLines, isBaseBook)
VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?);

updateTotalLines:
UPDATE book SET totalLines = ? WHERE id = ?;

delete:
DELETE FROM book WHERE id = ?;

countByCategoryId:
SELECT COUNT(*) FROM book WHERE categoryId = ?;

countAll:
SELECT COUNT(*) FROM book;

getMaxId:
SELECT MAX(id) FROM book;

updateCategoryId:
UPDATE book SET categoryId = ? WHERE id = ?;

-- Update connection flags on book
updateConnectionFlags:
UPDATE book SET 
    hasTargumConnection = ?,
    hasReferenceConnection = ?,
    hasCommentaryConnection = ?,
    hasOtherConnection = ?
WHERE id = ?;

lastInsertRowId:
SELECT last_insert_rowid();
</file>

<file path="dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/CategoryClosureQueries.sq">
-- Queries for the category_closure table

clear:
DELETE FROM category_closure;

insert:
INSERT OR IGNORE INTO category_closure(ancestorId, descendantId) VALUES(?, ?);

selectDescendants:
SELECT descendantId FROM category_closure WHERE ancestorId = ?;

selectAncestors:
SELECT ancestorId FROM category_closure WHERE descendantId = ?;

countAncestorsByDescendant:
SELECT COUNT(*) FROM category_closure WHERE descendantId = ?;
</file>

<file path="dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/CategoryQueries.sq">
-- Queries for categories

selectAll:
SELECT * FROM category ORDER BY title;

selectById:
SELECT * FROM category WHERE id = ?;

selectByParentId:
SELECT * FROM category WHERE parentId = ? ORDER BY title;

selectRoot:
SELECT * FROM category WHERE parentId IS NULL ORDER BY title;

selectByTitle:
SELECT * FROM category WHERE title = ? LIMIT 1;

selectByTitleLike:
SELECT * FROM category WHERE title LIKE ? ORDER BY level ASC, title LIMIT 1;

selectManyByTitleLike:
SELECT * FROM category WHERE title LIKE ? ORDER BY level ASC, title LIMIT ?;

insert:
INSERT INTO category (parentId, title, level)
VALUES (?, ?, ?);

update:
UPDATE category SET
    title = ?
WHERE id = ?;

delete:
DELETE FROM category WHERE id = ?;

countAll:
SELECT COUNT(*) FROM category;

lastInsertRowId:
SELECT last_insert_rowid();
</file>

<file path="dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/ConnectionTypeQueries.sq">
-- Queries for connection types

selectById:
SELECT * FROM connection_type WHERE id = ?;

selectByName:
SELECT * FROM connection_type WHERE name = ?;

selectAll:
SELECT * FROM connection_type ORDER BY name;

insert:
INSERT INTO connection_type (name)
VALUES (?);

update:
UPDATE connection_type
SET name = ?
WHERE id = ?;

delete:
DELETE FROM connection_type WHERE id = ?;

lastInsertRowId:
SELECT last_insert_rowid();
</file>

<file path="dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/Database.sq">
-- Categories table
CREATE TABLE IF NOT EXISTS category (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    parentId INTEGER,
    title TEXT NOT NULL,
    level INTEGER NOT NULL DEFAULT 0,
    FOREIGN KEY (parentId) REFERENCES category(id) ON DELETE CASCADE
);

CREATE INDEX IF NOT EXISTS idx_category_parent ON category(parentId);

-- Closure table for efficient descendant/ancestor lookups
CREATE TABLE IF NOT EXISTS category_closure (
    ancestorId INTEGER NOT NULL,
    descendantId INTEGER NOT NULL,
    PRIMARY KEY (ancestorId, descendantId),
    FOREIGN KEY (ancestorId) REFERENCES category(id) ON DELETE CASCADE,
    FOREIGN KEY (descendantId) REFERENCES category(id) ON DELETE CASCADE
);

CREATE INDEX IF NOT EXISTS idx_category_closure_ancestor ON category_closure(ancestorId);
CREATE INDEX IF NOT EXISTS idx_category_closure_descendant ON category_closure(descendantId);

-- Authors table
CREATE TABLE IF NOT EXISTS author (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL UNIQUE
);

CREATE INDEX IF NOT EXISTS idx_author_name ON author(name);

-- Table des topics
CREATE TABLE IF NOT EXISTS topic (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL UNIQUE
);

CREATE INDEX IF NOT EXISTS idx_topic_name ON topic(name);

-- Publication places table
CREATE TABLE IF NOT EXISTS pub_place (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL UNIQUE
);

CREATE INDEX IF NOT EXISTS idx_pub_place_name ON pub_place(name);

-- Publication dates table
CREATE TABLE IF NOT EXISTS pub_date (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    date TEXT NOT NULL UNIQUE
);

CREATE INDEX IF NOT EXISTS idx_pub_date_date ON pub_date(date);

-- Sources table (origin of each book)
CREATE TABLE IF NOT EXISTS source (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL UNIQUE
);

CREATE INDEX IF NOT EXISTS idx_source_name ON source(name);

-- Books table
CREATE TABLE IF NOT EXISTS book (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    categoryId INTEGER NOT NULL,
    sourceId INTEGER NOT NULL,
    title TEXT NOT NULL,
    heShortDesc TEXT,
    -- Optional raw notes attached to the base book (when a companion file '◊î◊¢◊®◊ï◊™ ◊¢◊ú <title>' exists)
    notesContent TEXT,
    orderIndex INTEGER NOT NULL DEFAULT 999,
    totalLines INTEGER NOT NULL DEFAULT 0,
    isBaseBook INTEGER NOT NULL DEFAULT 0,
    hasTargumConnection INTEGER NOT NULL DEFAULT 0,
    hasReferenceConnection INTEGER NOT NULL DEFAULT 0,
    hasCommentaryConnection INTEGER NOT NULL DEFAULT 0,
    hasOtherConnection INTEGER NOT NULL DEFAULT 0,
    FOREIGN KEY (categoryId) REFERENCES category(id) ON DELETE CASCADE,
    FOREIGN KEY (sourceId) REFERENCES source(id) ON DELETE RESTRICT
);

CREATE INDEX IF NOT EXISTS idx_book_category ON book(categoryId);
CREATE INDEX IF NOT EXISTS idx_book_title ON book(title);
CREATE INDEX IF NOT EXISTS idx_book_order ON book(orderIndex);
CREATE INDEX IF NOT EXISTS idx_book_source ON book(sourceId);

-- Book-publication place junction table
CREATE TABLE IF NOT EXISTS book_pub_place (
    bookId INTEGER NOT NULL,
    pubPlaceId INTEGER NOT NULL,
    PRIMARY KEY (bookId, pubPlaceId),
    FOREIGN KEY (bookId) REFERENCES book(id) ON DELETE CASCADE,
    FOREIGN KEY (pubPlaceId) REFERENCES pub_place(id) ON DELETE CASCADE
);

CREATE INDEX IF NOT EXISTS idx_book_pub_place_book ON book_pub_place(bookId);
CREATE INDEX IF NOT EXISTS idx_book_pub_place_place ON book_pub_place(pubPlaceId);

-- Book-publication date junction table
CREATE TABLE IF NOT EXISTS book_pub_date (
    bookId INTEGER NOT NULL,
    pubDateId INTEGER NOT NULL,
    PRIMARY KEY (bookId, pubDateId),
    FOREIGN KEY (bookId) REFERENCES book(id) ON DELETE CASCADE,
    FOREIGN KEY (pubDateId) REFERENCES pub_date(id) ON DELETE CASCADE
);

CREATE INDEX IF NOT EXISTS idx_book_pub_date_book ON book_pub_date(bookId);
CREATE INDEX IF NOT EXISTS idx_book_pub_date_date ON book_pub_date(pubDateId);

-- Book-topic junction table
CREATE TABLE IF NOT EXISTS book_topic (
    bookId INTEGER NOT NULL,
    topicId INTEGER NOT NULL,
    PRIMARY KEY (bookId, topicId),
    FOREIGN KEY (bookId) REFERENCES book(id) ON DELETE CASCADE,
    FOREIGN KEY (topicId) REFERENCES topic(id) ON DELETE CASCADE
);

CREATE INDEX IF NOT EXISTS idx_book_topic_book ON book_topic(bookId);
CREATE INDEX IF NOT EXISTS idx_book_topic_topic ON book_topic(topicId);

-- Book-author junction table
CREATE TABLE IF NOT EXISTS book_author (
    bookId INTEGER NOT NULL,
    authorId INTEGER NOT NULL,
    PRIMARY KEY (bookId, authorId),
    FOREIGN KEY (bookId) REFERENCES book(id) ON DELETE CASCADE,
    FOREIGN KEY (authorId) REFERENCES author(id) ON DELETE CASCADE
);

CREATE INDEX IF NOT EXISTS idx_book_author_book ON book_author(bookId);
CREATE INDEX IF NOT EXISTS idx_book_author_author ON book_author(authorId);

-- Lines table
CREATE TABLE IF NOT EXISTS line (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    bookId INTEGER NOT NULL,
    lineIndex INTEGER NOT NULL,
    content TEXT NOT NULL,
    tocEntryId INTEGER,
    FOREIGN KEY (bookId) REFERENCES book(id) ON DELETE CASCADE,
    FOREIGN KEY (tocEntryId) REFERENCES tocEntry(id) ON DELETE SET NULL
);

CREATE INDEX IF NOT EXISTS idx_line_book_index ON line(bookId, lineIndex);
CREATE INDEX IF NOT EXISTS idx_line_toc ON line(tocEntryId);

-- TOC texts table
CREATE TABLE IF NOT EXISTS tocText (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    text TEXT NOT NULL UNIQUE
);

CREATE INDEX IF NOT EXISTS idx_toc_text ON tocText(text);
CREATE INDEX IF NOT EXISTS idx_toctext_text_length ON tocText(text, length(text));

-- TOC entries table
CREATE TABLE IF NOT EXISTS tocEntry (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    bookId INTEGER NOT NULL,
    parentId INTEGER,
    textId INTEGER NOT NULL,
    level INTEGER NOT NULL,
    lineId INTEGER,
    isLastChild INTEGER NOT NULL DEFAULT 0,
    hasChildren INTEGER NOT NULL DEFAULT 0,
    FOREIGN KEY (bookId) REFERENCES book(id) ON DELETE CASCADE,
    FOREIGN KEY (parentId) REFERENCES tocEntry(id) ON DELETE CASCADE,
    FOREIGN KEY (textId) REFERENCES tocText(id) ON DELETE CASCADE,
    FOREIGN KEY (lineId) REFERENCES line(id) ON DELETE SET NULL
);

CREATE INDEX IF NOT EXISTS idx_toc_book ON tocEntry(bookId);
CREATE INDEX IF NOT EXISTS idx_toc_parent ON tocEntry(parentId);
CREATE INDEX IF NOT EXISTS idx_toc_text_id ON tocEntry(textId);
CREATE INDEX IF NOT EXISTS idx_toc_line ON tocEntry(lineId);
CREATE INDEX IF NOT EXISTS idx_tocentry_text_level ON tocEntry(textId, level);
CREATE INDEX IF NOT EXISTS idx_tocentry_level_book ON tocEntry(level, bookId);

-- Connection types table
CREATE TABLE IF NOT EXISTS connection_type (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL UNIQUE
);

CREATE INDEX IF NOT EXISTS idx_connection_type_name ON connection_type(name);

-- Links table
CREATE TABLE IF NOT EXISTS link (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    sourceBookId INTEGER NOT NULL,
    targetBookId INTEGER NOT NULL,
    sourceLineId INTEGER NOT NULL,
    targetLineId INTEGER NOT NULL,
    connectionTypeId INTEGER NOT NULL,
    FOREIGN KEY (sourceBookId) REFERENCES book(id) ON DELETE CASCADE,
    FOREIGN KEY (targetBookId) REFERENCES book(id) ON DELETE CASCADE,
    FOREIGN KEY (sourceLineId) REFERENCES line(id) ON DELETE CASCADE,
    FOREIGN KEY (targetLineId) REFERENCES line(id) ON DELETE CASCADE,
    FOREIGN KEY (connectionTypeId) REFERENCES connection_type(id) ON DELETE CASCADE
);

CREATE INDEX IF NOT EXISTS idx_link_source_book ON link(sourceBookId);
CREATE INDEX IF NOT EXISTS idx_link_source_line ON link(sourceLineId);
CREATE INDEX IF NOT EXISTS idx_link_target_book ON link(targetBookId);
CREATE INDEX IF NOT EXISTS idx_link_target_line ON link(targetLineId);
CREATE INDEX IF NOT EXISTS idx_link_type ON link(connectionTypeId);

-- Removed legacy FTS view/table in favor of Lucene (10.x)

-- Table to track whether books have links (as source or target)
CREATE TABLE IF NOT EXISTS book_has_links (
    bookId INTEGER PRIMARY KEY,
    hasSourceLinks INTEGER NOT NULL DEFAULT 0, -- 0 = false, 1 = true
    hasTargetLinks INTEGER NOT NULL DEFAULT 0, -- 0 = false, 1 = true
    FOREIGN KEY (bookId) REFERENCES book(id) ON DELETE CASCADE
);

CREATE INDEX IF NOT EXISTS idx_book_has_source_links ON book_has_links(hasSourceLinks);
CREATE INDEX IF NOT EXISTS idx_book_has_target_links ON book_has_links(hasTargetLinks);

-- Mapping table: line -> owning TOC entry
-- This denormalizes the relationship so every line can directly resolve
-- the TOC entry it belongs to (the latest heading before or at the line).
CREATE TABLE IF NOT EXISTS line_toc (
    lineId INTEGER PRIMARY KEY,
    tocEntryId INTEGER NOT NULL,
    FOREIGN KEY (lineId) REFERENCES line(id) ON DELETE CASCADE,
    FOREIGN KEY (tocEntryId) REFERENCES tocEntry(id) ON DELETE CASCADE
);

CREATE INDEX IF NOT EXISTS idx_linetoc_toc ON line_toc(tocEntryId);

-- Book acronyms table: stores alternate names/abbreviations per book
-- One row per (bookId, term) pair for efficient lookup
CREATE TABLE IF NOT EXISTS book_acronym (
    bookId INTEGER NOT NULL,
    term TEXT NOT NULL,
    PRIMARY KEY (bookId, term),
    FOREIGN KEY (bookId) REFERENCES book(id) ON DELETE CASCADE
);

-- Index to quickly find books by acronym term
CREATE INDEX IF NOT EXISTS idx_book_acronym_term ON book_acronym(term);
</file>

<file path="dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/LineQueries.sq">
-- Queries for lines

selectById:
SELECT * FROM line WHERE id = ?;

selectByBookId:
SELECT * FROM line WHERE bookId = ? ORDER BY lineIndex;

selectByBookIdRange:
SELECT * FROM line
WHERE bookId = ?
AND lineIndex >= ?
AND lineIndex <= ?
ORDER BY lineIndex;

selectByBookIdAndIndex:
SELECT * FROM line WHERE bookId = ? AND lineIndex = ?;

insert:
INSERT INTO line (bookId, lineIndex, content, tocEntryId)
VALUES (?, ?, ?, ?);

insertWithId:
INSERT INTO line (id, bookId, lineIndex, content, tocEntryId)
VALUES (?, ?, ?, ?, ?);

updateTocEntryId:
UPDATE line SET tocEntryId = ? WHERE id = ?;

delete:
DELETE FROM line WHERE id = ?;

deleteByBookId:
DELETE FROM line WHERE bookId = ?;

countByBookId:
SELECT COUNT(*) FROM line WHERE bookId = ?;

lastInsertRowId:
SELECT last_insert_rowid();
</file>

<file path="dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/LineTocQueries.sq">
-- Queries for mapping lines to their owning TOC entries

selectByLineId:
SELECT * FROM line_toc WHERE lineId = ?;

selectTocEntryIdByLineId:
SELECT tocEntryId FROM line_toc WHERE lineId = ?;

selectByBookId:
SELECT lt.lineId, lt.tocEntryId
FROM line_toc lt
JOIN line l ON l.id = lt.lineId
WHERE l.bookId = ?
ORDER BY l.lineIndex;

selectLineIdsByTocEntryId:
SELECT l.id
FROM line l
JOIN line_toc lt ON lt.lineId = l.id
WHERE lt.tocEntryId = ?
ORDER BY l.lineIndex;

insert:
INSERT INTO line_toc (lineId, tocEntryId)
VALUES (?, ?);

upsert:
INSERT INTO line_toc (lineId, tocEntryId)
VALUES (?, ?)
ON CONFLICT(lineId) DO UPDATE SET tocEntryId = excluded.tocEntryId;

deleteByLineId:
DELETE FROM line_toc WHERE lineId = ?;

deleteByBookId:
DELETE FROM line_toc WHERE lineId IN (
    SELECT l.id FROM line l WHERE l.bookId = ?
);
</file>

<file path="dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/LinkQueries.sq">
-- Queries for links

selectLinkById:
SELECT l.*, ct.name AS connectionType
FROM link l
JOIN connection_type ct ON l.connectionTypeId = ct.id
WHERE l.id = ?;

countAllLinks:
SELECT COUNT(*) FROM link;

selectLinksBySourceLineIds:
SELECT l.*, ct.name AS connectionType, b.title AS targetBookTitle, tl.content AS targetText
FROM link l
JOIN connection_type ct ON l.connectionTypeId = ct.id
JOIN book b ON l.targetBookId = b.id
JOIN line tl ON l.targetLineId = tl.id
WHERE l.sourceLineId IN ?
ORDER BY b.orderIndex;

selectLinksBySourceBook:
SELECT l.*, ct.name AS connectionType
FROM link l
JOIN connection_type ct ON l.connectionTypeId = ct.id
WHERE l.sourceBookId = ?;

selectCommentatorsByBook:
SELECT DISTINCT l.targetBookId, b.title AS targetBookTitle, a.name AS author, COUNT(*) AS linkCount
FROM link l
JOIN connection_type ct ON l.connectionTypeId = ct.id
JOIN book b ON l.targetBookId = b.id
LEFT JOIN book_author ba ON b.id = ba.bookId
LEFT JOIN author a ON ba.authorId = a.id
WHERE l.sourceBookId = ?
AND ct.name IN ('COMMENTARY', 'TARGUM')
GROUP BY l.targetBookId, b.title, a.name
ORDER BY b.orderIndex, b.title;

insert:
INSERT INTO link (sourceBookId, targetBookId, sourceLineId, targetLineId, connectionTypeId)
VALUES (?, ?, ?, ?, ?);

delete:
DELETE FROM link WHERE id = ?;

deleteByBookId:
DELETE FROM link WHERE sourceBookId = ? OR targetBookId = ?;

lastInsertRowId:
SELECT last_insert_rowid();

-- Count links by source book
countLinksBySourceBook:
SELECT COUNT(*) FROM link WHERE sourceBookId = ?;

-- Count links by target book
countLinksByTargetBook:
SELECT COUNT(*) FROM link WHERE targetBookId = ?;

-- Count links by source book and connection type
countLinksBySourceBookAndType:
SELECT COUNT(*)
FROM link l
JOIN connection_type ct ON l.connectionTypeId = ct.id
WHERE l.sourceBookId = ? AND ct.name = ?;

-- Count links by target book and connection type
countLinksByTargetBookAndType:
SELECT COUNT(*)
FROM link l
JOIN connection_type ct ON l.connectionTypeId = ct.id
WHERE l.targetBookId = ? AND ct.name = ?;
</file>

<file path="dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/PubDateQueries.sq">
-- Queries for publication dates

selectAll:
SELECT * FROM pub_date ORDER BY date;

selectById:
SELECT * FROM pub_date WHERE id = ?;

selectByDate:
SELECT * FROM pub_date WHERE date = ? LIMIT 1;

selectByBookId:
SELECT p.* FROM pub_date p
JOIN book_pub_date bp ON p.id = bp.pubDateId
WHERE bp.bookId = ?;

insert:
INSERT INTO pub_date (date)
VALUES (?)
ON CONFLICT (date) DO NOTHING;

linkBookPubDate:
INSERT INTO book_pub_date (bookId, pubDateId)
VALUES (?, ?)
ON CONFLICT (bookId, pubDateId) DO NOTHING;

delete:
DELETE FROM pub_date WHERE id = ?;

countAll:
SELECT COUNT(*) FROM pub_date;

lastInsertRowId:
SELECT last_insert_rowid();
</file>

<file path="dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/PubPlaceQueries.sq">
-- Queries for publication places

selectAll:
SELECT * FROM pub_place ORDER BY name;

selectById:
SELECT * FROM pub_place WHERE id = ?;

selectByName:
SELECT * FROM pub_place WHERE name = ? LIMIT 1;

selectByBookId:
SELECT p.* FROM pub_place p
JOIN book_pub_place bp ON p.id = bp.pubPlaceId
WHERE bp.bookId = ?;

insert:
INSERT INTO pub_place (name)
VALUES (?)
ON CONFLICT (name) DO NOTHING;

linkBookPubPlace:
INSERT INTO book_pub_place (bookId, pubPlaceId)
VALUES (?, ?)
ON CONFLICT (bookId, pubPlaceId) DO NOTHING;

delete:
DELETE FROM pub_place WHERE id = ?;

countAll:
SELECT COUNT(*) FROM pub_place;

lastInsertRowId:
SELECT last_insert_rowid();
</file>

<file path="dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/SourceQueries.sq">
-- Source queries

selectAll:
SELECT * FROM source ORDER BY name;

selectById:
SELECT * FROM source WHERE id = ?;

selectByName:
SELECT * FROM source WHERE name = ? LIMIT 1;

insert:
INSERT INTO source (name) VALUES (?);

lastInsertRowId:
SELECT last_insert_rowid();
</file>

<file path="dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/TocQueries.sq">
-- TocQueries.sq

selectByBookId:
SELECT t.*, tt.text
FROM tocEntry t
JOIN tocText tt ON t.textId = tt.id
WHERE t.bookId = ?;

selectTocById:
SELECT t.*, tt.text
FROM tocEntry t
JOIN tocText tt ON t.textId = tt.id
WHERE t.id = ?;

selectRootByBookId:
SELECT t.*, tt.text
FROM tocEntry t
JOIN tocText tt ON t.textId = tt.id
WHERE t.bookId = ? AND t.parentId IS NULL;

selectChildren:
SELECT t.*, tt.text
FROM tocEntry t
JOIN tocText tt ON t.textId = tt.id
WHERE t.parentId = ?;

selectByLineId:
SELECT t.*, tt.text
FROM tocEntry t
JOIN tocText tt ON t.textId = tt.id
WHERE t.lineId = ?;

insert:
INSERT INTO tocEntry (bookId, parentId, textId, level, lineId, isLastChild, hasChildren)
VALUES (?, ?, ?, ?, ?, ?, ?);

insertWithId:
INSERT INTO tocEntry (id, bookId, parentId, textId, level, lineId, isLastChild, hasChildren)
VALUES (?, ?, ?, ?, ?, ?, ?, ?);

updateLineId:
UPDATE tocEntry SET lineId = ? WHERE id = ?;

updateIsLastChild:
UPDATE tocEntry SET isLastChild = ? WHERE id = ?;

updateHasChildren:
UPDATE tocEntry SET hasChildren = ? WHERE id = ?;

delete:
DELETE FROM tocEntry WHERE id = ?;

deleteByBookId:
DELETE FROM tocEntry WHERE bookId = ?;

lastInsertRowId:
SELECT last_insert_rowid();
</file>

<file path="dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/TocTextQueries.sq">
-- Queries for table of contents texts

selectAll:
SELECT * FROM tocText ORDER BY text;

selectById:
SELECT * FROM tocText WHERE id = ?;

selectByText:
SELECT * FROM tocText WHERE text = ? LIMIT 1;

insert:
INSERT INTO tocText (text)
VALUES (?)
ON CONFLICT (text) DO NOTHING;

insertAndGetId:
INSERT OR IGNORE INTO tocText (text)
VALUES (?);

selectIdByText:
SELECT id FROM tocText WHERE text = ? LIMIT 1;

delete:
DELETE FROM tocText WHERE id = ?;

countAll:
SELECT COUNT(*) FROM tocText;

lastInsertRowId:
SELECT last_insert_rowid();
</file>

<file path="dao/src/commonMain/sqldelight/io/github/kdroidfilter/seforimlibrary/db/TopicQueries.sq">
-- Requ√™tes pour les topics

selectAll:
SELECT * FROM topic ORDER BY name;

selectById:
SELECT * FROM topic WHERE id = ?;

selectByName:
SELECT * FROM topic WHERE name = ? LIMIT 1;

selectByBookId:
SELECT t.* FROM topic t
JOIN book_topic bt ON t.id = bt.topicId
WHERE bt.bookId = ?
ORDER BY t.name;

insert:
INSERT INTO topic (name)
VALUES (?)
ON CONFLICT (name) DO NOTHING;

insertAndGetId:
INSERT OR IGNORE INTO topic (name)
VALUES (?);

selectIdByName:
SELECT id FROM topic WHERE name = ? LIMIT 1;

delete:
DELETE FROM topic WHERE id = ?;

countAll:
SELECT COUNT(*) FROM topic;

lastInsertRowId:
SELECT last_insert_rowid();

-- Requ√™tes pour la table de jonction book_topic

linkBookTopic:
INSERT INTO book_topic (bookId, topicId)
VALUES (?, ?)
ON CONFLICT (bookId, topicId) DO NOTHING;

unlinkBookTopic:
DELETE FROM book_topic WHERE bookId = ? AND topicId = ?;

deleteAllBookTopics:
DELETE FROM book_topic WHERE bookId = ?;

countBookTopics:
SELECT COUNT(*) FROM book_topic WHERE bookId = ?;
</file>

<file path="generator/build.gradle.kts">
plugins {
    alias(libs.plugins.multiplatform)
    alias(libs.plugins.kotlinx.serialization)
}

kotlin {
    jvmToolchain(21)

    jvm()

    sourceSets {
        commonMain.dependencies {
            api(project(":core"))
            api(project(":dao"))

            implementation(libs.kotlinx.coroutines.core)
            implementation(libs.kotlinx.coroutines.test)
            implementation(libs.kotlinx.serialization.json)
            implementation(libs.kotlinx.datetime)
            implementation(libs.kermit)
            implementation("org.jsoup:jsoup:1.17.2")
            implementation("org.slf4j:slf4j-simple:2.0.17")
        }

        commonTest.dependencies {
            implementation(kotlin("test"))
        }


        jvmMain.dependencies {
            implementation(libs.kotlinx.coroutines.swing)
            implementation(libs.sqlDelight.driver.sqlite)
            implementation(libs.lucene.core)
            implementation(libs.lucene.analysis.common)
            implementation(libs.lucene.queryparser)
            implementation(libs.lucene.highlighter)
            // (No external Hebrew morphology module required)
            implementation("com.github.luben:zstd-jni:1.5.7-6")
            implementation("org.apache.commons:commons-compress:1.26.2")
        }

    }

}

// Download latest Acronymizer DB into build/acronymizer/acronymizer.db
tasks.register<JavaExec>("downloadAcronymizer") {
    group = "application"
    description = "Download latest SeforimAcronymizer .db into build/acronymizer/acronymizer.db"

    dependsOn("jvmJar")
    mainClass.set("io.github.kdroidfilter.seforimlibrary.generator.DownloadAcronymizerKt")
    classpath = files(tasks.named("jvmJar")) + configurations.getByName("jvmRuntimeClasspath")

    jvmArgs = listOf("-Xmx512m")
}

// Download latest Otzaria source into build/otzaria/source
tasks.register<JavaExec>("downloadOtzaria") {
    group = "application"
    description = "Download latest otzaria-library zip and extract to build/otzaria/source"

    dependsOn("jvmJar")
    mainClass.set("io.github.kdroidfilter.seforimlibrary.generator.DownloadOtzariaKt")
    classpath = files(tasks.named("jvmJar")) + configurations.getByName("jvmRuntimeClasspath")

    jvmArgs = listOf("-Xmx512m")
}

// Package DB + Lucene indexes into single tar.zst and split
tasks.register<JavaExec>("packageArtifacts") {
    group = "application"
    description = "Create seforim_bundle.tar.zst (DB + indexes) with zstd and split into ~1.9GiB parts."

    dependsOn("jvmJar")
    mainClass.set("io.github.kdroidfilter.seforimlibrary.generator.PackageArtifactsKt")
    classpath = files(tasks.named("jvmJar")) + configurations.getByName("jvmRuntimeClasspath")

    // Pass optional properties if provided
    if (project.hasProperty("seforimDb")) {
        systemProperty("seforimDb", project.property("seforimDb") as String)
    }
    // Output bundle
    if (project.hasProperty("bundleOutput")) {
        systemProperty("bundleOutput", project.property("bundleOutput") as String)
    }
    // Backward-compatible: if -Poutput was provided, pass it through as legacy
    if (project.hasProperty("output")) {
        systemProperty("output", project.property("output") as String)
    }
    if (project.hasProperty("zstdLevel")) {
        systemProperty("zstdLevel", project.property("zstdLevel") as String)
    }
    if (project.hasProperty("zstdWorkers")) {
        systemProperty("zstdWorkers", project.property("zstdWorkers") as String)
    }
    if (project.hasProperty("splitPartBytes")) {
        systemProperty("splitPartBytes", project.property("splitPartBytes") as String)
    }

    jvmArgs = listOf("-Xmx512m")
}

// Build Lucene index using StandardAnalyzer
// Usage:
//   ./gradlew :generator:buildLuceneIndexDefault -PseforimDb=/path/to/seforim.db
tasks.register<JavaExec>("buildLuceneIndexDefault") {
    group = "application"
    description = "Build Lucene index using StandardAnalyzer. Requires -PseforimDb."

    dependsOn("jvmJar")
    mainClass.set("io.github.kdroidfilter.seforimlibrary.generator.BuildLuceneIndexKt")
    classpath = files(tasks.named("jvmJar")) + configurations.getByName("jvmRuntimeClasspath")

    // Pass DB path as system property recognized by the Kotlin entrypoint
    if (project.hasProperty("seforimDb")) {
        systemProperty("seforimDb", project.property("seforimDb") as String)
    } else if (System.getenv("SEFORIM_DB") != null) {
        systemProperty("SEFORIM_DB", System.getenv("SEFORIM_DB"))
    } else {
        // Default to DB under build/
        val defaultDbPath = layout.buildDirectory.file("seforim.db").get().asFile.absolutePath
        systemProperty("seforimDb", defaultDbPath)
    }

    // Prefer in-memory DB for faster reads (override with -PinMemoryDb=false)
    val inMemory = project.findProperty("inMemoryDb") != "false"
    if (inMemory) {
        systemProperty("inMemoryDb", "true")
    }

    jvmArgs = listOf(
        "-Xmx10g",
        "-XX:+UseG1GC",
        "-XX:MaxGCPauseMillis=200",
        "--enable-native-access=ALL-UNNAMED",
        "--add-modules=jdk.incubator.vector"
    )
}


// Phase 1: generate categories/books/lines only
// Usage:
//   ./gradlew :generator:generateLines -PseforimDb=/path/to.db -PsourceDir=/path/to/otzaria [-PacronymDb=/path/acronymizer.db]
tasks.register<JavaExec>("generateLines") {
    group = "application"
    description = "Phase 1: categories/books/lines only."

    dependsOn("jvmJar")
    dependsOn("downloadAcronymizer")
    mainClass.set("io.github.kdroidfilter.seforimlibrary.generator.GenerateLinesKt")
    classpath = files(tasks.named("jvmJar")) + configurations.getByName("jvmRuntimeClasspath")

    // Always provide a default DB path under build/ so no -PseforimDb is needed
    val defaultDbPath = layout.buildDirectory.file("seforim.db").get().asFile.absolutePath
    val defaultAcronymDb = layout.buildDirectory.file("acronymizer/acronymizer.db").get().asFile.absolutePath
    // In-memory DB generation enabled by default (override with -PinMemoryDb=false)
    val inMemory = project.findProperty("inMemoryDb") != "false"
    val cliDbPath = if (inMemory) ":memory:" else defaultDbPath
    // arg0: DB path only; sourceDir omitted so Kotlin will auto-download Otzaria
    args(cliDbPath)

    // Provide acronym DB via system property so Kotlin picks it up
    if (project.hasProperty("acronymDb")) {
        systemProperty("acronymDb", project.property("acronymDb") as String)
    } else {
        systemProperty("acronymDb", defaultAcronymDb)
    }

    // If in-memory DB is used, persist destination (default to build/seforim.db)
    if (inMemory) {
        if (project.hasProperty("persistDb")) {
            systemProperty("persistDb", project.property("persistDb") as String)
        } else {
            systemProperty("persistDb", defaultDbPath)
        }
    }

    jvmArgs = listOf(
        "-Xmx10g",
        "-XX:+UseG1GC",
        "-XX:MaxGCPauseMillis=200",
        "--enable-native-access=ALL-UNNAMED",
        "--add-modules=jdk.incubator.vector"
    )
}

// Phase 2: process links only
// Usage:
//   ./gradlew :generator:generateLinks -PseforimDb=/path/to.db -PsourceDir=/path/to/otzaria
tasks.register<JavaExec>("generateLinks") {
    group = "application"
    description = "Phase 2: process links only."

    dependsOn("jvmJar")
    mainClass.set("io.github.kdroidfilter.seforimlibrary.generator.GenerateLinksKt")
    classpath = files(tasks.named("jvmJar")) + configurations.getByName("jvmRuntimeClasspath")

    // Default DB path in build/
    val defaultDbPath = layout.buildDirectory.file("seforim.db").get().asFile.absolutePath
    // In-memory DB generation enabled by default (override with -PinMemoryDb=false)
    val inMemory = project.findProperty("inMemoryDb") != "false"
    val cliDbPath = if (inMemory) ":memory:" else defaultDbPath
    args(cliDbPath)

    if (inMemory) {
        if (project.hasProperty("persistDb")) {
            systemProperty("persistDb", project.property("persistDb") as String)
        } else {
            systemProperty("persistDb", defaultDbPath)
        }
        // Seed from base DB on disk by default
        if (project.hasProperty("seforimDb")) {
            systemProperty("baseDb", project.property("seforimDb") as String)
        } else {
            systemProperty("baseDb", defaultDbPath)
        }
    }

    jvmArgs = listOf(
        "-Xmx10g",
        "-XX:+UseG1GC",
        "-XX:MaxGCPauseMillis=200",
        "--enable-native-access=ALL-UNNAMED",
        "--add-modules=jdk.incubator.vector"
    )
}
</file>

<file path="generator/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/generator/Generator.kt">
package io.github.kdroidfilter.seforimlibrary.generator


import co.touchlab.kermit.Logger
import io.github.kdroidfilter.seforimlibrary.core.models.*
import io.github.kdroidfilter.seforimlibrary.dao.repository.SeforimRepository
import io.github.kdroidfilter.seforimlibrary.generator.utils.HebrewTextUtils
import kotlinx.coroutines.coroutineScope
import kotlinx.coroutines.async
import kotlinx.coroutines.awaitAll
import kotlinx.coroutines.runBlocking
import kotlinx.serialization.SerialName
import kotlinx.serialization.Serializable
import kotlinx.serialization.json.Json
import org.jsoup.Jsoup
import org.jsoup.safety.Safelist
import java.io.File
import java.nio.file.Files
import java.nio.file.Path
import java.nio.file.Paths
import kotlin.io.path.exists
import kotlin.io.path.extension
import kotlin.io.path.nameWithoutExtension
import kotlin.io.path.readText

/**
 * DatabaseGenerator is responsible for generating the Otzaria database from source files.
 * It processes directories, books, and links to create a structured database.
 *
 * @property sourceDirectory The path to the source directory containing the data files
 * @property repository The repository used to store the generated data
 */
class DatabaseGenerator(
    private val sourceDirectory: Path,
    private val repository: SeforimRepository,
    private val acronymDbPath: String? = null,
    private val textIndex: io.github.kdroidfilter.seforimlibrary.generator.lucene.TextIndexWriter? = null,
    private val lookupIndex: io.github.kdroidfilter.seforimlibrary.generator.lucene.LookupIndexWriter? = null
) {

    private val logger = Logger.withTag("DatabaseGenerator")


    private val json = Json {
        ignoreUnknownKeys = true
        coerceInputValues = true
    }
    private var nextBookId = 1L // Counter for book IDs
    private var nextLineId = 1L // Counter for line IDs
    private var nextTocEntryId = 1L // Counter for TOC entry IDs

    // Optional connection to the Acronymizer DB (opened lazily)
    private var acronymDb: java.sql.Connection? = null

    // Library root used for relative path normalization
    private lateinit var libraryRoot: Path

    // Map from library-relative book key (e.g. "◊™◊†"◊ö/◊ë◊®◊ê◊©◊ô◊™.txt") to source name (e.g. "sefariaToOtzaria")
    private val manifestSourcesByRel = mutableMapOf<String, String>()
    // Cache of source name -> id from DB
    private val sourceNameToId = mutableMapOf<String, Long>()

    // Source blacklist loaded from resources (fallback to default)
    private val sourceBlacklist: Set<String> = loadSourceBlacklistFromResources()

    // In-memory caches to accelerate link processing using available RAM
    private var booksByTitle: Map<String, Book> = emptyMap()
    private var booksById: Map<Long, Book> = emptyMap()
    // For each bookId, maps lineIndex -> lineId (0 means missing)
    private val lineIdCache = mutableMapOf<Long, LongArray>()

    // Tracks books processed from the priority list to avoid double insertion
    private val processedPriorityBookKeys = mutableSetOf<String>()

    // Overall progress across books
    private var totalBooksToProcess: Int = 0
    private var processedBooksCount: Int = 0

    // Book contents cache: maps library-relative key -> list of lines
    private val bookContentCache = mutableMapOf<String, List<String>>()


    /**
     * Generates the database by processing metadata, directories, and links.
     * This is the main entry point for the database generation process.
     */
    suspend fun generate(): Unit = coroutineScope {
        logger.i { "Starting database generation..." }
        logger.i { "Source directory: $sourceDirectory" }

        try {
            // Disable foreign keys for better performance during bulk insertion
            logger.i { "Disabling foreign keys for better performance..." }
            disableForeignKeys()

            // Lower durability for faster bulk writes (restored afterward)
            logger.i { "Setting PRAGMA synchronous=OFF for bulk generation" }
            repository.setSynchronousOff()
            logger.i { "Setting PRAGMA journal_mode=OFF for bulk generation" }
            repository.setJournalModeOff()

            // Wrap the entire generation in a single transaction for major SQLite speedups
            repository.runInTransaction {
                // Load metadata
                val metadata = loadMetadata()
                logger.i { "Metadata loaded: ${metadata.size} entries" }

                // Load sources from files_manifest.json and upsert source table
                loadSourcesFromManifest()
                precreateSourceEntries()

                // Process hierarchy
                val libraryPath = sourceDirectory.resolve("◊ê◊ï◊¶◊®◊ô◊ê")
                if (!libraryPath.exists()) {
                    throw IllegalStateException("The directory ◊ê◊ï◊¶◊®◊ô◊ê does not exist in $sourceDirectory")
                }

                // Save for relative path computations
                libraryRoot = libraryPath

                // Estimate total number of books (txt files) for progress tracking
                totalBooksToProcess = try {
                    Files.walk(libraryRoot).use { s ->
                        s.filter { Files.isRegularFile(it) && it.extension == "txt" }
                            .filter { !it.fileName.toString().substringBeforeLast('.')
                                .startsWith("◊î◊¢◊®◊ï◊™ ◊¢◊ú ") }
                            .count().toInt()
                    }
                } catch (_: Exception) { 0 }
                logger.i { "Planned to process approximately $totalBooksToProcess books" }

                // Process priority books first (if any), then process the full library
                runCatching {
                    processPriorityBooks(loadMetadata = { metadata })
                }.onFailure { e ->
                    logger.w(e) { "Failed processing priority list; continuing with full generation" }
                }

                logger.i { "üöÄ Starting to process library directory: $libraryPath" }
                // Preload all book .txt contents into RAM for faster processing
                preloadAllBookContents(libraryPath)
                processDirectory(libraryPath, null, 0, metadata)

                // Process links
                processLinks()

                // Build category closure table for fast descendant queries
                logger.i { "Building category_closure (ancestor-descendant) table..." }
                repository.rebuildCategoryClosure()

                // Finalize Lucene index if present
                runCatching { textIndex?.commit() }
                    .onSuccess { logger.i { "Lucene index commit completed" } }
                    .onFailure { e -> logger.w(e) { "Lucene index commit failed" } }
                runCatching { lookupIndex?.commit() }
                    .onSuccess { logger.i { "Lookup index commit completed" } }
                    .onFailure { e -> logger.w(e) { "Lookup index commit failed" } }
            }
            // Restore PRAGMAs after commit
            logger.i { "Re-enabling foreign keys..." }
            enableForeignKeys()
            logger.i { "Restoring PRAGMA synchronous=NORMAL" }
            repository.setSynchronousNormal()
            // Restore journal mode after commit
            logger.i { "Restoring PRAGMA journal_mode=WAL" }
            repository.setJournalModeWal()
            logger.i { "Generation completed successfully!" }
        } catch (e: Exception) {
            // Make sure to re-enable foreign keys even if an error occurs
            try {
                enableForeignKeys()
            } catch (innerEx: Exception) {
                logger.w(innerEx) { "Error re-enabling foreign keys after failure" }
            }
            try {
                repository.setSynchronousNormal()
            } catch (_: Exception) {}
            try {
                repository.setJournalModeWal()
            } catch (_: Exception) {}

            logger.e(e) { "Error during generation" }
            throw e
        }
    }

    /**
     * Phase 1: Generate categories, books, TOCs and lines only (no links).
     */
    suspend fun generateLinesOnly(): Unit = coroutineScope {
        logger.i { "Starting phase 1: categories/books/lines generation..." }
        try {
            // Performance PRAGMAs
            disableForeignKeys()
            repository.setSynchronousOff()
            repository.setJournalModeOff()

            repository.runInTransaction {
                val metadata = loadMetadata()
                // Load sources and create entries upfront
                loadSourcesFromManifest()
                precreateSourceEntries()
                val libraryPath = sourceDirectory.resolve("◊ê◊ï◊¶◊®◊ô◊ê")
                if (!libraryPath.exists()) {
                    throw IllegalStateException("The directory ◊ê◊ï◊¶◊®◊ô◊ê does not exist in $sourceDirectory")
                }
                libraryRoot = libraryPath

                totalBooksToProcess = try {
                    Files.walk(libraryRoot).use { s ->
                        s.filter { Files.isRegularFile(it) && it.extension == "txt" }
                            .filter { !it.fileName.toString().substringBeforeLast('.')
                                .startsWith("◊î◊¢◊®◊ï◊™ ◊¢◊ú ") }
                            .count().toInt()
                    }
                } catch (_: Exception) { 0 }
                logger.i { "Planned to process approximately $totalBooksToProcess books (phase 1)" }

                runCatching { processPriorityBooks(loadMetadata = { metadata }) }
                    .onFailure { e -> logger.w(e) { "Failed processing priority list; continuing with full generation (phase 1)" } }
                // Preload all book .txt contents into RAM for faster processing
                preloadAllBookContents(libraryPath)
                processDirectory(libraryPath, null, 0, metadata)

                // Build category closure after categories insertion
                logger.i { "Building category_closure table (phase 1)..." }
                repository.rebuildCategoryClosure()
            }
        } finally {
            runCatching { enableForeignKeys() }
            runCatching { repository.setSynchronousNormal() }
            runCatching { repository.setJournalModeWal() }
            logger.i { "Phase 1 completed." }
        }
    }

    /**
     * Phase 2: Process links only and update link-related flags.
     */
    suspend fun generateLinksOnly(): Unit = coroutineScope {
        logger.i { "Starting phase 2: links processing..." }
        try {
            disableForeignKeys()
            repository.setSynchronousOff()
            repository.setJournalModeOff()
            repository.runInTransaction {
                processLinks()
            }
        } finally {
            runCatching { enableForeignKeys() }
            runCatching { repository.setSynchronousNormal() }
            runCatching { repository.setJournalModeWal() }
            logger.i { "Phase 2 completed." }
        }
    }

    // Prepare caches so that link resolution uses RAM instead of round-trips
    private suspend fun ensureCachesLoaded() {
        if (booksByTitle.isEmpty()) {
            val allBooks = repository.getAllBooks()
            booksByTitle = allBooks.associateBy { it.title }
            booksById = allBooks.associateBy { it.id }
            logger.i { "Preloaded ${allBooks.size} books into memory for fast link processing" }
        }
    }

    // Ensure we have lineIndex -> lineId mapping for the given book in memory
    private suspend fun ensureLineIndexCache(bookId: Long) {
        if (lineIdCache.containsKey(bookId)) return
        val totalLines = booksById[bookId]?.totalLines ?: repository.getBook(bookId)?.totalLines ?: 0
        val arr = LongArray(totalLines.coerceAtLeast(0)) { 0L }
        // Use existing repository.getLines to load ids and indices; content is ignored here
        val lines = if (totalLines > 0) repository.getLines(bookId, 0, totalLines - 1) else emptyList()
        for (ln in lines) {
            val idx = ln.lineIndex
            if (idx >= 0 && idx < arr.size) arr[idx] = ln.id
        }
        lineIdCache[bookId] = arr
        logger.d { "Loaded ${lines.size} line id/index pairs for book $bookId into memory" }
    }

    // Lookup helper using the RAM cache
    private suspend fun getLineIdCached(bookId: Long, lineIndex: Int): Long? {
        ensureLineIndexCache(bookId)
        val arr = lineIdCache[bookId] ?: return null
        if (lineIndex < 0 || lineIndex >= arr.size) return null
        val id = arr[lineIndex]
        return if (id == 0L) null else id
    }

    // Preload all book file contents into RAM, keyed by library-relative path
    private suspend fun preloadAllBookContents(libraryPath: Path) {
        // Avoid reloading if already populated
        if (bookContentCache.isNotEmpty()) return
        logger.i { "Preloading book contents into RAM from $libraryPath ..." }
        val files = Files.walk(libraryPath).use { s ->
            s.filter { Files.isRegularFile(it) && it.extension == "txt" }
                .filter { p ->
                    // Skip notes files
                    val name = p.fileName.toString().substringBeforeLast('.')
                    if (name.startsWith("◊î◊¢◊®◊ï◊™ ◊¢◊ú ")) return@filter false
                    // Skip blacklisted sources when known
                    val rel = runCatching { toLibraryRelativeKey(p) }.getOrElse { p.fileName.toString() }
                    val src = manifestSourcesByRel[rel] ?: "Unknown"
                    if (sourceBlacklist.contains(src)) {
                        logger.d { "Skipping preload for blacklisted source '$src': $rel" }
                        return@filter false
                    }
                    true
                }
                .toList()
        }
        // Parallelize reads
        val loaded = coroutineScope {
            files.map { p ->
                async {
                    val key = toLibraryRelativeKey(p)
                    val content = p.readText(Charsets.UTF_8)
                    key to content.lines()
                }
            }.awaitAll()
        }
        for ((k, v) in loaded) bookContentCache[k] = v
        logger.i { "Preloaded ${bookContentCache.size} books into RAM" }
    }

    /**
     * Loads book metadata from the metadata.json file.
     * Attempts to parse the file in different formats (Map or List).
     *
     * @return A map of book titles to their metadata
     */
    private suspend fun loadMetadata(): Map<String, BookMetadata> {
        val metadataFile = sourceDirectory.resolve("metadata.json")
        return if (metadataFile.exists()) {
            val content = metadataFile.readText()
            try {
                // Try to parse as Map first (original format)
                json.decodeFromString<Map<String, BookMetadata>>(content)
            } catch (e: Exception) {
                // If that fails, try to parse as List and convert to Map
                try {
                    val metadataList = json.decodeFromString<List<BookMetadata>>(content)
                    logger.i { "Parsed metadata as List with ${metadataList.size} entries" }
                    // Convert list to map using title as key
                    metadataList.associateBy { it.title }
                } catch (e: Exception) {
                    logger.i(e) { "Failed to parse metadata.json" }
                    emptyMap()
                }
            }
        } else {
            logger.w { "Metadata file metadata.json not found" }
            emptyMap()
        }
    }

    @Serializable
    private data class ManifestEntry(
        val hash: String? = null
    )

    /**
     * Loads `files_manifest.json` and builds a mapping from library-relative path
     * (under ◊ê◊ï◊¶◊®◊ô◊ê) to a source name (top-level directory of the manifest entry).
     */
    private suspend fun loadSourcesFromManifest() {
        manifestSourcesByRel.clear()
        // Prefer manifest in the provided source directory; fallback to repo path if present
        val primary = sourceDirectory.resolve("files_manifest.json")
        val fallback = Paths.get("otzaria-library/files_manifest.json")
        val manifestPath = when {
            primary.exists() -> primary
            fallback.exists() -> fallback
            else -> null
        }
        if (manifestPath == null) {
            logger.w { "files_manifest.json not found; assigning source 'Unknown' to all books" }
            return
        }
        runCatching {
            val content = manifestPath.readText()
            val map = json.decodeFromString<Map<String, ManifestEntry>>(content)
            // For every manifest key, if it contains "/◊ê◊ï◊¶◊®◊ô◊ê/", index the subpath after it
            for ((path, _) in map) {
                val parts = path.split('/')
                if (parts.isEmpty()) continue
                val sourceName = parts.first()
                val idx = parts.indexOf("◊ê◊ï◊¶◊®◊ô◊ê")
                if (idx < 0 || idx == parts.size - 1) continue
                val rel = parts.drop(idx + 1).joinToString("/")
                // Keep first assignment, warn on duplicates
                val prev = manifestSourcesByRel.putIfAbsent(rel, sourceName)
                if (prev != null && prev != sourceName) {
                    logger.w { "Duplicate source mapping for '$rel': existing=$prev new=$sourceName; keeping existing" }
                }
            }
            logger.i { "Loaded ${manifestSourcesByRel.size} book‚Üísource mappings from manifest" }
        }.onFailure { e ->
            logger.w(e) { "Failed to parse files_manifest.json; sources will be 'Unknown'" }
        }
    }

    /**
     * Ensure all known source names from manifest are present in DB, including 'Unknown'.
     */
    private suspend fun precreateSourceEntries() {
        // Always ensure 'Unknown' exists
        val unknownId = repository.insertSource("Unknown")
        sourceNameToId["Unknown"] = unknownId
        // Insert all discovered sources
        val uniqueSources = manifestSourcesByRel.values.toSet()
        for (name in uniqueSources) {
            val id = repository.insertSource(name)
            sourceNameToId[name] = id
        }
        logger.i { "Prepared ${sourceNameToId.size} sources in DB" }
    }


    /**
     * Processes a directory recursively, creating categories and books.
     *
     * @param directory The directory to process
     * @param parentCategoryId The ID of the parent category, if any
     * @param level The current level in the directory hierarchy
     * @param metadata The metadata for books
     */
    private suspend fun processDirectory(
        directory: Path,
        parentCategoryId: Long?,
        level: Int,
        metadata: Map<String, BookMetadata>
    ) {
        logger.i { "=== Processing directory: ${directory.fileName} with parentCategoryId: $parentCategoryId (level: $level) ===" }

        Files.list(directory).use { stream ->
            val entries = stream.sorted { a, b ->
                a.fileName.toString().compareTo(b.fileName.toString())
            }.toList()

            logger.d { "Found ${entries.size} entries in directory ${directory.fileName}" }

            for (entry in entries) {
                when {
                    Files.isDirectory(entry) -> {
                        logger.d { "Processing subdirectory: ${entry.fileName} with parentId: $parentCategoryId" }
                        val categoryId = createCategory(entry, parentCategoryId, level)
                        logger.i { "‚úÖ Created category '${entry.fileName}' with ID: $categoryId (parent: $parentCategoryId)" }
                        processDirectory(entry, categoryId, level + 1, metadata)
                    }

                    Files.isRegularFile(entry) && entry.extension == "txt" -> {
                        // Skip if already processed from the priority list
                        val key = toLibraryRelativeKey(entry)
                        if (processedPriorityBookKeys.contains(key)) {
                            logger.i { "‚è≠Ô∏è Skipping already-processed priority book: $key" }
                            continue
                        }
                        // Skip companion notes files named '◊î◊¢◊®◊ï◊™ ◊¢◊ú <title>.txt'.
                        val fname = entry.fileName.toString()
                        val titleNoExt = fname.substringBeforeLast('.')
                        if (titleNoExt.startsWith("◊î◊¢◊®◊ï◊™ ◊¢◊ú ")) {
                            logger.i { "üìù Skipping notes file '$fname' (will be attached to base book if present)" }
                            continue
                        }
                        if (parentCategoryId == null) {
                            logger.w { "‚ùå Book found without category: $entry" }
                            continue
                        }
                        logger.i { "üìö Processing book ${entry.fileName} with categoryId: $parentCategoryId" }
                        createAndProcessBook(entry, parentCategoryId, metadata)
                    }

                    else -> {
                        logger.d { "Skipping entry: ${entry.fileName} (not a supported file type)" }
                    }
                }
            }
        }
        logger.i { "=== Finished processing directory: ${directory.fileName} ===" }
    }

    /**
     * Creates a category in the database.
     *
     * @param path The path representing the category
     * @param parentId The ID of the parent category, if any
     * @param level The level in the category hierarchy
     * @return The ID of the created category
     */
    private suspend fun createCategory(
        path: Path,
        parentId: Long?,
        level: Int
    ): Long {
        val title = path.fileName.toString()
        logger.i { "üèóÔ∏è Creating category: '$title' (level $level, parent: $parentId)" }

        val category = Category(
            parentId = parentId,
            title = title,
            level = level
        )

        val insertedId = repository.insertCategory(category)
        logger.i { "‚úÖ Category '$title' created with ID: $insertedId" }

        // Additional verification
        val insertedCategory = repository.getCategory(insertedId)
        if (insertedCategory == null) {
            // Changed from error to warning level to reduce unnecessary error logs
            logger.w { "‚ùå WARNING: Unable to retrieve the category that was just inserted (ID: $insertedId)" }
        } else {
            logger.d { "‚úÖ Verification: category retrieved with ID: ${insertedCategory.id}, parent: ${insertedCategory.parentId}" }
        }

        return insertedId
    }


    /**
     * Creates a book in the database and processes its content.
     *
     * @param path The path to the book file
     * @param categoryId The ID of the category the book belongs to
     * @param metadata The metadata for the book
     */
    private suspend fun createAndProcessBook(
        path: Path,
        categoryId: Long,
        metadata: Map<String, BookMetadata>,
        isBaseBook: Boolean = false
    ) {
        val filename = path.fileName.toString()
        val title = filename.substringBeforeLast('.')
        val meta = metadata[title]

        logger.i { "Processing book: $title with categoryId: $categoryId" }

        // Apply source blacklist
        val srcName = getSourceNameFor(path)
        if (sourceBlacklist.contains(srcName)) {
            logger.i { "‚õî Skipping '$title' from blacklisted source '$srcName'" }
            processedBooksCount += 1
            val pct = if (totalBooksToProcess > 0) (processedBooksCount * 100 / totalBooksToProcess) else 0
            logger.i { "Books progress: $processedBooksCount/$totalBooksToProcess (${pct}%)" }
            return
        }

        // Assign a unique ID to this book
        val currentBookId = nextBookId++
        logger.d { "Assigning ID $currentBookId to book '$title' with categoryId: $categoryId" }

        // Create author list if author is available in metadata
        val authors = meta?.author?.let { authorName ->
            listOf(Author(name = authorName))
        } ?: emptyList()

        // Create publication places list if pubPlace is available in metadata
        val pubPlaces = meta?.pubPlace?.let { pubPlaceName ->
            listOf(PubPlace(name = pubPlaceName))
        } ?: emptyList()

        // Create publication dates list if pubDate is available in metadata
        val pubDates = meta?.pubDate?.let { pubDateValue ->
            listOf(PubDate(date = pubDateValue))
        } ?: emptyList()

        // Detect companion notes file named '◊î◊¢◊®◊ï◊™ ◊¢◊ú <title>.txt' in the same directory
        val notesContent: String? = runCatching {
            val dir = path.parent
            val notesTitle = "◊î◊¢◊®◊ï◊™ ◊¢◊ú $title"
            val candidate = dir.resolve("$notesTitle.txt")
            if (Files.isRegularFile(candidate)) {
                // Prefer preloaded cache if available
                val key = toLibraryRelativeKey(candidate)
                val lines = bookContentCache[key]
                if (lines != null) lines.joinToString("\n") else candidate.readText(Charsets.UTF_8)
            } else null
        }.getOrNull()

        val sourceId = resolveSourceIdFor(path)
        val book = Book(
            id = currentBookId,
            categoryId = categoryId,
            sourceId = sourceId,
            title = title,
            authors = authors,
            pubPlaces = pubPlaces,
            pubDates = pubDates,
            heShortDesc = meta?.heShortDesc,
            notesContent = notesContent,
            order = meta?.order ?: 999f,
            topics = extractTopics(path),
            isBaseBook = isBaseBook
        )

        logger.d { "Inserting book '${book.title}' with ID: ${book.id} and categoryId: ${book.categoryId}" }
        val insertedBookId = repository.insertBook(book)

        // ‚úÖ Important verification: ensure that ID and categoryId are correct
        val insertedBook = repository.getBook(insertedBookId)
        if (insertedBook?.categoryId != categoryId) {
            logger.w { "WARNING: Book inserted with wrong categoryId! Expected: $categoryId, Got: ${insertedBook?.categoryId}" }
            // Correct the categoryId if necessary
            repository.updateBookCategoryId(insertedBookId, categoryId)
        }

        logger.d { "Book '${book.title}' inserted with ID: $insertedBookId and categoryId: $categoryId" }

        // Insert acronyms for this book if an Acronymizer DB is available
        try {
            val terms = fetchAcronymsForTitle(title)
            if (terms.isNotEmpty()) {
                repository.bulkInsertBookAcronyms(insertedBookId, terms)
                logger.i { "Inserted ${terms.size} acronyms for '${title}'" }
            }
        } catch (e: Exception) {
            logger.w(e) { "Failed to insert acronyms for '$title'" }
        }

        // Populate Lucene title index (title + acronyms + topics)
        runCatching {
            // Always index exact title
            textIndex?.addBookTitleTerm(insertedBookId, categoryId, title, title)
            // Also index sanitized variant if different
            val titleSan = sanitizeAcronymTerm(title)
            if (titleSan.isNotBlank() && !titleSan.equals(title, ignoreCase = true)) {
                textIndex?.addBookTitleTerm(insertedBookId, categoryId, title, titleSan)
            }
            // Acronyms
            val acronyms = runCatching { fetchAcronymsForTitle(title) }.getOrDefault(emptyList())
            for (t in acronyms) textIndex?.addBookTitleTerm(insertedBookId, categoryId, title, t)
            // Topics (if present)
            val topicTerms = book.topics
                .asSequence()
                .map { sanitizeAcronymTerm(it.name) }
                .map { it.trim() }
                .filter { it.isNotEmpty() }
                .distinct()
                .toList()
            for (t in topicTerms) textIndex?.addBookTitleTerm(insertedBookId, categoryId, title, t)
        }.onFailure { e ->
            logger.w(e) { "Failed to index book title terms for '$title'" }
        }

        // Populate Lookup index (books + acronyms + topics)
        runCatching {
            val terms = buildList {
                add(title)
                val tSan = sanitizeAcronymTerm(title)
                if (tSan.isNotBlank() && !tSan.equals(title, ignoreCase = true)) add(tSan)
                addAll(runCatching { fetchAcronymsForTitle(title) }.getOrDefault(emptyList()))
                // topics from the book model
                addAll(
                    book.topics
                        .asSequence()
                        .map { sanitizeAcronymTerm(it.name) }
                        .map { it.trim() }
                        .filter { it.isNotEmpty() }
                        .distinct()
                        .toList()
                )
            }
            lookupIndex?.addBook(insertedBookId, categoryId, title, terms)
        }.onFailure { e -> logger.w(e) { "Failed to index book lookup for '$title'" } }

        // Process content of the book
        processBookContent(path, insertedBookId, title, categoryId)

        // Book-level progress
        processedBooksCount += 1
        val pct = if (totalBooksToProcess > 0) (processedBooksCount * 100 / totalBooksToProcess) else 0
        logger.i { "Books progress: $processedBooksCount/$totalBooksToProcess (${pct}%)" }
    }

    /**
     * Processes the content of a book, extracting lines and TOC entries.
     *
     * @param path The path to the book file
     * @param bookId The ID of the book in the database
     */
    private suspend fun processBookContent(path: Path, bookId: Long, bookTitle: String, categoryId: Long) = coroutineScope {
        logger.d { "Processing content for book ID: $bookId" }
        logger.i { "Processing content of book ID: $bookId (ID generated by the database)" }

        // Prefer preloaded content from RAM if available
        val key = toLibraryRelativeKey(path)
        val lines = bookContentCache[key] ?: run {
            val content = path.readText(Charsets.UTF_8)
            content.lines()
        }
        logger.i { "Number of lines: ${lines.size}" }

        // Process each line one by one, handling TOC entries as we go
        processLinesWithTocEntries(bookId, bookTitle, categoryId, lines)

        // Update the total number of lines
        repository.updateBookTotalLines(bookId, lines.size)

        logger.i { "Content processed successfully for book ID: $bookId (ID generated by the database)" }
    }


    /**
     * Processes lines of a book, identifying and creating TOC entries.
     *
     * @param bookId The ID of the book in the database
     * @param lines The lines of the book content
     */
    private suspend fun processLinesWithTocEntries(bookId: Long, bookTitle: String, categoryId: Long, lines: List<String>) {
        logger.d { "Processing lines and TOC entries together for book ID: $bookId" }

        // Structure pour stocker toutes les entr√©es TOC cr√©√©es
        data class TocEntryData(
            val id: Long,
            val parentId: Long?,
            val level: Int,
            val text: String,
            val lineIndex: Int
        )

        val allTocEntries = mutableListOf<TocEntryData>()
        val parentStack = mutableMapOf<Int, Long>()
        val entriesByParent = mutableMapOf<Long?, MutableList<Long>>()
        var currentOwningTocEntryId: Long? = null
        val lineTocBuffer = ArrayList<Pair<Long, Long>>(minOf(lines.size, 200_000))

        // PREMI√àRE PASSE : Cr√©er toutes les entr√©es et lignes
        for ((lineIndex, line) in lines.withIndex()) {
            val plainText = cleanHtml(line)
            val level = detectHeaderLevel(line)

            if (level > 0) {
                if (plainText.isBlank()) {
                    logger.d { "‚ö†Ô∏è Skipping empty header at level $level (line $lineIndex)" }
                    parentStack.remove(level)
                    continue
                }

                val parentId = (level - 1 downTo 1).firstNotNullOfOrNull { parentStack[it] }
                val currentTocEntryId = nextTocEntryId++
                val currentLineId = nextLineId++

                // Stocker l'info de cette entr√©e pour la deuxi√®me passe
                allTocEntries.add(TocEntryData(
                    id = currentTocEntryId,
                    parentId = parentId,
                    level = level,
                    text = plainText,
                    lineIndex = lineIndex
                ))

                // Cr√©er l'entr√©e TOC avec hasChildren = false par d√©faut
                val tocEntry = TocEntry(
                    id = currentTocEntryId,
                    bookId = bookId,
                    parentId = parentId,
                    text = plainText,
                    level = level,
                    lineId = null,
                    isLastChild = false,
                    hasChildren = false  // Par d√©faut, sera mis √† jour dans la deuxi√®me passe
                )

                val tocEntryId = repository.insertTocEntry(tocEntry)
                parentStack[level] = tocEntryId
                entriesByParent.getOrPut(parentId) { mutableListOf() }.add(tocEntryId)
                currentOwningTocEntryId = tocEntryId

                val lineId = repository.insertLine(
                    Line(
                        id = currentLineId,
                        bookId = bookId,
                        lineIndex = lineIndex,
                        content = line
                    )
                )
                repository.updateTocEntryLineId(tocEntryId, lineId)
                repository.updateLineTocEntry(lineId, tocEntryId)
                // Buffer this mapping instead of writing immediately
                lineTocBuffer.add(lineId to tocEntryId)
                if (lineTocBuffer.size >= 200_000) {
                    repository.bulkUpsertLineToc(lineTocBuffer)
                    lineTocBuffer.clear()
                }
                // Index heading line
                runCatching {
                    textIndex?.addLine(
                        bookId = bookId,
                        bookTitle = bookTitle,
                        categoryId = categoryId,
                        lineId = lineId,
                        lineIndex = lineIndex,
                        normalizedText = plainText,
                        rawPlainText = plainText
                    )
                }.onFailure { e -> logger.w(e) { "Failed to index heading line $lineId in book $bookId" } }

                // Index TOC for lookup
                runCatching {
                    lookupIndex?.addToc(
                        tocId = tocEntryId,
                        bookId = bookId,
                        categoryId = categoryId,
                        bookTitle = bookTitle,
                        text = plainText,
                        level = level
                    )
                }.onFailure { e -> logger.w(e) { "Failed to index TOC $tocEntryId for book $bookId" } }
            } else {
                // Regular line
                val currentLineId = nextLineId++
                val insertedLineId = repository.insertLine(
                    Line(
                        id = currentLineId,
                        bookId = bookId,
                        lineIndex = lineIndex,
                        content = line
                    )
                )
                // Buffer mapping for regular line if there is a current owner
                currentOwningTocEntryId?.let { ownerId ->
                    lineTocBuffer.add(insertedLineId to ownerId)
                    if (lineTocBuffer.size >= 200_000) {
                        repository.bulkUpsertLineToc(lineTocBuffer)
                        lineTocBuffer.clear()
                    }
                }
                // Index regular line
                runCatching {
                    textIndex?.addLine(
                        bookId = bookId,
                        bookTitle = bookTitle,
                        categoryId = categoryId,
                        lineId = insertedLineId,
                        lineIndex = lineIndex,
                        normalizedText = plainText,
                        rawPlainText = plainText
                    )
                }.onFailure { e -> logger.w(e) { "Failed to index line $insertedLineId in book $bookId" } }
            }

            if (lineIndex % 1000 == 0) {
                val pct = if (lines.isNotEmpty()) (lineIndex * 100 / lines.size) else 0
                logger.i { "Book $bookId '$bookTitle': $lineIndex/${lines.size} lines (${pct}%)" }
            }
        }

        // Flush buffered line‚Üítoc mappings in bulk
        repository.bulkUpsertLineToc(lineTocBuffer)

        // DEUXI√àME PASSE : Mettre √† jour isLastChild et hasChildren
        logger.d { "Updating isLastChild and hasChildren for book ID: $bookId" }

        // Cr√©er un set des IDs qui ont des enfants
        val parentIds = allTocEntries.mapNotNull { it.parentId }.toSet()

        // Mettre √† jour hasChildren pour les entr√©es qui ont des enfants
        for (entry in allTocEntries) {
            if (entry.id in parentIds) {
                logger.d { "Updating TOC entry ${entry.id} as having children" }
                repository.updateTocEntryHasChildren(entry.id, true)
            }
        }

        // Mettre √† jour isLastChild
        for ((parentId, children) in entriesByParent) {
            if (children.isNotEmpty()) {
                val lastChildId = children.last()
                logger.d { "Marking TOC entry $lastChildId as last child of parent $parentId" }
                repository.updateTocEntryIsLastChild(lastChildId, true)
            }
        }

        logger.i { "‚úÖ Finished processing lines and TOC entries for book ID: $bookId" }
        logger.i { "   Total TOC entries: ${allTocEntries.size}" }
        logger.i { "   Entries with children: ${parentIds.size}" }
    }

    private fun cleanHtml(html: String): String {
        val cleaned = Jsoup.clean(html, Safelist.none())
            .trim()
            .replace("\\s+".toRegex(), " ")
        val withoutMaqaf = HebrewTextUtils.replaceMaqaf(cleaned, " ")
        return HebrewTextUtils.removeAllDiacritics(withoutMaqaf)
    }


    private fun detectHeaderLevel(line: String): Int {
        return when {
            line.startsWith("<h1", ignoreCase = true) -> 1
            line.startsWith("<h2", ignoreCase = true) -> 2
            line.startsWith("<h3", ignoreCase = true) -> 3
            line.startsWith("<h4", ignoreCase = true) -> 4
            line.startsWith("<h5", ignoreCase = true) -> 5
            line.startsWith("<h6", ignoreCase = true) -> 6
            else -> 0
        }
    }

    // ===== Priority handling =====

    /**
     * Reads the priority list from resources and returns normalized relative paths under the library root.
     */
    private fun loadPriorityList(): List<String> {
        return try {
            val stream = this::class.java.classLoader.getResourceAsStream("priority.txt")
                ?: return emptyList()
            stream.bufferedReader(Charsets.UTF_8).use { reader ->
                reader.lineSequence()
                    .map { it.trim() }
                    .filter { it.isNotEmpty() && !it.startsWith("#") }
                    .map { raw ->
                        // Normalize separators
                        var s = raw.replace('\\', '/')
                        // Remove BOM if present
                        if (s.isNotEmpty() && s[0].code == 0xFEFF) s = s.substring(1)
                        // Remove leading slash
                        s = s.removePrefix("/")
                        // Try to start from '◊ê◊ï◊¶◊®◊ô◊ê' if present
                        val idx = s.indexOf("◊ê◊ï◊¶◊®◊ô◊ê")
                        if (idx >= 0) s = s.substring(idx + "◊ê◊ï◊¶◊®◊ô◊ê".length).removePrefix("/")
                        s
                    }
                    .filter { it.endsWith(".txt", ignoreCase = true) }
                    .toList()
            }
        } catch (e: Exception) {
            logger.w(e) { "Unable to read priority.txt from resources" }
            emptyList()
        }
    }

    /**
     * Processes books listed in priority.txt before the normal directory traversal.
     * Ensures categories exist and records processed books to avoid duplicates.
     */
    private suspend fun processPriorityBooks(loadMetadata: () -> Map<String, BookMetadata>) {
        val entries = loadPriorityList()
        if (entries.isEmpty()) {
            logger.i { "No priority entries found" }
            return
        }

        logger.i { "Processing ${entries.size} priority entries first" }
        val metadata = loadMetadata()

        outer@ for ((idx, relative) in entries.withIndex()) {
            // Build the absolute path under the library root
            val parts = relative.split('/').filter { it.isNotEmpty() }
            if (parts.isEmpty()) continue

            // Last part is the book filename, everything before are categories
            val categories = if (parts.size > 1) parts.dropLast(1) else emptyList()
            val bookFileName = parts.last()
            // Skip notes-only entries from priority list
            if (bookFileName.substringBeforeLast('.').startsWith("◊î◊¢◊®◊ï◊™ ◊¢◊ú ")) {
                logger.i { "‚è≠Ô∏è Skipping notes file in priority list: $bookFileName" }
                continue@outer
            }

            // Fold into actual filesystem path
            var currentPath = libraryRoot
            for (p in categories) currentPath = currentPath.resolve(p)
            val bookPath = currentPath.resolve(bookFileName)

            if (!Files.isRegularFile(bookPath)) {
                logger.w { "Priority entry ${idx + 1}/${entries.size}: file not found: $bookPath" }
                continue@outer
            }

            // Avoid processing duplicates listed multiple times
            val key = toLibraryRelativeKey(bookPath)
            if (processedPriorityBookKeys.contains(key)) {
                logger.d { "Priority entry ${idx + 1}/${entries.size}: already processed (dup in list): $key" }
                continue@outer
            }

            // Ensure categories exist and get the final parent category id
            var parentId: Long? = null
            var level = 0
            var catPath = libraryRoot
            for (cat in categories) {
                catPath = catPath.resolve(cat)
                parentId = createCategory(catPath, parentId, level)
                level += 1
            }

            if (parentId == null) {
                logger.w { "Priority entry ${idx + 1}/${entries.size}: missing parent category for $bookPath; skipping" }
                continue@outer
            }

            logger.i { "‚≠ê Priority ${idx + 1}/${entries.size}: processing $bookFileName under categories ${categories.joinToString("/")}" }
            createAndProcessBook(bookPath, parentId, metadata, isBaseBook = true)

            // Mark as processed to avoid double insertion during full traversal
            processedPriorityBookKeys.add(key)
        }
    }

    /**
     * Compute a normalized key for a book file relative to the library root.
     */
    private fun toLibraryRelativeKey(file: Path): String {
        return try {
            val rel = libraryRoot.relativize(file).toString().replace('\\', '/')
            rel
        } catch (_: Exception) {
            // Fallback to filename
            file.fileName.toString()
        }
    }

    // Resolve a source id for a book file using the manifest mapping
    private suspend fun resolveSourceIdFor(file: Path): Long {
        val rel = toLibraryRelativeKey(file)
        val sourceName = manifestSourcesByRel[rel] ?: "Unknown"
        val cached = sourceNameToId[sourceName]
        if (cached != null) return cached
        val id = repository.insertSource(sourceName)
        sourceNameToId[sourceName] = id
        return id
    }

    private fun getSourceNameFor(file: Path): String {
        val rel = toLibraryRelativeKey(file)
        return manifestSourcesByRel[rel] ?: "Unknown"
    }

    private fun loadSourceBlacklistFromResources(): Set<String> {
        val fallback = setOf("wiki_jewish_books")
        return try {
            val resourceNames = listOf("source-blacklist.txt", "/source-blacklist.txt")
            val cl = Thread.currentThread().contextClassLoader
            val stream = resourceNames.asSequence()
                .mapNotNull { name ->
                    cl?.getResourceAsStream(name) ?: DatabaseGenerator::class.java.getResourceAsStream(name)
                }
                .firstOrNull()
            if (stream == null) return fallback
            stream.bufferedReader(Charsets.UTF_8).use { br ->
                br.lineSequence()
                    .map { it.trim() }
                    .filter { it.isNotEmpty() && !it.startsWith("#") }
                    .toSet()
            }.ifEmpty { fallback }
        } catch (e: Exception) {
            Logger.withTag("DatabaseGenerator").w(e) { "Failed to load source-blacklist.txt; using fallback" }
            fallback
        }
    }

    /**
     * Processes all link files in the links directory.
     * Links connect lines between different books.
     */
    private suspend fun processLinks() {
        // Load caches once so most lookups stay in memory
        ensureCachesLoaded()
        val linksDir = sourceDirectory.resolve("links")
        if (!linksDir.exists()) {
            logger.w { "Links directory not found" }
            return
        }

        // Count links before processing
        val linksBefore = repository.countLinks()
        logger.d { "Links in database before processing: $linksBefore" }

        logger.i { "Loading all link JSON files into RAM..." }
        // Preload all links JSON into memory to minimize IO
        val linkFiles = Files.list(linksDir).use { s -> s.filter { it.extension == "json" }.toList() }
        val linksByBook = coroutineScope {
            linkFiles.map { file ->
                async {
                    val bookTitle = file.nameWithoutExtension.removeSuffix("_links")
                    val content = file.readText()
                    val links = parseLinksFromJson(content, bookTitle)
                    bookTitle to links
                }
            }.mapNotNull { deferred ->
                runCatching { deferred.await() }
                    .onFailure { e -> logger.w(e) { "Failed to preload links from file" } }
                    .getOrNull()
            }.toMap(mutableMapOf())
        }

        logger.i { "Processing links from RAM..." }
        var totalLinks = 0
        for ((bookTitle, links) in linksByBook) {
            val processedLinks = processLinksForBook(bookTitle, links)
            totalLinks += processedLinks
            logger.d { "Processed $processedLinks links for $bookTitle, total so far: $totalLinks" }
        }

        // Count links after processing
        val linksAfter = repository.countLinks()
        logger.d { "Links in database after processing: $linksAfter" }
        logger.d { "Added ${linksAfter - linksBefore} links to the database" }

        logger.i { "Total of $totalLinks links processed" }

        // Update the book_has_links table
        updateBookHasLinksTable()
    }

    /**
     * Processes a single link file, creating links between books.
     *
     * @param linkFile The path to the link file
     * @return The number of links successfully processed
     */
    private suspend fun processLinkFile(linkFile: Path): Int {
        val bookTitle = linkFile.nameWithoutExtension.removeSuffix("_links")
        logger.d { "Processing link file for book: $bookTitle" }

        // Find the source book (use RAM cache)
        val sourceBook = booksByTitle[bookTitle]

        if (sourceBook == null) {
            logger.w { "Source book not found for links: $bookTitle" }
            return 0
        }
        logger.d { "Found source book with ID: ${sourceBook.id}" }

        try {
            val content = linkFile.readText()
            logger.d { "Link file content length: ${content.length}" }
            val links = parseLinksFromJson(content, bookTitle)
            logger.d { "Decoded ${links.size} links from file" }
            var processed = 0

            for ((index, linkData) in links.withIndex()) {
                try {
                    // Find the target book
                    // Handle paths with backslashes
                    val path = linkData.path_2
                    val targetTitle = if (path.contains('\\')) {
                        // Extract the last component of a backslash-separated path
                        val lastComponent = path.split('\\').last()
                        // Remove file extension if present
                        lastComponent.substringBeforeLast('.', lastComponent)
                    } else {
                        // Use the standard path handling for forward slash paths
                        val targetPath = Paths.get(path)
                        targetPath.fileName.toString().substringBeforeLast('.')
                    }
                    logger.d { "Link ${index + 1}/${links.size} - Target book title: $targetTitle" }

                    // Try to find the target book (use RAM cache)
                    val targetBook = booksByTitle[targetTitle]
                    if (targetBook == null) {
                        // Enhanced logging for debugging
                        logger.i { "Link ${index + 1}/${links.size} - Target book not found: $targetTitle" }
                        logger.i { "Original path: ${linkData.path_2}" }
                        continue
                    }
                    logger.d { "Using target book with ID: ${targetBook.id}" }

                    // Find the lines
                    // Adjust indices from 1-based to 0-based
                    val sourceLineIndex = (linkData.line_index_1.toInt() - 1).coerceAtLeast(0)
                    val targetLineIndex = (linkData.line_index_2.toInt() - 1).coerceAtLeast(0)

                    logger.d { "Looking for source line at index: $sourceLineIndex (original: ${linkData.line_index_1}) in book ${sourceBook.id}" }

                    // Try to find the source line (use RAM cache)
                    val sourceLineId = getLineIdCached(sourceBook.id, sourceLineIndex)
                    if (sourceLineId == null) {
                        logger.d { "Source line not found at index: $sourceLineIndex, skipping this link but continuing with others" }
                        continue
                    }
                    logger.d { "Using source line with ID: $sourceLineId" }

                    logger.d { "Looking for target line at index: $targetLineIndex (original: ${linkData.line_index_2}) in book ${targetBook.id}" }

                    // Try to find the target line (use RAM cache)
                    val targetLineId = getLineIdCached(targetBook.id, targetLineIndex)
                    if (targetLineId == null) {
                        logger.d { "Target line not found at index: $targetLineIndex, skipping this link but continuing with others" }
                        continue
                    }
                    logger.d { "Using target line with ID: $targetLineId" }

                    val link = Link(
                        sourceBookId = sourceBook.id,
                        targetBookId = targetBook.id,
                        sourceLineId = sourceLineId,
                        targetLineId = targetLineId,
                        connectionType = ConnectionType.fromString(linkData.connectionType)
                    )

                    logger.d { "Inserting link from book ${sourceBook.id} to book ${targetBook.id}" }
                    val linkId = repository.insertLink(link)
                    logger.d { "Link inserted with ID: $linkId" }
                    processed++
                } catch (e: Exception) {
                    // Changed from error to debug level to reduce unnecessary error logs
                    logger.d(e) { "Error processing link: ${linkData.heRef_2}" }
                    logger.d { "Error processing link: ${e.message}" }
                }
            }
            logger.d { "Processed $processed links out of ${links.size}" }
            return processed
        } catch (e: Exception) {
            // Changed from error to warning level to reduce unnecessary error logs
            logger.w(e) { "Error processing link file: ${linkFile.fileName}" }
            logger.d { "Error processing link file: ${e.message}" }
            return 0
        }
    }

    /**
     * Processes links that were preloaded in memory for a given source book.
     */
    private suspend fun processLinksForBook(bookTitle: String, links: List<LinkData>): Int {
        val sourceBook = booksByTitle[bookTitle]
        if (sourceBook == null) {
            logger.w { "Source book not found for links: $bookTitle" }
            return 0
        }
        var processed = 0
        for ((index, linkData) in links.withIndex()) {
            try {
                val path = linkData.path_2
                val targetTitle = if (path.contains('\\')) {
                    val lastComponent = path.split('\\').last()
                    lastComponent.substringBeforeLast('.', lastComponent)
                } else {
                    val targetPath = Paths.get(path)
                    targetPath.fileName.toString().substringBeforeLast('.')
                }

                val targetBook = booksByTitle[targetTitle]
                if (targetBook == null) {
                    logger.i { "Link ${index + 1}/${links.size} - Target book not found: $targetTitle" }
                    logger.i { "Original path: ${linkData.path_2}" }
                    continue
                }

                val sourceLineIndex = (linkData.line_index_1.toInt() - 1).coerceAtLeast(0)
                val targetLineIndex = (linkData.line_index_2.toInt() - 1).coerceAtLeast(0)

                val sourceLineId = getLineIdCached(sourceBook.id, sourceLineIndex)
                if (sourceLineId == null) continue

                val targetLineId = getLineIdCached(targetBook.id, targetLineIndex)
                if (targetLineId == null) continue

                val link = Link(
                    sourceBookId = sourceBook.id,
                    targetBookId = targetBook.id,
                    sourceLineId = sourceLineId,
                    targetLineId = targetLineId,
                    connectionType = ConnectionType.fromString(linkData.connectionType)
                )
                repository.insertLink(link)
                processed++
            } catch (_: Exception) {
                // Skip malformed entries but continue
            }
        }
        return processed
    }

    /**
     * Extracts topics from the file path.
     * Topics are derived from the directory structure.
     *
     * @param path The path to the book file
     * @return A list of topics extracted from the path
     */
    private fun extractTopics(path: Path): List<Topic> {
        // Extract topics from the path
        val parts = path.toString().split(File.separator)
        val topicNames = parts.dropLast(1).takeLast(2)

        return topicNames.map { name ->
            Topic(name = name)
        }
    }

    /**
     * Fetch and sanitize acronym terms for a given book title from the Acronymizer DB.
     */
    private fun fetchAcronymsForTitle(title: String): List<String> {
        val path = acronymDbPath ?: return emptyList()
        try {
            if (acronymDb == null) {
                acronymDb = java.sql.DriverManager.getConnection("jdbc:sqlite:$path")
            }
            val conn = acronymDb ?: return emptyList()

            conn.prepareStatement(
                "SELECT terms FROM AcronymResults WHERE book_title = ? ORDER BY id DESC LIMIT 1"
            ).use { ps ->
                ps.setString(1, title)
                ps.executeQuery().use { rs ->
                    if (!rs.next()) return emptyList()
                    val raw = rs.getString(1) ?: return emptyList()
                    val parts = raw.split(',')
                    val clean = parts
                        .map { sanitizeAcronymTerm(it) }
                        .map { it.trim() }
                        .filter { it.isNotEmpty() }

                    // De-duplicate and drop items identical to the title after normalization
                    val titleNormalized = sanitizeAcronymTerm(title)
                    return clean
                        .map { it.trim() }
                        .filter { it.isNotEmpty() }
                        .filter { !it.equals(title, ignoreCase = true) }
                        .filter { !it.equals(titleNormalized, ignoreCase = true) }
                        .distinct()
                }
            }
        } catch (e: Exception) {
            logger.w(e) { "Error reading acronyms for '$title' from $path" }
            return emptyList()
        }
    }

    // Clean an acronym using HebrewTextUtils and remove gershayim
    private fun sanitizeAcronymTerm(raw: String): String {
        var s = raw.trim()
        if (s.isEmpty()) return ""
        s = HebrewTextUtils.removeAllDiacritics(s)
        s = HebrewTextUtils.replaceMaqaf(s, " ")
        s = s.replace("\u05F4", "") // remove Hebrew gershayim (◊¥)
        s = s.replace("\u05F3", "") // remove Hebrew geresh (◊≥)
        s = s.replace("\\s+".toRegex(), " ").trim()
        return s
    }

    /**
     * Disables foreign key constraints in the database to improve performance during bulk insertion.
     * This should be called before starting the data generation process.
     */
    private suspend fun disableForeignKeys() {
        logger.d { "Disabling foreign key constraints" }
        repository.executeRawQuery("PRAGMA foreign_keys = OFF")
    }

    /**
     * Re-enables foreign key constraints in the database after data insertion is complete.
     * This should be called after all data has been inserted to ensure data integrity.
     */
    private suspend fun enableForeignKeys() {
        logger.d { "Re-enabling foreign key constraints" }
        repository.executeRawQuery("PRAGMA foreign_keys = ON")
    }

    // Removed: FTS rebuild is obsolete (Lucene index is committed in this run)

    /**
     * Updates the book_has_links table to indicate which books have source links, target links, or both.
     * This should be called after all links have been processed.
     */
    private suspend fun updateBookHasLinksTable() {
        logger.i { "Updating book_has_links table with separate source and target link flags..." }

        // Ensure all books are present in book_has_links
        runCatching {
            repository.executeRawQuery(
                "INSERT OR IGNORE INTO book_has_links(bookId, hasSourceLinks, hasTargetLinks) " +
                        "SELECT id, 0, 0 FROM book"
            )
        }

        // Reset flags, then set from aggregated distinct sets
        runCatching { repository.executeRawQuery("UPDATE book_has_links SET hasSourceLinks=0, hasTargetLinks=0") }
        runCatching {
            repository.executeRawQuery(
                "UPDATE book_has_links SET hasSourceLinks=1 " +
                        "WHERE bookId IN (SELECT DISTINCT sourceBookId FROM link)"
            )
        }
        runCatching {
            repository.executeRawQuery(
                "UPDATE book_has_links SET hasTargetLinks=1 " +
                        "WHERE bookId IN (SELECT DISTINCT targetBookId FROM link)"
            )
        }

        // Reset book per-connection-type flags
        runCatching {
            repository.executeRawQuery(
                "UPDATE book SET hasTargumConnection=0, hasReferenceConnection=0, hasCommentaryConnection=0, hasOtherConnection=0"
            )
        }

        // Helper to set a type flag in one statement
        suspend fun setConnFlag(typeName: String, column: String) {
            val sql = "UPDATE book SET $column=1 WHERE id IN (" +
                    "SELECT DISTINCT bId FROM (" +
                    "SELECT sourceBookId AS bId FROM link l JOIN connection_type ct ON ct.id = l.connectionTypeId WHERE ct.name='$typeName' " +
                    "UNION " +
                    "SELECT targetBookId AS bId FROM link l JOIN connection_type ct ON ct.id = l.connectionTypeId WHERE ct.name='$typeName'" +
                    ")" +
                    ")"
            repository.executeRawQuery(sql)
        }

        runCatching { setConnFlag("TARGUM", "hasTargumConnection") }
        runCatching { setConnFlag("REFERENCE", "hasReferenceConnection") }
        runCatching { setConnFlag("COMMENTARY", "hasCommentaryConnection") }
        runCatching { setConnFlag("OTHER", "hasOtherConnection") }

        // Quick summary counts (single queries)
        val totalBooks = repository.getAllBooks().size
        val booksWithSourceLinks = repository.countBooksWithSourceLinks().toInt()
        val booksWithTargetLinks = repository.countBooksWithTargetLinks().toInt()
        val booksWithAnyLinks = repository.countBooksWithAnyLinks().toInt()

        logger.i { "Book_has_links table updated. Found:" }
        logger.i { "- $booksWithSourceLinks books with source links" }
        logger.i { "- $booksWithTargetLinks books with target links" }
        logger.i { "- $booksWithAnyLinks books with any links (source or target)" }
        logger.i { "- $totalBooks total books" }
    }



    /**
     * Parses links from JSON content, handling both Ben-YehudaToOtzaria and DictaToOtzaria formats
     */
    private fun parseLinksFromJson(content: String, bookTitle: String): List<LinkData> {
        return try {
            // First, try to parse as Ben-YehudaToOtzaria format (List<LinkData>)
            json.decodeFromString<List<LinkData>>(content)
        } catch (e: Exception) {
            // If that fails, try to parse as DictaToOtzaria format (Map<String, List<DictaLinkData>>)
            try {
                val dictaLinksMap = json.decodeFromString<Map<String, List<DictaLinkData>>>(content)
                logger.d { "Successfully parsed DictaToOtzaria format for $bookTitle with ${dictaLinksMap.size} line groups" }
                
                // Convert DictaToOtzaria format to LinkData format
                // Note: DictaToOtzaria format doesn't map perfectly to LinkData structure
                // We'll need to handle this conversion carefully or skip for now
                logger.w { "DictaToOtzaria format conversion not yet implemented for $bookTitle" }
                emptyList<LinkData>()
            } catch (e2: Exception) {
                logger.w(e2) { "Failed to parse links from file for $bookTitle in any known format" }
                emptyList<LinkData>()
            }
        }
    }

    // Internal classes

    /**
     * Data class representing a link between two books.
     * Used for deserializing link data from JSON files.
     */
    @Serializable
    private data class LinkData(
        val heRef_2: String,
        val line_index_1: Double,
        val path_2: String,
        val line_index_2: Double,
        @SerialName("Conection Type")
        val connectionType: String = ""
    )

    /**
     * Data class for DictaToOtzaria link format
     */
    @Serializable
    private data class DictaLinkData(
        val start: Int,
        val end: Int,
        val refs: Map<String, String>
    )

}
</file>

<file path="generator/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/generator/lucene/LookupIndexWriter.kt">
package io.github.kdroidfilter.seforimlibrary.generator.lucene

interface LookupIndexWriter : AutoCloseable {
    fun addBook(
        bookId: Long,
        categoryId: Long,
        displayTitle: String,
        terms: Collection<String>
    )

    fun addToc(
        tocId: Long,
        bookId: Long,
        categoryId: Long,
        bookTitle: String,
        text: String,
        level: Int
    )

    fun commit()
}
</file>

<file path="generator/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/generator/lucene/TextIndexWriter.kt">
package io.github.kdroidfilter.seforimlibrary.generator.lucene

/**
 * Platform-agnostic interface for text indexing used by the generator.
 * The JVM implementation uses Apache Lucene. Other platforms may provide
 * a no-op or alternate implementation.
 */
interface TextIndexWriter : AutoCloseable {
    /**
     * Index a single content line document.
     * @param bookId The book id
     * @param bookTitle The book title (for display)
     * @param categoryId The category id of the book
     * @param lineId The line id
     * @param lineIndex The 0-based line index within the book
     * @param normalizedText Normalized text to index in the primary field (typically StandardAnalyzer)
     * @param rawPlainText Optional raw plain text (stored) for snippet generation
     * @param normalizedTextHebrew Optional normalized text for a secondary text field
     */
    fun addLine(
        bookId: Long,
        bookTitle: String,
        categoryId: Long,
        lineId: Long,
        lineIndex: Int,
        normalizedText: String,
        rawPlainText: String? = null,
        normalizedTextHebrew: String? = null
    )

    /**
     * Index a term for book title suggestions (title and acronyms).
     * Caller passes already-normalized term.
     */
    fun addBookTitleTerm(
        bookId: Long,
        categoryId: Long,
        displayTitle: String,
        term: String
    )

    /**
     * Flush and commit pending writes.
     */
    fun commit()

    override fun close()
}
</file>

<file path="generator/src/commonMain/kotlin/io/github/kdroidfilter/seforimlibrary/generator/utils/HebrewTextUtils.kt">
package io.github.kdroidfilter.seforimlibrary.generator.utils

/**
 * Utility class for processing Hebrew text by removing diacritical marks (nikud/niqqud).
 *
 * This class provides functions to clean Hebrew text from various diacritical marks including:
 * - Nikud (vowel points)
 * - Teamim (biblical cantillation marks)
 * - Maqaf (Hebrew hyphen)
 *
 * Based on the Unicode ranges and character mappings used in Hebrew text processing.
 */
object HebrewTextUtils {

    /**
     * Hebrew nikud (vowel point) characters mapping.
     * These are the diacritical marks used in Hebrew to indicate vowels.
     */
    private val NIKUD_SIGNS = mapOf(
        "HATAF_SEGOL" to "÷±",    // U+05B1
        "HATAF_PATAH" to "÷≤",     // U+05B2
        "HATAF_QAMATZ" to "÷≥",    // U+05B3
        "HIRIQ" to "÷¥",           // U+05B4
        "TSERE" to "÷µ",           // U+05B5
        "SEGOL" to "÷∂",           // U+05B6
        "PATAH" to "÷∑",           // U+05B7
        "QAMATZ" to "÷∏",          // U+05B8
        "SIN_DOT" to "◊Ç",         // U+05C2
        "SHIN_DOT" to "◊Å",        // U+05C1
        "HOLAM" to "÷π",           // U+05B9
        "DAGESH" to "÷º",          // U+05BC
        "QUBUTZ" to "÷ª",          // U+05BB
        "SHEVA" to "÷∞",           // U+05B0
        "QAMATZ_QATAN" to "◊á"     // U+05C7
    )

    /**
     * Meteg character (silluq) - U+05BD.
     * A vertical line placed to the left of a vowel to indicate stress.
     */
    private const val METEG = "÷Ω"

    /**
     * Regular expression pattern for removing all nikud signs including meteg.
     */
    private val NIKUD_WITH_METEG_REGEX = "[${NIKUD_SIGNS.values.joinToString("")}$METEG]".toRegex()

    /**
     * Regular expression pattern for removing nikud signs only (excluding meteg).
     */
    private val NIKUD_ONLY_REGEX = "[${NIKUD_SIGNS.values.joinToString("")}]".toRegex()

    /**
     * Regular expression pattern for biblical cantillation marks (teamim).
     * Covers Unicode range U+0591 to U+05AF.
     */
    private val TEAMIM_REGEX = "[\u0591-\u05AF]".toRegex()

    /**
     * Hebrew maqaf character (hyphen) - U+05BE.
     */
    private const val MAQAF_CHAR = "÷æ"

    /**
     * Removes all nikud (vowel points) from Hebrew text.
     *
     * This function strips vowel diacritical marks from Hebrew text, making it suitable
     * for applications that need unpointed Hebrew text.
     *
     * @param text The Hebrew text containing nikud marks, or null
     * @param includeMeteg Whether to also remove meteg marks (default: true)
     * @return The text with nikud removed, or empty string if input is null/empty
     *
     * @sample
     * ```kotlin
     * val pointed = "◊ë÷∞÷º◊®÷µ◊ê◊©÷¥◊Å◊ô◊™"
     * val unpointed = HebrewTextUtils.removeNikud(pointed)
     * // Result: "◊ë◊®◊ê◊©◊ô◊™"
     * ```
     */
    fun removeNikud(text: String?, includeMeteg: Boolean = true): String {
        if (text.isNullOrEmpty()) return ""

        return if (includeMeteg) {
            text.replace(NIKUD_WITH_METEG_REGEX, "")
        } else {
            text.replace(NIKUD_ONLY_REGEX, "")
        }
    }

    /**
     * Removes biblical cantillation marks (teamim) from Hebrew text.
     *
     * Teamim are accent marks used in biblical Hebrew to indicate musical notation
     * and syntactic relationships. This function removes these marks while preserving
     * the base text and nikud.
     *
     * @param text The Hebrew text containing teamim, or null
     * @return The text with teamim removed, or empty string if input is null/empty
     *
     * @sample
     * ```kotlin
     * val withTeamim = "◊ë÷∞÷º◊®÷µ◊ê◊©÷¥◊Å÷ñ◊ô◊™"
     * val withoutTeamim = HebrewTextUtils.removeTeamim(withTeamim)
     * // Result: "◊ë÷∞÷º◊®÷µ◊ê◊©÷¥◊Å◊ô◊™"
     * ```
     */
    fun removeTeamim(text: String?): String {
        if (text.isNullOrEmpty()) return ""
        return text.replace(TEAMIM_REGEX, "")
    }

    /**
     * Removes all diacritical marks from Hebrew text.
     *
     * This function removes both nikud (vowel points) and teamim (cantillation marks),
     * resulting in plain Hebrew consonantal text.
     *
     * @param text The Hebrew text containing diacritical marks, or null
     * @return The text with all diacritical marks removed, or empty string if input is null/empty
     *
     * @sample
     * ```kotlin
     * val fullyMarked = "◊ë÷∞÷º◊®÷µ◊ê◊©÷¥◊Å÷ñ◊ô◊™ ◊ë÷∏÷º◊®÷∏÷£◊ê"
     * val plain = HebrewTextUtils.removeAllDiacritics(fullyMarked)
     * // Result: "◊ë◊®◊ê◊©◊ô◊™ ◊ë◊®◊ê"
     * ```
     */
    fun removeAllDiacritics(text: String?): String {
        if (text.isNullOrEmpty()) return ""
        return removeTeamim(removeNikud(text, true))
    }

    /**
     * Checks whether the given text contains nikud marks.
     *
     * @param text The text to examine, or null
     * @return `true` if the text contains any nikud marks, `false` otherwise
     *
     * @sample
     * ```kotlin
     * val hasNikud = HebrewTextUtils.containsNikud("◊ë÷∞÷º◊®÷µ◊ê◊©÷¥◊Å◊ô◊™") // true
     * val noNikud = HebrewTextUtils.containsNikud("◊ë◊®◊ê◊©◊ô◊™")     // false
     * ```
     */
    fun containsNikud(text: String?): Boolean {
        if (text.isNullOrEmpty()) return false
        return NIKUD_WITH_METEG_REGEX.containsMatchIn(text)
    }

    /**
     * Checks whether the given text contains teamim (cantillation marks).
     *
     * @param text The text to examine, or null
     * @return `true` if the text contains any teamim, `false` otherwise
     *
     * @sample
     * ```kotlin
     * val hasTeamim = HebrewTextUtils.containsTeamim("◊ë÷∞÷º◊®÷µ◊ê◊©÷¥◊Å÷ñ◊ô◊™") // true
     * val noTeamim = HebrewTextUtils.containsTeamim("◊ë÷∞÷º◊®÷µ◊ê◊©÷¥◊Å◊ô◊™")   // false
     * ```
     */
    fun containsTeamim(text: String?): Boolean {
        if (text.isNullOrEmpty()) return false
        return TEAMIM_REGEX.containsMatchIn(text)
    }

    /**
     * Checks whether the given text contains maqaf (Hebrew hyphen).
     *
     * @param text The text to examine, or null
     * @return `true` if the text contains any maqaf characters, `false` otherwise
     *
     * @sample
     * ```kotlin
     * val hasMaqaf = HebrewTextUtils.containsMaqaf("◊ê÷µ◊ú÷æ◊©÷∑◊Å◊ì÷∑÷º◊ô") // true
     * val noMaqaf = HebrewTextUtils.containsMaqaf("◊ê◊ú ◊©◊ì◊ô")     // false
     * ```
     */
    fun containsMaqaf(text: String?): Boolean {
        if (text.isNullOrEmpty()) return false
        return text.contains(MAQAF_CHAR)
    }

    /**
     * Replaces Hebrew maqaf characters with a specified replacement string.
     *
     * Maqaf is the Hebrew hyphen character (÷æ) used to connect words or parts of words
     * in Hebrew text. This function allows replacing it with other characters like
     * space, dash, or any other string.
     *
     * @param text The text containing maqaf characters, or null
     * @param replacement The string to replace maqaf with (default: single space)
     * @return The text with maqaf characters replaced, or empty string if input is null/empty
     *
     * @sample
     * ```kotlin
     * val withMaqaf = "◊ê÷µ◊ú÷æ◊©÷∑◊Å◊ì÷∑÷º◊ô"
     * val withSpace = HebrewTextUtils.replaceMaqaf(withMaqaf)        // "◊ê÷µ◊ú ◊©÷∑◊Å◊ì÷∑÷º◊ô"
     * val withDash = HebrewTextUtils.replaceMaqaf(withMaqaf, "-")    // "◊ê÷µ◊ú-◊©÷∑◊Å◊ì÷∑÷º◊ô"
     * ```
     */
    fun replaceMaqaf(text: String?, replacement: String = " "): String {
        if (text.isNullOrEmpty()) return ""
        return text.replace(MAQAF_CHAR, replacement)
    }
}
</file>

<file path="generator/src/commonMain/resources/otzaria-folder-to-remove.txt">
# One folder per line (under ◊ê◊ï◊¶◊®◊ô◊ê/)
# These folders will be removed after extraction of the Otzaria source
◊ê◊ï◊ì◊ï◊™ ◊î◊™◊ï◊õ◊†◊î
◊ê◊ï◊ì◊ï◊™ ◊¢◊ú ◊î◊™◊ï◊õ◊†◊î
◊î◊ï◊ì◊¢◊î ◊ó◊©◊ï◊ë◊î
</file>

<file path="generator/src/commonMain/resources/priority.txt">
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊™◊ï◊®◊î/◊ë◊®◊ê◊©◊ô◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊™◊ï◊®◊î/◊©◊û◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊™◊ï◊®◊î/◊ï◊ô◊ß◊®◊ê.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊™◊ï◊®◊î/◊ë◊û◊ì◊ë◊®.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊™◊ï◊®◊î/◊ì◊ë◊®◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊†◊ë◊ô◊ê◊ô◊ù/◊ô◊î◊ï◊©◊¢.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊†◊ë◊ô◊ê◊ô◊ù/◊©◊ï◊§◊ò◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊†◊ë◊ô◊ê◊ô◊ù/◊©◊û◊ï◊ê◊ú ◊ê.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊†◊ë◊ô◊ê◊ô◊ù/◊©◊û◊ï◊ê◊ú ◊ë.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊†◊ë◊ô◊ê◊ô◊ù/◊û◊ú◊õ◊ô◊ù ◊ê.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊†◊ë◊ô◊ê◊ô◊ù/◊û◊ú◊õ◊ô◊ù ◊ë.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊†◊ë◊ô◊ê◊ô◊ù/◊ô◊©◊¢◊ô◊î◊ï.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊†◊ë◊ô◊ê◊ô◊ù/◊ô◊®◊û◊ô◊î◊ï.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊†◊ë◊ô◊ê◊ô◊ù/◊ô◊ó◊ñ◊ß◊ê◊ú.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊†◊ë◊ô◊ê◊ô◊ù/◊î◊ï◊©◊¢.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊†◊ë◊ô◊ê◊ô◊ù/◊ô◊ï◊ê◊ú.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊†◊ë◊ô◊ê◊ô◊ù/◊¢◊û◊ï◊°.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊†◊ë◊ô◊ê◊ô◊ù/◊¢◊ï◊ë◊ì◊ô◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊†◊ë◊ô◊ê◊ô◊ù/◊ô◊ï◊†◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊†◊ë◊ô◊ê◊ô◊ù/◊û◊ô◊õ◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊†◊ë◊ô◊ê◊ô◊ù/◊†◊ó◊ï◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊†◊ë◊ô◊ê◊ô◊ù/◊ó◊ë◊ß◊ï◊ß.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊†◊ë◊ô◊ê◊ô◊ù/◊¶◊§◊†◊ô◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊†◊ë◊ô◊ê◊ô◊ù/◊ó◊í◊ô.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊†◊ë◊ô◊ê◊ô◊ù/◊ñ◊õ◊®◊ô◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊†◊ë◊ô◊ê◊ô◊ù/◊û◊ú◊ê◊õ◊ô.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊õ◊™◊ï◊ë◊ô◊ù/◊®◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊õ◊™◊ï◊ë◊ô◊ù/◊™◊î◊ô◊ú◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊õ◊™◊ï◊ë◊ô◊ù/◊ê◊ô◊ï◊ë.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊õ◊™◊ï◊ë◊ô◊ù/◊û◊©◊ú◊ô.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊õ◊™◊ï◊ë◊ô◊ù/◊©◊ô◊® ◊î◊©◊ô◊®◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊õ◊™◊ï◊ë◊ô◊ù/◊ß◊î◊ú◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊õ◊™◊ï◊ë◊ô◊ù/◊ê◊ô◊õ◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊õ◊™◊ï◊ë◊ô◊ù/◊ê◊°◊™◊®.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊õ◊™◊ï◊ë◊ô◊ù/◊ì◊†◊ô◊ê◊ú.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊õ◊™◊ï◊ë◊ô◊ù/◊¢◊ñ◊®◊ê.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊õ◊™◊ï◊ë◊ô◊ù/◊†◊ó◊û◊ô◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊õ◊™◊ï◊ë◊ô◊ù/◊ì◊ë◊®◊ô ◊î◊ô◊û◊ô◊ù ◊ê.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊†◊ö/◊õ◊™◊ï◊ë◊ô◊ù/◊ì◊ë◊®◊ô ◊î◊ô◊û◊ô◊ù ◊ë.txt

/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊û◊©◊†◊î ◊ë◊®◊õ◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊û◊©◊†◊î ◊§◊ê◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊û◊©◊†◊î ◊ì◊û◊ê◊ô.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊û◊©◊†◊î ◊õ◊ú◊ê◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊û◊©◊†◊î ◊©◊ë◊ô◊¢◊ô◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊û◊©◊†◊î ◊™◊®◊ï◊û◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊û◊©◊†◊î ◊û◊¢◊©◊®◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊û◊©◊†◊î ◊û◊¢◊©◊® ◊©◊†◊ô.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊û◊©◊†◊î ◊ó◊ú◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊û◊©◊†◊î ◊¢◊®◊ú◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊û◊©◊†◊î ◊ë◊ô◊õ◊ï◊®◊ô◊ù.txt

/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊û◊©◊†◊î ◊©◊ë◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊û◊©◊†◊î ◊¢◊ô◊®◊ï◊ë◊ô◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊û◊©◊†◊î ◊§◊°◊ó◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊û◊©◊†◊î ◊©◊ß◊ú◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊û◊©◊†◊î ◊ô◊ï◊û◊ê.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊û◊©◊†◊î ◊°◊ï◊õ◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊û◊©◊†◊î ◊ë◊ô◊¶◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊û◊©◊†◊î ◊®◊ê◊© ◊î◊©◊†◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊û◊©◊†◊î ◊™◊¢◊†◊ô◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊û◊©◊†◊î ◊û◊í◊ô◊ú◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊û◊©◊†◊î ◊û◊ï◊¢◊ì ◊ß◊ò◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊û◊©◊†◊î ◊ó◊í◊ô◊í◊î.txt

/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊†◊©◊ô◊ù/◊û◊©◊†◊î ◊ô◊ë◊û◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊†◊©◊ô◊ù/◊û◊©◊†◊î ◊õ◊™◊ï◊ë◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊†◊©◊ô◊ù/◊û◊©◊†◊î ◊†◊ì◊®◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊†◊©◊ô◊ù/◊û◊©◊†◊î ◊†◊ñ◊ô◊®.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊†◊©◊ô◊ù/◊û◊©◊†◊î ◊°◊ï◊ò◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊†◊©◊ô◊ù/◊û◊©◊†◊î ◊í◊ô◊ò◊ô◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊†◊©◊ô◊ù/◊û◊©◊†◊î ◊ß◊ô◊ì◊ï◊©◊ô◊ü.txt

/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊û◊©◊†◊î ◊ë◊ë◊ê ◊ß◊û◊ê.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊û◊©◊†◊î ◊ë◊ë◊ê ◊û◊¶◊ô◊¢◊ê.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊û◊©◊†◊î ◊ë◊ë◊ê ◊ë◊™◊®◊ê.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊û◊©◊†◊î ◊°◊†◊î◊ì◊®◊ô◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊û◊©◊†◊î ◊û◊õ◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊û◊©◊†◊î ◊©◊ë◊ï◊¢◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊û◊©◊†◊î ◊¢◊ì◊ô◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊û◊©◊†◊î ◊¢◊ë◊ï◊ì◊î ◊ñ◊®◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊û◊©◊†◊î ◊ê◊ë◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊û◊©◊†◊î ◊î◊ï◊®◊ô◊ï◊™.txt

/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ß◊ì◊©◊ô◊ù/◊û◊©◊†◊î ◊ñ◊ë◊ó◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ß◊ì◊©◊ô◊ù/◊û◊©◊†◊î ◊û◊†◊ó◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ß◊ì◊©◊ô◊ù/◊û◊©◊†◊î ◊ó◊ï◊ú◊ô◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ß◊ì◊©◊ô◊ù/◊û◊©◊†◊î ◊ë◊õ◊ï◊®◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ß◊ì◊©◊ô◊ù/◊û◊©◊†◊î ◊¢◊®◊õ◊ô◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ß◊ì◊©◊ô◊ù/◊û◊©◊†◊î ◊™◊û◊ï◊®◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ß◊ì◊©◊ô◊ù/◊û◊©◊†◊î ◊õ◊®◊ô◊™◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ß◊ì◊©◊ô◊ù/◊û◊©◊†◊î ◊û◊¢◊ô◊ú◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ß◊ì◊©◊ô◊ù/◊û◊©◊†◊î ◊™◊û◊ô◊ì.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ß◊ì◊©◊ô◊ù/◊û◊©◊†◊î ◊û◊ì◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ß◊ì◊©◊ô◊ù/◊û◊©◊†◊î ◊ß◊ô◊†◊ô◊ù.txt

/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ò◊î◊®◊ï◊™/◊û◊©◊†◊î ◊õ◊ú◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ò◊î◊®◊ï◊™/◊û◊©◊†◊î ◊ê◊î◊ú◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ò◊î◊®◊ï◊™/◊û◊©◊†◊î ◊†◊í◊¢◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ò◊î◊®◊ï◊™/◊û◊©◊†◊î ◊§◊®◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ò◊î◊®◊ï◊™/◊û◊©◊†◊î ◊ò◊î◊®◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ò◊î◊®◊ï◊™/◊û◊©◊†◊î ◊û◊ß◊ï◊ê◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ò◊î◊®◊ï◊™/◊û◊©◊†◊î ◊†◊ì◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ò◊î◊®◊ï◊™/◊û◊©◊†◊î ◊û◊õ◊©◊ô◊®◊ô◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ò◊î◊®◊ï◊™/◊û◊©◊†◊î ◊ñ◊ë◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ò◊î◊®◊ï◊™/◊û◊©◊†◊î ◊ò◊ë◊ï◊ú ◊ô◊ï◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ò◊î◊®◊ï◊™/◊û◊©◊†◊î ◊ô◊ì◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊©◊†◊î/◊°◊ì◊® ◊ò◊î◊®◊ï◊™/◊û◊©◊†◊î ◊¢◊ï◊ß◊¶◊ô◊ù.txt

/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊ë◊®◊õ◊ï◊™.txt

/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊©◊ë◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊¢◊ô◊®◊ï◊ë◊ô◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊§◊°◊ó◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊ô◊ï◊û◊ê.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊°◊ï◊õ◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊ë◊ô◊¶◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊®◊ê◊© ◊î◊©◊†◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊™◊¢◊†◊ô◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊û◊í◊ô◊ú◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊û◊ï◊¢◊ì ◊ß◊ò◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊ó◊í◊ô◊í◊î.txt

/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊†◊©◊ô◊ù/◊ô◊ë◊û◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊†◊©◊ô◊ù/◊õ◊™◊ï◊ë◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊†◊©◊ô◊ù/◊†◊ì◊®◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊†◊©◊ô◊ù/◊†◊ñ◊ô◊®.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊†◊©◊ô◊ù/◊°◊ï◊ò◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊†◊©◊ô◊ù/◊í◊ô◊ò◊ô◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊†◊©◊ô◊ù/◊ß◊ô◊ì◊ï◊©◊ô◊ü.txt

/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊ë◊ë◊ê ◊ß◊û◊ê.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊ë◊ë◊ê ◊û◊¶◊ô◊¢◊ê.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊ë◊ë◊ê ◊ë◊™◊®◊ê.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊°◊†◊î◊ì◊®◊ô◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊û◊õ◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊©◊ë◊ï◊¢◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊¢◊ì◊ô◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊¢◊ë◊ï◊ì◊î ◊ñ◊®◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊î◊ï◊®◊ô◊ï◊™.txt

/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊ß◊ì◊©◊ô◊ù/◊ñ◊ë◊ó◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊ß◊ì◊©◊ô◊ù/◊û◊†◊ó◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊ß◊ì◊©◊ô◊ù/◊ó◊ï◊ú◊ô◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊ß◊ì◊©◊ô◊ù/◊ë◊õ◊ï◊®◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊ß◊ì◊©◊ô◊ù/◊¢◊®◊õ◊ô◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊ß◊ì◊©◊ô◊ù/◊™◊û◊ï◊®◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊ß◊ì◊©◊ô◊ù/◊õ◊®◊ô◊™◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊ß◊ì◊©◊ô◊ù/◊û◊¢◊ô◊ú◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊ß◊ì◊©◊ô◊ù/◊™◊û◊ô◊ì.txt

/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ë◊ë◊ú◊ô/◊°◊ì◊® ◊ò◊î◊®◊ï◊™/◊†◊ì◊î.txt

/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊ë◊®◊õ◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊§◊ê◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊ì◊û◊ê◊ô.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊õ◊ú◊ê◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊©◊ë◊ô◊¢◊ô◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊™◊®◊ï◊û◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊û◊¢◊©◊®◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊û◊¢◊©◊® ◊©◊†◊ô.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊ó◊ú◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊¢◊®◊ú◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊ë◊õ◊ï◊®◊ô◊ù.txt

/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊©◊ë◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊¢◊ô◊®◊ï◊ë◊ô◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊§◊°◊ó◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊©◊ß◊ú◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊ô◊ï◊û◊ê.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊°◊ï◊õ◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊ë◊ô◊¶◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊®◊ê◊© ◊î◊©◊†◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊™◊¢◊†◊ô◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊û◊í◊ô◊ú◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊û◊ï◊¢◊ì ◊ß◊ò◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊ó◊í◊ô◊í◊î.txt

/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊†◊©◊ô◊ù/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊ô◊ë◊û◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊†◊©◊ô◊ù/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊õ◊™◊ï◊ë◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊†◊©◊ô◊ù/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊†◊ì◊®◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊†◊©◊ô◊ù/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊†◊ñ◊ô◊®.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊†◊©◊ô◊ù/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊°◊ï◊ò◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊†◊©◊ô◊ù/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊í◊ô◊ò◊ô◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊†◊©◊ô◊ù/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊ß◊ô◊ì◊ï◊©◊ô◊ü.txt

/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊ë◊ë◊ê ◊ß◊û◊ê.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊ë◊ë◊ê ◊û◊¶◊ô◊¢◊ê.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊ë◊ë◊ê ◊ë◊™◊®◊ê.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊°◊†◊î◊ì◊®◊ô◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊û◊õ◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊©◊ë◊ï◊¢◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊¢◊ë◊ï◊ì◊î ◊ñ◊®◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊î◊ï◊®◊ô◊ï◊™.txt

/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô/◊°◊ì◊® ◊ò◊î◊®◊ï◊™/◊™◊ú◊û◊ï◊ì ◊ô◊®◊ï◊©◊ú◊û◊ô ◊†◊ì◊î.txt

/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊™◊ï◊°◊§◊™◊ê ◊ë◊®◊õ◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊™◊ï◊°◊§◊™◊ê ◊§◊ê◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊™◊ï◊°◊§◊™◊ê ◊ì◊û◊ê◊ô.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊™◊ï◊°◊§◊™◊ê ◊õ◊ú◊ê◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊™◊ï◊°◊§◊™◊ê ◊©◊ë◊ô◊¢◊ô◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊™◊ï◊°◊§◊™◊ê ◊™◊®◊ï◊û◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊™◊ï◊°◊§◊™◊ê ◊û◊¢◊©◊®◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊™◊ï◊°◊§◊™◊ê ◊û◊¢◊©◊® ◊©◊†◊ô.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊™◊ï◊°◊§◊™◊ê ◊ó◊ú◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊™◊ï◊°◊§◊™◊ê ◊¢◊®◊ú◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ñ◊®◊¢◊ô◊ù/◊™◊ï◊°◊§◊™◊ê ◊ë◊ô◊õ◊ï◊®◊ô◊ù.txt

/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊™◊ï◊°◊§◊™◊ê ◊©◊ë◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊™◊ï◊°◊§◊™◊ê ◊¢◊ô◊®◊ï◊ë◊ô◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊™◊ï◊°◊§◊™◊ê ◊§◊°◊ó◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊™◊ï◊°◊§◊™◊ê ◊©◊ß◊ú◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊™◊ï◊°◊§◊™◊ê ◊ô◊ï◊û◊ê.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊™◊ï◊°◊§◊™◊ê ◊°◊ï◊õ◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊™◊ï◊°◊§◊™◊ê ◊ë◊ô◊¶◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊™◊ï◊°◊§◊™◊ê ◊™◊¢◊†◊ô◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊™◊ï◊°◊§◊™◊ê ◊û◊í◊ô◊ú◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊™◊ï◊°◊§◊™◊ê ◊û◊ï◊¢◊ì ◊ß◊ò◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊û◊ï◊¢◊ì/◊™◊ï◊°◊§◊™◊ê ◊ó◊í◊ô◊í◊î.txt

/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊†◊©◊ô◊ù/◊™◊ï◊°◊§◊™◊ê ◊ô◊ë◊û◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊†◊©◊ô◊ù/◊™◊ï◊°◊§◊™◊ê ◊õ◊™◊ï◊ë◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊†◊©◊ô◊ù/◊™◊ï◊°◊§◊™◊ê ◊†◊ì◊®◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊†◊©◊ô◊ù/◊™◊ï◊°◊§◊™◊ê ◊†◊ñ◊ô◊®.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊†◊©◊ô◊ù/◊™◊ï◊°◊§◊™◊ê ◊°◊ï◊ò◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊†◊©◊ô◊ù/◊™◊ï◊°◊§◊™◊ê ◊í◊ô◊ò◊ô◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊†◊©◊ô◊ù/◊™◊ï◊°◊§◊™◊ê ◊ß◊ô◊ì◊ï◊©◊ô◊ü.txt

/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊™◊ï◊°◊§◊™◊ê ◊ë◊ë◊ê ◊ß◊û◊ê.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊™◊ï◊°◊§◊™◊ê ◊ë◊ë◊ê ◊û◊¶◊ô◊¢◊ê.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊™◊ï◊°◊§◊™◊ê ◊ë◊ë◊ê ◊ë◊™◊®◊ê.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊™◊ï◊°◊§◊™◊ê ◊°◊†◊î◊ì◊®◊ô◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊™◊ï◊°◊§◊™◊ê ◊û◊õ◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊™◊ï◊°◊§◊™◊ê ◊©◊ë◊ï◊¢◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊™◊ï◊°◊§◊™◊ê ◊¢◊ì◊ï◊ô◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊™◊ï◊°◊§◊™◊ê ◊¢◊ë◊ï◊ì◊î ◊ñ◊®◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊™◊ï◊°◊§◊™◊ê ◊î◊ï◊®◊ô◊ï◊™.txt

/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ß◊ì◊©◊ô◊ù/◊™◊ï◊°◊§◊™◊ê ◊ñ◊ë◊ó◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ß◊ì◊©◊ô◊ù/◊™◊ï◊°◊§◊™◊ê ◊û◊†◊ó◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ß◊ì◊©◊ô◊ù/◊™◊ï◊°◊§◊™◊ê ◊ó◊ï◊ú◊ô◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ß◊ì◊©◊ô◊ù/◊™◊ï◊°◊§◊™◊ê ◊ë◊õ◊ï◊®◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ß◊ì◊©◊ô◊ù/◊™◊ï◊°◊§◊™◊ê ◊¢◊®◊õ◊ô◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ß◊ì◊©◊ô◊ù/◊™◊ï◊°◊§◊™◊ê ◊™◊û◊ï◊®◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ß◊ì◊©◊ô◊ù/◊™◊ï◊°◊§◊™◊ê ◊õ◊®◊ô◊™◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ß◊ì◊©◊ô◊ù/◊™◊ï◊°◊§◊™◊ê ◊û◊¢◊ô◊ú◊î.txt

/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ò◊î◊®◊ï◊™/◊™◊ï◊°◊§◊™◊ê ◊õ◊ú◊ô◊ù ◊ß◊û◊ê.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ò◊î◊®◊ï◊™/◊™◊ï◊°◊§◊™◊ê ◊õ◊ú◊ô◊ù ◊û◊¶◊ô◊¢◊ê.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ò◊î◊®◊ï◊™/◊™◊ï◊°◊§◊™◊ê ◊õ◊ú◊ô◊ù ◊ë◊™◊®◊ê.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ò◊î◊®◊ï◊™/◊™◊ï◊°◊§◊™◊ê ◊ê◊î◊ú◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ò◊î◊®◊ï◊™/◊™◊ï◊°◊§◊™◊ê ◊†◊í◊¢◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ò◊î◊®◊ï◊™/◊™◊ï◊°◊§◊™◊ê ◊§◊®◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ò◊î◊®◊ï◊™/◊™◊ï◊°◊§◊™◊ê ◊ò◊î◊®◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ò◊î◊®◊ï◊™/◊™◊ï◊°◊§◊™◊ê ◊û◊ß◊ï◊ï◊ê◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ò◊î◊®◊ï◊™/◊™◊ï◊°◊§◊™◊ê ◊†◊ì◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ò◊î◊®◊ï◊™/◊™◊ï◊°◊§◊™◊ê ◊û◊õ◊©◊ô◊®◊ô◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ò◊î◊®◊ï◊™/◊™◊ï◊°◊§◊™◊ê ◊ñ◊ë◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ò◊î◊®◊ï◊™/◊™◊ï◊°◊§◊™◊ê ◊ò◊ë◊ï◊ú ◊ô◊ï◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ò◊î◊®◊ï◊™/◊™◊ï◊°◊§◊™◊ê ◊ô◊ì◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊™◊ï◊°◊§◊™◊ê/◊ì◊§◊ï◊° ◊ï◊ô◊ú◊†◊ê/◊°◊ì◊® ◊ò◊î◊®◊ï◊™/◊™◊ï◊°◊§◊™◊ê ◊¢◊ï◊ß◊¶◊ô◊ü.txt

/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊ê◊í◊ì◊™ ◊ë◊®◊ê◊©◊ô◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊ê◊ï◊¶◊® ◊û◊ì◊®◊©◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊ë◊ô◊ê◊ï◊® ◊î◊®◊ì◊ú ◊¢◊ú ◊§◊®◊ß◊ô ◊ì◊®◊ë◊ô ◊ê◊ú◊ô◊¢◊ñ◊®.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊ë◊®◊ê◊©◊ô◊™ ◊®◊ë◊™◊ô.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™ -◊û◊ì◊®◊©◊ô◊ù ◊ß◊¶◊®◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™ ◊ó◊ú◊ß ◊ê - ◊ë◊®◊ô◊ô◊™◊ê ◊ì◊û◊¢◊©◊î ◊û◊®◊õ◊ë◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™ ◊ó◊ú◊ß ◊ê - ◊ó◊ú◊ï◊ù ◊û◊®◊ì◊õ◊ô ◊ï◊™◊§◊ú◊™◊ï ◊ï◊™◊§◊ú◊™ ◊ê◊°◊™◊®.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™ ◊ó◊ú◊ß ◊ê - ◊ú◊ß◊ï◊ò◊ô◊ù ◊û◊û◊ì◊®◊© ◊©◊ï◊ó◊® ◊ò◊ï◊ë ◊õ◊™◊ë ◊ô◊ì.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™ ◊ó◊ú◊ß ◊ê - ◊û◊ê◊û◊® ◊í◊ì◊ï◊ú◊î ◊¢◊†◊ï◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™ ◊ó◊ú◊ß ◊ê - ◊û◊í◊ú◊™ ◊ê◊†◊ò◊ô◊ï◊õ◊° ◊ë◊ú◊©◊ï◊ü ◊ê◊®◊û◊ô.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™ ◊ó◊ú◊ß ◊ê - ◊û◊ì◊®◊© ◊ô◊ú◊û◊ì◊†◊ï.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™ ◊ó◊ú◊ß ◊ê - ◊û◊ì◊®◊© ◊õ◊™◊§◊ï◊ó ◊ë◊¢◊¶◊ô ◊î◊ô◊¢◊®.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™ ◊ó◊ú◊ß ◊ê - ◊û◊ì◊®◊© ◊©◊†◊ô ◊õ◊™◊ï◊ë◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™ ◊ó◊ú◊ß ◊ê - ◊û◊©◊†◊™ ◊û◊°◊õ◊™ ◊õ◊ú◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™ ◊ó◊ú◊ß ◊ê - ◊°◊ì◊® ◊®◊ë◊î ◊ì◊ë◊®◊ê◊©◊ô◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™ ◊ó◊ú◊ß ◊ê - ◊§◊®◊ß◊ô ◊î◊ô◊õ◊ú◊ï◊™ ◊®◊ë◊™◊ô.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™ ◊ó◊ú◊ß ◊ê - ◊§◊®◊ß ◊¶◊ì◊ß◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™ ◊ó◊ú◊ß ◊ê - ◊©◊ú◊© ◊§◊°◊ô◊ß◊™◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™ ◊ó◊ú◊ß ◊ë - ◊ë◊®◊ô◊ô◊™◊ê ◊ì◊û◊ñ◊ú◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™ ◊ó◊ú◊ß ◊ë - ◊û◊ì◊®◊© ◊ê◊ï◊™◊ô◊ï◊™ ◊®◊ë◊ô ◊¢◊ß◊ô◊ë◊ê ◊î◊©◊ú◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™ ◊ó◊ú◊ß ◊ë - ◊û◊ì◊®◊© ◊ê◊ú◊§◊ê ◊ë◊ô◊™◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™ ◊ó◊ú◊ß ◊ë - ◊û◊ì◊®◊© ◊û◊†◊ô◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™ ◊ó◊ú◊ß ◊ë - ◊û◊ì◊®◊© ◊©◊ú◊©◊î ◊ï◊ê◊®◊ë◊¢◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™ ◊ó◊ú◊ß ◊ë - ◊û◊ì◊®◊© ◊™◊û◊ï◊®◊î ◊î◊©◊ú◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™ ◊ó◊ú◊ß ◊ë - ◊û◊õ◊ô◊ú◊™◊ê.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™ ◊ó◊ú◊ß ◊ë - ◊°◊§◊® ◊ñ◊®◊ï◊ë◊ë◊ú.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™/◊û◊ì◊®◊© ◊ê◊ë◊ê ◊í◊ï◊®◊ô◊ï◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™/◊û◊ì◊®◊©◊ï◊™ ◊ó◊ú◊ß ◊ë - ◊ú◊ß◊ï◊ò◊ô ◊û◊ì◊®◊©◊ô◊ù ◊û◊õ◊™◊ë ◊ô◊ì.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊ë◊™◊ô ◊û◊ì◊®◊©◊ï◊™/◊û◊ì◊®◊©◊ï◊™ ◊ó◊ú◊ß ◊ë - ◊û◊ì◊®◊© ◊ó◊°◊®◊ï◊™ ◊ï◊ô◊™◊®◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊î◊¢◊®◊ï◊™ ◊ë◊ï◊ë◊® ◊¢◊ú ◊û◊ì◊®◊© ◊û◊©◊ú◊ô.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊î◊¢◊®◊ï◊™ ◊ï◊™◊ô◊ß◊ï◊†◊ô◊ù ◊¢◊ú ◊û◊ì◊®◊© ◊ê◊í◊ì◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊î◊¢◊®◊ï◊™ ◊¢◊ú ◊ë◊ô◊ê◊ï◊® ◊î◊®◊ì◊ú ◊¢◊ú ◊§◊®◊ß◊ô ◊ì◊®◊ë◊ô ◊ê◊ú◊ô◊¢◊ñ◊®.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊ô◊ú◊ß◊ï◊ò ◊©◊û◊¢◊ï◊†◊ô ◊¢◊ú ◊î◊™◊ï◊®◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊ô◊ú◊ß◊ï◊ò ◊©◊û◊¢◊ï◊†◊ô ◊¢◊ú ◊†◊ö.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊ê◊í◊ì◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊ñ◊ï◊ò◊ê.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊ô◊ú◊û◊ì◊†◊ï ◊û◊™◊ï◊ö ◊ô◊ú◊ß◊ï◊ò ◊™◊ú◊û◊ï◊ì ◊™◊ï◊®◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊ú◊ß◊ó ◊ò◊ï◊ë/◊û◊ì◊®◊© ◊ú◊ß◊ó ◊ò◊ï◊ë.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊ú◊ß◊ó ◊ò◊ï◊ë/◊û◊ì◊®◊© ◊ú◊ß◊ó ◊ò◊ï◊ë ◊¢◊ú ◊ê◊ô◊õ◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊ú◊ß◊ó ◊ò◊ï◊ë/◊û◊ì◊®◊© ◊ú◊ß◊ó ◊ò◊ï◊ë ◊¢◊ú ◊ê◊°◊™◊®.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊ú◊ß◊ó ◊ò◊ï◊ë/◊û◊ì◊®◊© ◊ú◊ß◊ó ◊ò◊ï◊ë ◊¢◊ú ◊ß◊î◊ú◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊ú◊ß◊ó ◊ò◊ï◊ë/◊û◊ì◊®◊© ◊ú◊ß◊ó ◊ò◊ï◊ë ◊¢◊ú ◊®◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊ú◊ß◊ó ◊ò◊ï◊ë/◊û◊ì◊®◊© ◊ú◊ß◊ó ◊ò◊ï◊ë ◊¢◊ú ◊©◊ô◊® ◊î◊©◊ô◊®◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊ú◊ß◊ó ◊ò◊ï◊ë/◊î◊¢◊®◊ï◊™ ◊¢◊ú ◊û◊ì◊®◊© ◊ú◊ß◊ó ◊ò◊ï◊ë.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊ú◊ß◊ó ◊ò◊ï◊ë/◊û◊§◊®◊©◊ô◊ù/◊ë◊ê◊ï◊® ◊î◊®◊ê◊ù ◊¢◊ú ◊û◊ì◊®◊© ◊ú◊ß◊ó ◊ò◊ï◊ë.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊ú◊ß◊ó ◊ò◊ï◊ë/◊û◊§◊®◊©◊ô◊ù/◊î◊¢◊®◊ï◊™ ◊ï◊™◊ô◊ß◊ï◊†◊ô◊ù ◊¢◊ú ◊û◊ì◊®◊© ◊ú◊ß◊ó ◊ò◊ï◊ë.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊ú◊ß◊ó ◊ò◊ï◊ë/◊û◊§◊®◊©◊ô◊ù/◊î◊¢◊®◊ï◊™ ◊ï◊™◊ô◊ß◊ï◊†◊ô◊ù ◊¢◊ú ◊û◊ì◊®◊© ◊ú◊ß◊ó ◊ò◊ï◊ë ◊¢◊ú ◊ê◊°◊™◊®.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊û◊©◊ú◊ô.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊®◊ë◊î/◊ë◊®◊ê◊©◊ô◊™ ◊®◊ë◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊®◊ë◊î/◊©◊û◊ï◊™ ◊®◊ë◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊®◊ë◊î/◊ï◊ô◊ß◊®◊ê ◊®◊ë◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊®◊ë◊î/◊ë◊û◊ì◊ë◊® ◊®◊ë◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊®◊ë◊î/◊ì◊ë◊®◊ô◊ù ◊®◊ë◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊®◊ë◊î/◊®◊ï◊™ ◊®◊ë◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊®◊ë◊î/◊©◊ô◊® ◊î◊©◊ô◊®◊ô◊ù ◊®◊ë◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊®◊ë◊î/◊ß◊î◊ú◊™ ◊®◊ë◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊®◊ë◊î/◊ê◊ô◊õ◊î ◊®◊ë◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊®◊ë◊î/◊ê◊°◊™◊® ◊®◊ë◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊®◊ë◊î/◊û◊§◊®◊©◊ô◊ù/◊ó◊ô◊ì◊ï◊©◊ô ◊î◊®◊ì◊ú ◊¢◊ú ◊ë◊®◊ê◊©◊ô◊™ ◊®◊ë◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊®◊ë◊î/◊û◊§◊®◊©◊ô◊ù/◊ó◊ô◊ì◊ï◊©◊ô ◊î◊®◊ì◊ú ◊¢◊ú ◊©◊û◊ï◊™ ◊®◊ë◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊®◊ë◊î/◊û◊§◊®◊©◊ô◊ù/◊ó◊ô◊ì◊ï◊©◊ô ◊î◊®◊ì◊ú ◊¢◊ú ◊ï◊ô◊ß◊®◊ê ◊®◊ë◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊®◊ë◊î/◊û◊§◊®◊©◊ô◊ù/◊ó◊ô◊ì◊ï◊©◊ô ◊î◊®◊ì◊ú ◊¢◊ú ◊ë◊û◊ì◊ë◊® ◊®◊ë◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊®◊ë◊î/◊û◊§◊®◊©◊ô◊ù/◊ó◊ô◊ì◊ï◊©◊ô ◊î◊®◊ì◊ú ◊¢◊ú ◊ì◊ë◊®◊ô◊ù ◊®◊ë◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊®◊ë◊î/◊û◊§◊®◊©◊ô◊ù/◊ó◊ô◊ì◊ï◊©◊ô ◊î◊®◊ì◊ú ◊¢◊ú ◊®◊ï◊™ ◊®◊ë◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊®◊ë◊î/◊û◊§◊®◊©◊ô◊ù/◊ó◊ô◊ì◊ï◊©◊ô ◊î◊®◊ì◊ú ◊¢◊ú ◊©◊ô◊® ◊î◊©◊ô◊®◊ô◊ù ◊®◊ë◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊®◊ë◊î/◊û◊§◊®◊©◊ô◊ù/◊ó◊ô◊ì◊ï◊©◊ô ◊î◊®◊ì◊ú ◊¢◊ú ◊ß◊î◊ú◊™ ◊®◊ë◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊®◊ë◊î/◊û◊§◊®◊©◊ô◊ù/◊ó◊ô◊ì◊ï◊©◊ô ◊î◊®◊ì◊ú ◊¢◊ú ◊ê◊ô◊õ◊î ◊®◊ë◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊®◊ë◊î/◊û◊§◊®◊©◊ô◊ù/◊ó◊ô◊ì◊ï◊©◊ô ◊î◊®◊ì◊ú ◊¢◊ú ◊ê◊°◊™◊® ◊®◊ë◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊©◊õ◊ú ◊ò◊ï◊ë.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊©◊û◊ï◊ê◊ú.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊™◊î◊ô◊ú◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊ì◊®◊© ◊™◊†◊ó◊ï◊û◊ê.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊û◊©◊†◊™ ◊®◊ë◊ô ◊ê◊ú◊ô◊¢◊ñ◊®.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊°◊ì◊® ◊¢◊ï◊ú◊ù ◊ñ◊ï◊ò◊ê.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊°◊ì◊® ◊¢◊ï◊ú◊ù ◊®◊ë◊î/◊°◊ì◊® ◊¢◊ï◊ú◊ù ◊®◊ë◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊°◊ì◊® ◊¢◊ï◊ú◊ù ◊®◊ë◊î/◊û◊§◊®◊©◊ô◊ù/◊í◊®◊ê ◊¢◊ú ◊°◊ì◊® ◊¢◊ï◊ú◊ù ◊®◊ë◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊°◊ì◊® ◊¢◊ï◊ú◊ù ◊®◊ë◊î/◊û◊§◊®◊©◊ô◊ù/◊ô◊¢◊ë◊• ◊¢◊ú ◊°◊ì◊® ◊¢◊ï◊ú◊ù ◊®◊ë◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊°◊ì◊® ◊¢◊ï◊ú◊ù ◊®◊ë◊î/◊û◊§◊®◊©◊ô◊ù/◊û◊ê◊ô◊® ◊¢◊ô◊ü ◊¢◊ú ◊°◊ì◊® ◊¢◊ï◊ú◊ù ◊®◊ë◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊°◊§◊® ◊î◊ô◊©◊® (◊û◊ì◊®◊©).txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊°◊§◊®◊ô ◊ì◊ê◊í◊ì◊™◊ê ◊¢◊ú ◊û◊í◊ô◊ú◊™ ◊ê◊°◊™◊®.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊¢◊ô◊ü ◊ô◊¢◊ß◊ë.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊¢◊ô◊ü ◊ô◊¢◊ß◊ë (◊û◊ê◊™ ◊©◊û◊ï◊ê◊ú ◊¶◊ë◊ô ◊í◊ú◊ô◊ß).txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊§◊°◊ô◊ß◊™◊ê ◊ì◊®◊ë ◊õ◊î◊†◊ê.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊§◊°◊ô◊ß◊™◊ê ◊®◊ë◊™◊ô.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊§◊® ◊ê◊ó◊ì ◊¢◊ú ◊§◊®◊ß◊ô ◊ì◊®◊ë◊ô ◊ê◊ú◊ô◊¢◊ñ◊®.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊§◊®◊ß◊ô ◊ì◊®◊ë◊ô ◊ê◊ú◊ô◊¢◊ñ◊®.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊™◊†◊ê ◊ì◊ë◊ô ◊ê◊ú◊ô◊î◊ï ◊®◊ë◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊™◊†◊ê ◊ì◊ë◊ô ◊ê◊ú◊ô◊î◊ï ◊ñ◊ï◊ò◊ê.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊ê◊í◊ì◊î/◊™◊†◊ó◊ï◊û◊ê ◊ë◊ï◊ë◊®.txt

/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊î◊ú◊õ◊î/◊û◊í◊ô◊ú◊™ ◊™◊¢◊†◊ô◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊î◊ú◊õ◊î/◊û◊ì◊®◊© ◊™◊†◊ê◊ô◊ù ◊¢◊ú ◊°◊§◊® ◊ì◊ë◊®◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊î◊ú◊õ◊î/◊û◊õ◊ô◊ú◊™◊ê ◊ì◊®◊ë◊ô ◊ô◊©◊û◊¢◊ê◊ú.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊î◊ú◊õ◊î/◊û◊õ◊ô◊ú◊™◊ê ◊ì◊®◊ë◊ô ◊©◊û◊¢◊ï◊ü ◊ë◊ü ◊ô◊ï◊ó◊ê◊ô.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊î◊ú◊õ◊î/◊ó◊§◊• ◊ó◊ô◊ô◊ù ◊¢◊ú ◊°◊§◊®◊ê.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊î◊ú◊õ◊î/◊°◊§◊®◊ê.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊î◊ú◊õ◊î/◊°◊§◊®◊ô ◊ë◊û◊ì◊ë◊®.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊î◊ú◊õ◊î/◊°◊§◊®◊ô ◊ì◊ë◊®◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊û◊ì◊®◊©/◊î◊ú◊õ◊î/◊°◊§◊®◊ô ◊ñ◊ï◊ò◊ê.txt

/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊î◊ß◊ì◊û◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊û◊°◊ô◊®◊™ ◊™◊ï◊®◊î ◊©◊ë◊¢◊ú ◊§◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊î◊ß◊ì◊û◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊û◊¶◊ï◊ï◊™ ◊ú◊ê ◊™◊¢◊©◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊î◊ß◊ì◊û◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊û◊¶◊ï◊ï◊™ ◊¢◊©◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊î◊ß◊ì◊û◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊™◊ï◊õ◊ü ◊î◊ó◊ô◊ë◊ï◊®.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊û◊ì◊¢/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊ô◊°◊ï◊ì◊ô ◊î◊™◊ï◊®◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊û◊ì◊¢/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊ì◊¢◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊û◊ì◊¢/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊™◊ú◊û◊ï◊ì ◊™◊ï◊®◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊û◊ì◊¢/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊¢◊ë◊ï◊ì◊î ◊ñ◊®◊î ◊ï◊ó◊ï◊ß◊ï◊™ ◊î◊í◊ï◊ô◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊û◊ì◊¢/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊™◊©◊ï◊ë◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ê◊î◊ë◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊ß◊®◊ô◊ê◊™ ◊©◊û◊¢.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ê◊î◊ë◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊™◊§◊ô◊ú◊î ◊ï◊ë◊®◊õ◊™ ◊õ◊î◊†◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ê◊î◊ë◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊™◊§◊ô◊ú◊ô◊ü ◊ï◊û◊ñ◊ï◊ñ◊î ◊ï◊°◊§◊® ◊™◊ï◊®◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ê◊î◊ë◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊¶◊ô◊¶◊ô◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ê◊î◊ë◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊ë◊®◊õ◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ê◊î◊ë◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊û◊ô◊ú◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ê◊î◊ë◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊°◊ì◊® ◊î◊™◊§◊ô◊ú◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ñ◊û◊†◊ô◊ù/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊©◊ë◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ñ◊û◊†◊ô◊ù/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊¢◊ô◊®◊ï◊ë◊ô◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ñ◊û◊†◊ô◊ù/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊©◊ß◊ú◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ñ◊û◊†◊ô◊ù/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊ß◊ô◊ì◊ï◊© ◊î◊ó◊ï◊ì◊©.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ñ◊û◊†◊ô◊ù/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊™◊¢◊†◊ô◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ñ◊û◊†◊ô◊ù/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊û◊í◊ô◊ú◊î ◊ï◊ó◊†◊ï◊õ◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ñ◊û◊†◊ô◊ù/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊©◊ï◊§◊® ◊ï◊°◊ï◊õ◊î ◊ï◊ú◊ï◊ú◊ë.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ñ◊û◊†◊ô◊ù/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊©◊ë◊ô◊™◊™ ◊ô◊ï◊ù ◊ò◊ï◊ë.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ñ◊û◊†◊ô◊ù/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊©◊ë◊ô◊™◊™ ◊¢◊©◊ï◊®.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ñ◊û◊†◊ô◊ù/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊ó◊û◊• ◊ï◊û◊¶◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊†◊©◊ô◊ù/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊ê◊ô◊©◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊†◊©◊ô◊ù/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊í◊ô◊®◊ï◊©◊ô◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊†◊©◊ô◊ù/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊ô◊ë◊ï◊ù ◊ï◊ó◊ú◊ô◊¶◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊†◊©◊ô◊ù/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊°◊ï◊ò◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊†◊©◊ô◊ù/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊†◊¢◊®◊î ◊ë◊™◊ï◊ú◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ß◊ì◊ï◊©◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊û◊ê◊õ◊ú◊ï◊™ ◊ê◊°◊ï◊®◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ß◊ì◊ï◊©◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊©◊ó◊ô◊ò◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ß◊ì◊ï◊©◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊ê◊ô◊°◊ï◊®◊ô ◊ë◊ô◊ê◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊î◊§◊ú◊ê◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊†◊ì◊®◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊î◊§◊ú◊ê◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊†◊ñ◊ô◊®◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊î◊§◊ú◊ê◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊¢◊®◊õ◊ô◊ù ◊ï◊ó◊®◊û◊ô◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊î◊§◊ú◊ê◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊©◊ë◊ï◊¢◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ñ◊®◊¢◊ô◊ù/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊™◊®◊ï◊û◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ñ◊®◊¢◊ô◊ù/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊û◊¢◊©◊®◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ñ◊®◊¢◊ô◊ù/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊û◊¢◊©◊® ◊©◊†◊ô ◊ï◊†◊ò◊¢ ◊®◊ë◊¢◊ô.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ñ◊®◊¢◊ô◊ù/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊©◊û◊ô◊ò◊î ◊ï◊ô◊ï◊ë◊ú.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ñ◊®◊¢◊ô◊ù/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊û◊™◊†◊ï◊™ ◊¢◊†◊ô◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ñ◊®◊¢◊ô◊ù/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊õ◊ú◊ê◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ñ◊®◊¢◊ô◊ù/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊ë◊ô◊õ◊ï◊®◊ô◊ù ◊ï◊©◊ê◊® ◊û◊™◊†◊ï◊™ ◊õ◊î◊ï◊†◊î ◊©◊ë◊í◊ë◊ï◊ú◊ô◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊¢◊ë◊ï◊ì◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊ë◊ô◊™ ◊î◊ë◊ó◊ô◊®◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊¢◊ë◊ï◊ì◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊õ◊ú◊ô ◊î◊û◊ß◊ì◊© ◊ï◊î◊¢◊ï◊ë◊ì◊ô◊ü ◊ë◊ï.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊¢◊ë◊ï◊ì◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊ê◊ô◊°◊ï◊®◊ô ◊î◊û◊ñ◊ë◊ó.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊¢◊ë◊ï◊ì◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊ë◊ô◊ê◊™ ◊û◊ß◊ì◊©.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊¢◊ë◊ï◊ì◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊û◊¢◊©◊î ◊î◊ß◊®◊ë◊†◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊¢◊ë◊ï◊ì◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊¢◊ë◊ï◊ì◊™ ◊ô◊ï◊ù ◊î◊õ◊§◊ï◊®◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊¢◊ë◊ï◊ì◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊§◊°◊ï◊ú◊ô ◊î◊û◊ï◊ß◊ì◊©◊ô◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊¢◊ë◊ï◊ì◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊™◊û◊ô◊ì◊ô◊ù ◊ï◊û◊ï◊°◊§◊ô◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊¢◊ë◊ï◊ì◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊û◊¢◊ô◊ú◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ß◊ï◊®◊ë◊†◊ï◊™/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊ë◊õ◊ï◊®◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ß◊ï◊®◊ë◊†◊ï◊™/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊©◊í◊í◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ß◊ï◊®◊ë◊†◊ï◊™/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊û◊ó◊ï◊°◊®◊ô ◊õ◊§◊®◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ß◊ï◊®◊ë◊†◊ï◊™/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊™◊û◊ï◊®◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ß◊ï◊®◊ë◊†◊ï◊™/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊ß◊®◊ë◊ü ◊§◊°◊ó.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ß◊ï◊®◊ë◊†◊ï◊™/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊ó◊í◊ô◊í◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊†◊ñ◊ß◊ô ◊û◊û◊ï◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊í◊ñ◊ô◊ú◊î ◊ï◊ê◊ë◊ô◊ì◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊í◊†◊ô◊ë◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊ó◊ï◊ë◊ú ◊ï◊û◊ñ◊ô◊ß.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊†◊ñ◊ô◊ß◊ô◊ü/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊®◊ï◊¶◊ó ◊ï◊©◊û◊ô◊®◊™ ◊†◊§◊©.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ß◊†◊ô◊ô◊ü/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊û◊õ◊ô◊®◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ß◊†◊ô◊ô◊ü/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊ñ◊õ◊ô◊ô◊î ◊ï◊û◊™◊†◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ß◊†◊ô◊ô◊ü/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊©◊ú◊ï◊ó◊ô◊ü ◊ï◊©◊ï◊™◊§◊ô◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ß◊†◊ô◊ô◊ü/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊¢◊ë◊ì◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ß◊†◊ô◊ô◊ü/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊©◊õ◊†◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊û◊©◊§◊ò◊ô◊ù/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊û◊ú◊ï◊ï◊î ◊ï◊ú◊ï◊ï◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊û◊©◊§◊ò◊ô◊ù/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊©◊õ◊ô◊®◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊û◊©◊§◊ò◊ô◊ù/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊†◊ó◊ú◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊û◊©◊§◊ò◊ô◊ù/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊ò◊ï◊¢◊ü ◊ï◊†◊ò◊¢◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊û◊©◊§◊ò◊ô◊ù/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊©◊ê◊ú◊î ◊ï◊§◊ô◊ß◊ì◊ï◊ü.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ò◊î◊®◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊©◊ê◊® ◊ê◊ë◊ï◊™ ◊î◊ò◊ï◊û◊ê◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ò◊î◊®◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊ò◊ï◊û◊ê◊™ ◊û◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ò◊î◊®◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊ò◊ï◊û◊ê◊™ ◊¶◊®◊¢◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ò◊î◊®◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊û◊ò◊û◊ê◊ô ◊û◊©◊õ◊ë ◊ï◊û◊ï◊©◊ë.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ò◊î◊®◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊ò◊ï◊û◊ê◊™ ◊ê◊ï◊õ◊ú◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ò◊î◊®◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊§◊®◊î ◊ê◊ì◊ï◊û◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ò◊î◊®◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊û◊ß◊ï◊ê◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊ò◊î◊®◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊õ◊ú◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊©◊ï◊§◊ò◊ô◊ù/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊°◊†◊î◊ì◊®◊ô◊ü ◊ï◊î◊¢◊ï◊†◊©◊ô◊ü ◊î◊û◊°◊ï◊®◊ô◊ü ◊ú◊î◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊©◊ï◊§◊ò◊ô◊ù/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊¢◊ì◊ï◊™.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊©◊ï◊§◊ò◊ô◊ù/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊û◊û◊®◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊©◊ï◊§◊ò◊ô◊ù/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊ê◊ë◊ú.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊û◊©◊†◊î ◊™◊ï◊®◊î/◊°◊§◊® ◊©◊ï◊§◊ò◊ô◊ù/◊û◊©◊†◊î ◊™◊ï◊®◊î, ◊î◊ú◊õ◊ï◊™ ◊û◊ú◊õ◊ô◊ù ◊ï◊û◊ú◊ó◊û◊ï◊™.txt

/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊ò◊ï◊®/◊ò◊ï◊®.txt

/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊©◊ï◊ú◊ó◊ü ◊¢◊®◊ï◊ö/◊©◊ï◊ú◊ó◊ü ◊¢◊®◊ï◊ö, ◊î◊ß◊ì◊û◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊©◊ï◊ú◊ó◊ü ◊¢◊®◊ï◊ö/◊©◊ï◊ú◊ó◊ü ◊¢◊®◊ï◊ö, ◊ê◊ï◊®◊ó ◊ó◊ô◊ô◊ù.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊©◊ï◊ú◊ó◊ü ◊¢◊®◊ï◊ö/◊©◊ï◊ú◊ó◊ü ◊¢◊®◊ï◊ö, ◊ô◊ï◊®◊î ◊ì◊¢◊î.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊©◊ï◊ú◊ó◊ü ◊¢◊®◊ï◊ö/◊©◊ï◊ú◊ó◊ü ◊¢◊®◊ï◊ö, ◊ê◊ë◊ü ◊î◊¢◊ñ◊®.txt
/◊ê◊ï◊¶◊®◊ô◊ê/◊î◊ú◊õ◊î/◊©◊ï◊ú◊ó◊ü ◊¢◊®◊ï◊ö/◊©◊ï◊ú◊ó◊ü ◊¢◊®◊ï◊ö, ◊ó◊ï◊©◊ü ◊û◊©◊§◊ò.txt
</file>

<file path="generator/src/commonMain/resources/source-blacklist.txt">
wiki_jewish_books
</file>

<file path="generator/src/jvmMain/kotlin/io/github/kdroidfilter/seforimlibrary/generator/AcronymizerFetcher.kt">
package io.github.kdroidfilter.seforimlibrary.generator

import co.touchlab.kermit.Logger
import java.net.URI
import java.net.http.HttpClient
import java.net.http.HttpRequest
import java.net.http.HttpResponse
import java.nio.file.Files
import java.nio.file.Path
import java.nio.file.Paths

object AcronymizerFetcher {
    private const val LATEST_API = "https://api.github.com/repos/kdroidFilter/SeforimAcronymizer/releases/latest"

    /** Ensure acronymizer DB is available locally under build/acronymizer/acronymizer.db (relative to CWD). */
    fun ensureLocalDb(logger: Logger): Path {
        val destRoot = Paths.get("build", "acronymizer")
        val dbPath = destRoot.resolve("acronymizer.db")
        if (Files.exists(dbPath) && Files.isRegularFile(dbPath) && Files.size(dbPath) > 0) {
            logger.i { "Using existing acronymizer DB at ${dbPath.toAbsolutePath()}" }
            return dbPath
        }
        Files.createDirectories(destRoot)
        downloadLatestDb(dbPath, logger)
        return dbPath
    }

    private fun downloadLatestDb(outDb: Path, logger: Logger) {
        val client = HttpClient.newBuilder()
            .version(HttpClient.Version.HTTP_2)
            .followRedirects(HttpClient.Redirect.NORMAL)
            .build()
        val token = System.getenv("GITHUB_TOKEN") ?: System.getenv("GH_TOKEN")
        val req = HttpRequest.newBuilder(URI(LATEST_API))
            .header("Accept", "application/vnd.github+json")
            .header("User-Agent", "SeforimLibrary-AcronymizerFetcher/1.0")
            .apply { if (!token.isNullOrBlank()) header("Authorization", "Bearer $token") }
            .build()
        val res = client.send(req, HttpResponse.BodyHandlers.ofString())
        if (res.statusCode() !in 200..299) {
            throw IllegalStateException("GitHub API error: HTTP ${res.statusCode()}\n${res.body()}")
        }
        val body = res.body()
        // Find a .db asset browser_download_url
        val regex = Regex(""""browser_download_url"\s*:\s*"([^"]+\.db)"""")
        val dbUrl = regex.findAll(body).map { it.groupValues[1] }.firstOrNull()
            ?: throw IllegalStateException("No .db asset found in latest SeforimAcronymizer release")
        logger.i { "Downloading acronymizer DB from $dbUrl" }

        val dbReq = HttpRequest.newBuilder(URI(dbUrl))
            .header("Accept", "application/octet-stream")
            .header("User-Agent", "SeforimLibrary-AcronymizerFetcher/1.0")
            .apply { if (!token.isNullOrBlank()) header("Authorization", "Bearer $token") }
            .build()
        val dbRes = client.send(dbReq, HttpResponse.BodyHandlers.ofInputStream())
        if (dbRes.statusCode() !in 200..299) {
            throw IllegalStateException("Failed to download acronymizer DB: HTTP ${dbRes.statusCode()}")
        }
        Files.createDirectories(outDb.parent)
        dbRes.body().use { input ->
            Files.newOutputStream(outDb).use { output ->
                input.copyTo(output, 1 shl 20) // 1 MiB buffer
            }
        }
        logger.i { "Saved acronymizer DB to ${outDb.toAbsolutePath()}" }
    }
}
</file>

<file path="generator/src/jvmMain/kotlin/io/github/kdroidfilter/seforimlibrary/generator/BuildFromScratch.kt">
package io.github.kdroidfilter.seforimlibrary.generator

import app.cash.sqldelight.driver.jdbc.sqlite.JdbcSqliteDriver
import co.touchlab.kermit.Logger
import co.touchlab.kermit.Severity
import io.github.kdroidfilter.seforimlibrary.dao.repository.SeforimRepository
import io.github.kdroidfilter.seforimlibrary.generator.lucene.LuceneTextIndexWriter
import io.github.kdroidfilter.seforimlibrary.generator.lucene.LuceneLookupIndexWriter
import kotlinx.coroutines.runBlocking
import java.io.File
import java.nio.file.Path
import java.nio.file.Paths
import kotlin.io.path.Path as KPath
import kotlin.system.exitProcess

/**
 * JVM entry point for the Otzaria database generator with Lucene indexing.
 */
fun main(args: Array<String>) = runBlocking {
    Logger.setMinSeverity(Severity.Warn)
    val logger = Logger.withTag("Main")

    // Resolve inputs (adapt as needed)
    val dbPath = "/Volumes/Data/Downloads/seforim_lucene.db"
    val sourcePath = KPath("/Volumes/Data/Downloads/otzaria_latest")
    val acronymDbPath: String? = "/Volumes/Data/Downloads/acronymizer.db"

    val dbFile = File(dbPath)
    val dbExists = dbFile.exists()
    if (dbExists) {
        val backupFile = File("$dbPath.bak")
        if (backupFile.exists()) backupFile.delete()
        dbFile.renameTo(backupFile)
    }

    val driver = JdbcSqliteDriver(url = "jdbc:sqlite:$dbPath")
    val repository = SeforimRepository(dbPath, driver)

    // Index dir beside the DB
    val indexDir = if (dbPath.endsWith(".db")) Paths.get("$dbPath.lucene") else Paths.get("$dbPath.luceneindex")
    val luceneWriter = LuceneTextIndexWriter(indexDir)
    val lookupIndexDir = if (dbPath.endsWith(".db")) Paths.get("$dbPath.lookup.lucene") else Paths.get("$dbPath.lookupindex")
    val lookupWriter = LuceneLookupIndexWriter(lookupIndexDir)

    try {
        val generator = DatabaseGenerator(sourcePath, repository, acronymDbPath, luceneWriter, lookupWriter)
        generator.generate()
        logger.i { "Generation completed successfully! DB: $dbPath Index: $indexDir" }
    } catch (e: Exception) {
        logger.e(e) { "Error during generation" }
        exitProcess(1)
    } finally {
        runCatching { luceneWriter.close() }
        runCatching { lookupWriter.close() }
        repository.close()
    }
}
</file>

<file path="generator/src/jvmMain/kotlin/io/github/kdroidfilter/seforimlibrary/generator/BuildLuceneIndex.kt">
package io.github.kdroidfilter.seforimlibrary.generator

import app.cash.sqldelight.driver.jdbc.sqlite.JdbcSqliteDriver
import app.cash.sqldelight.db.SqlCursor
import app.cash.sqldelight.db.QueryResult
import co.touchlab.kermit.Logger
import co.touchlab.kermit.Severity
import io.github.kdroidfilter.seforimlibrary.dao.repository.SeforimRepository
import io.github.kdroidfilter.seforimlibrary.generator.lucene.LuceneTextIndexWriter
import io.github.kdroidfilter.seforimlibrary.generator.lucene.LuceneLookupIndexWriter
import io.github.kdroidfilter.seforimlibrary.generator.utils.HebrewTextUtils
import kotlinx.coroutines.runBlocking
import kotlinx.coroutines.async
import kotlinx.coroutines.awaitAll
import kotlinx.coroutines.Dispatchers
import org.apache.lucene.analysis.standard.StandardAnalyzer
import org.apache.lucene.analysis.Analyzer
import org.apache.lucene.analysis.TokenStream
import org.apache.lucene.analysis.core.LowerCaseFilter
import org.apache.lucene.analysis.miscellaneous.PerFieldAnalyzerWrapper
import org.apache.lucene.analysis.ngram.NGramTokenFilter
import org.jsoup.Jsoup
import org.jsoup.safety.Safelist
import java.io.File
import java.nio.file.Files
import java.nio.file.Path
import java.nio.file.Paths

/**
 * Build Lucene indexes using Lucene's StandardAnalyzer and an extra 4-gram field for substring search.
 *
 * Input: path to an existing SQLite DB (seforim.db).
 *
 * Usage:
 *   ./gradlew -p SeforimLibrary :generator:buildLuceneIndexDefault -PseforimDb=/path/to/seforim.db
 *   Optional: -PinMemoryDb=false to read directly from disk (RAM by default)
 */
fun main() = runBlocking {
    Logger.setMinSeverity(Severity.Warn)
    val logger = Logger.withTag("BuildLuceneIndexDefault")

    val dbPath: String =
        System.getProperty("seforimDb")
            ?: System.getenv("SEFORIM_DB")
            ?: Paths.get("build", "seforim.db").toString()

    val dbFile = File(dbPath)
    require(dbFile.exists()) { "Database not found at $dbPath" }

    // Prepare index output paths next to the DB
    // Use a distinct suffix for this index to avoid clashing with other variants
    val indexDir: Path = if (dbPath.endsWith(".db")) Paths.get("$dbPath.lucene") else Paths.get("$dbPath.lucene")
    val lookupDir: Path = if (dbPath.endsWith(".db")) Paths.get("$dbPath.lookup.lucene") else Paths.get("$dbPath.lookup")
    runCatching { Files.createDirectories(indexDir) }
    runCatching { Files.createDirectories(lookupDir) }

    // Open repository (prefer in-memory for faster reads)
    val useMemoryDb = (System.getProperty("inMemoryDb") ?: "true") != "false"
    // Use a shared in-memory DB so multiple connections can read concurrently when multithreading
    val jdbcUrl = if (useMemoryDb) "jdbc:sqlite:file:seforim_index_std?mode=memory&cache=shared" else "jdbc:sqlite:$dbPath"
    val driver = JdbcSqliteDriver(url = jdbcUrl)
    val repo = SeforimRepository(dbPath, driver)

    if (useMemoryDb) {
        // Seed in-memory DB from disk to avoid disk I/O during indexing
        val baseDb = dbPath
        if (File(baseDb).exists()) {
            logger.i { "[IndexDefault] Seeding in-memory DB from $baseDb" }
            runCatching {
                val escaped = baseDb.replace("'", "''")
                repo.executeRawQuery("PRAGMA foreign_keys=OFF")
                repo.executeRawQuery("ATTACH DATABASE '$escaped' AS disk")
                val tables = driver.executeQuery(null,
                    "SELECT name FROM disk.sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%'",
                    { c: SqlCursor ->
                        val list = mutableListOf<String>()
                        while (c.next().value) c.getString(0)?.let { list.add(it) }
                        QueryResult.Value(list)
                    }, 0
                ).value
                for (t in tables) {
                    repo.executeRawQuery("DELETE FROM \"$t\"")
                    repo.executeRawQuery("INSERT INTO \"$t\" SELECT * FROM disk.\"$t\"")
                }
                repo.executeRawQuery("DETACH DATABASE disk")
                repo.executeRawQuery("PRAGMA foreign_keys=ON")
                logger.i { "[IndexDefault] Seed complete: ${'$'}{tables.size} tables copied" }
            }.onFailure { e ->
                logger.e(e) { "[IndexDefault] Failed to seed in-memory DB; falling back to disk reads" }
            }
        } else {
            logger.w { "[IndexDefault] Base DB not found at $baseDb; cannot seed in-memory DB" }
        }
    }

    // Use Lucene's StandardAnalyzer by default; add per-field 4-gram analyzer for substring search
    val defaultAnalyzer = StandardAnalyzer()
    val ngram4Analyzer = object : Analyzer() {
        override fun createComponents(fieldName: String): TokenStreamComponents {
            val src = org.apache.lucene.analysis.standard.StandardTokenizer()
            var ts: TokenStream = src
            ts = LowerCaseFilter(ts)
            ts = NGramTokenFilter(ts, 4, 4, false)
            return TokenStreamComponents(src, ts)
        }
    }
    val analyzer = PerFieldAnalyzerWrapper(
        defaultAnalyzer,
        mapOf(
            LuceneTextIndexWriter.FIELD_TEXT_NG4 to ngram4Analyzer
        )
    )

    LuceneTextIndexWriter(indexDir, analyzer = analyzer).use { writer ->
        LuceneLookupIndexWriter(lookupDir, analyzer = analyzer).use { lookup ->
            val books = repo.getAllBooks()
            val indexThreads = (System.getProperty("indexThreads") ?: Runtime.getRuntime().availableProcessors().toString()).toInt().coerceAtLeast(1)
            val workerDispatcher = Dispatchers.Default.limitedParallelism(indexThreads)
            val totalBooks = books.size
            logger.i { "Indexing $totalBooks books into $indexDir using StandardAnalyzer + 4-gram field" }
            val progress = java.util.concurrent.atomic.AtomicInteger(0)

            books.map { book ->
                async(workerDispatcher) {
                    val current = progress.incrementAndGet()
                    val globalPct = if (totalBooks > 0) (current * 100 / totalBooks) else 0
                    logger.i { "[$current/$totalBooks | ${globalPct}%] Indexing book: '${book.title}' (id=${book.id})" }

                    // Create a separate read-only connection per worker for concurrent reads
                    val localRepo = SeforimRepository(dbPath, JdbcSqliteDriver(url = jdbcUrl))
                    try {
                        // Title terms (stored in text index for future use)
                        writer.addBookTitleTerm(book.id, book.categoryId, book.title, book.title)
                        val titleSan = sanitizeAcronymTerm(book.title)
                        if (titleSan.isNotBlank() && !titleSan.equals(book.title, ignoreCase = true)) {
                            writer.addBookTitleTerm(book.id, book.categoryId, book.title, titleSan)
                        }
                        // Topics ‚Üí title terms for text index
                        runCatching {
                            val topicTerms = book.topics
                                .asSequence()
                                .map { sanitizeAcronymTerm(it.name) }
                                .map { it.trim() }
                                .filter { it.isNotEmpty() }
                                .distinct()
                                .toList()
                            topicTerms.forEach { t -> writer.addBookTitleTerm(book.id, book.categoryId, book.title, t) }
                        }

                        // Lookup: acronyms + topics + title variants
                        runCatching {
                            val acronyms = runCatching { localRepo.getAcronymsForBook(book.id) }.getOrDefault(emptyList())
                            val topicTerms = book.topics.asSequence()
                                .map { sanitizeAcronymTerm(it.name) }
                                .map { it.trim() }
                                .filter { it.isNotEmpty() }
                                .distinct()
                                .toList()
                            val terms = buildList {
                                add(book.title)
                                if (titleSan.isNotBlank()) add(titleSan)
                                addAll(acronyms)
                                addAll(topicTerms)
                            }.filter { it.isNotBlank() }
                            lookup.addBook(book.id, book.categoryId, book.title, terms)
                        }

                        // Lines: process sequentially per book; workers run per-book in parallel
                        val total = book.totalLines
                        if (total > 0) {
                            val allLines = runCatching { localRepo.getLines(book.id, 0, total - 1) }.getOrDefault(emptyList())
                            var processed = 0
                            var nextLogPct = 10
                            for (ln in allLines) {
                                val normalized = normalizeForIndexDefault(ln.content)
                                writer.addLine(
                                    bookId = book.id,
                                    bookTitle = book.title,
                                    categoryId = book.categoryId,
                                    lineId = ln.id,
                                    lineIndex = ln.lineIndex,
                                    normalizedText = normalized,
                                    rawPlainText = null
                                )
                                processed += 1
                                val pct = (processed.toLong() * 100L / total).toInt().coerceIn(0, 100)
                                if (pct >= nextLogPct) {
                                    logger.i { "   Lines ${processed}/$total (${pct}%) for '${book.title}' (bookParallel)" }
                                    nextLogPct = ((pct / 10) + 1) * 10
                                }
                            }
                        }

                        // TOC into lookup
                        runCatching {
                            val tocs = localRepo.getBookToc(book.id)
                            for (t in tocs) {
                                val norm = normalizeForIndexDefault(t.text)
                                lookup.addToc(
                                    tocId = t.id,
                                    bookId = t.bookId,
                                    categoryId = book.categoryId,
                                    bookTitle = book.title,
                                    text = norm,
                                    level = t.level
                                )
                            }
                        }

                        logger.i { "Completed '${book.title}' [$current/$totalBooks | ${globalPct}%]" }
                    } finally {
                        localRepo.close()
                    }
                }
            }.awaitAll()
            writer.commit()
            lookup.commit()
            logger.i { "Lucene text index built successfully at $indexDir (StandardAnalyzer + 4-gram)" }
            logger.i { "Lucene lookup index built successfully at $lookupDir" }
        }
    }

    repo.close()
}

private fun normalizeForIndexDefault(html: String): String {
    val cleaned = Jsoup.clean(html, Safelist.none())
        .trim()
        .replace("\\s+".toRegex(), " ")
    val withoutMaqaf = HebrewTextUtils.replaceMaqaf(cleaned, " ")
    // Drop gershayim (U+05F4) and geresh (U+05F3)
    val withoutGeresh = withoutMaqaf
        .replace("\u05F4", "")
        .replace("\u05F3", "")
    // Normalize final forms (◊ö/◊ù/◊ü/◊£/◊•) -> base letters (◊õ/◊û/◊†/◊§/◊¶)
    val noFinals = normalizeFinalLetters(withoutGeresh)
    // Drop diacritics entirely to index unpointed text
    return HebrewTextUtils.removeAllDiacritics(noFinals)
}

private fun sanitizeAcronymTerm(raw: String): String {
    var s = raw.trim()
    if (s.isEmpty()) return ""
    s = HebrewTextUtils.removeAllDiacritics(s)
    s = HebrewTextUtils.replaceMaqaf(s, " ")
    s = s.replace("\u05F4", "") // gershayim
    s = s.replace("\u05F3", "") // geresh
    s = normalizeFinalLetters(s)
    s = s.replace("\\s+".toRegex(), " ").trim()
    return s
}

/** Replace Hebrew final letters (sofit) by their base forms. */
private fun normalizeFinalLetters(text: String): String = text
    .replace('\u05DA', '\u05DB') // ◊ö -> ◊õ
    .replace('\u05DD', '\u05DE') // ◊ù -> ◊û
    .replace('\u05DF', '\u05E0') // ◊ü -> ◊†
    .replace('\u05E3', '\u05E4') // ◊£ -> ◊§
    .replace('\u05E5', '\u05E6') // ◊• -> ◊¶
</file>

<file path="generator/src/jvmMain/kotlin/io/github/kdroidfilter/seforimlibrary/generator/DownloadAcronymizer.kt">
package io.github.kdroidfilter.seforimlibrary.generator

import co.touchlab.kermit.Logger
import co.touchlab.kermit.Severity

/**
 * Standalone entrypoint that downloads the latest SeforimAcronymizer .db
 * and saves it under build/acronymizer/acronymizer.db. Prints the path.
 */
fun main() {
    Logger.setMinSeverity(Severity.Info)
    val logger = Logger.withTag("DownloadAcronymizer")
    val path = AcronymizerFetcher.ensureLocalDb(logger)
    logger.i { "Acronymizer DB ready at: ${path.toAbsolutePath()}" }
    println(path.toAbsolutePath().toString())
}
</file>

<file path="generator/src/jvmMain/kotlin/io/github/kdroidfilter/seforimlibrary/generator/DownloadOtzaria.kt">
package io.github.kdroidfilter.seforimlibrary.generator

import co.touchlab.kermit.Logger
import co.touchlab.kermit.Severity

/**
 * Standalone entrypoint that downloads the latest otzaria-library release (.zip)
 * and extracts it under build/otzaria/source. Prints the path when done.
 */
fun main() {
    Logger.setMinSeverity(Severity.Info)
    val logger = Logger.withTag("DownloadOtzaria")
    val path = OtzariaFetcher.ensureLocalSource(logger)
    logger.i { "Otzaria ready at: ${path.toAbsolutePath()}" }
    println(path.toAbsolutePath().toString())
}
</file>

<file path="generator/src/jvmMain/kotlin/io/github/kdroidfilter/seforimlibrary/generator/GenerateLines.kt">
package io.github.kdroidfilter.seforimlibrary.generator

import app.cash.sqldelight.driver.jdbc.sqlite.JdbcSqliteDriver
import co.touchlab.kermit.Logger
import co.touchlab.kermit.Severity
import io.github.kdroidfilter.seforimlibrary.dao.repository.SeforimRepository
import io.github.kdroidfilter.seforimlibrary.db.SeforimDb
import kotlinx.coroutines.runBlocking
import java.io.File
import java.nio.file.Paths

/**
 * Phase 1 entry point: generate categories, books, TOCs and lines only.
 *
 * Usage examples:
 *   ./gradlew -p SeforimLibrary :generator:generateLines -PseforimDb=/path/to.db -PsourceDir=/path/to/otzaria [-PacronymDb=/path/acronym.db]
 */
fun main(args: Array<String>) = runBlocking {
    Logger.setMinSeverity(Severity.Info)
    val logger = Logger.withTag("GenerateLines")

    val dbPath = args.getOrNull(0)
        ?: System.getProperty("seforimDb")
        ?: System.getenv("SEFORIM_DB")
        ?: Paths.get("build", "seforim.db").toString()
    val useMemoryDb = (System.getProperty("inMemoryDb") == "true") || dbPath == ":memory:"
    val persistDbPath = System.getProperty("persistDb")
        ?: System.getenv("SEFORIM_DB_OUT")
        ?: Paths.get("build", "seforim.db").toString()
    val sourceDir = args.getOrNull(1)
        ?: System.getProperty("sourceDir")
        ?: System.getenv("OTZARIA_SOURCE_DIR")
        ?: OtzariaFetcher.ensureLocalSource(logger).toString()
    val acronymDbPath = args.getOrNull(2)
        ?: System.getProperty("acronymDb")
        ?: System.getenv("ACRONYM_DB")
        ?: run {
            // Prefer an already-downloaded DB under build/; otherwise fetch latest
            val defaultPath = Paths.get("build", "acronymizer", "acronymizer.db").toFile()
            if (defaultPath.exists() && defaultPath.isFile) defaultPath.absolutePath
            else AcronymizerFetcher.ensureLocalDb(logger).toAbsolutePath().toString()
        }

    // If writing directly to disk, rotate existing DB; for in-memory we will persist at the end
    if (!useMemoryDb) {
        val dbFile = File(dbPath)
        if (dbFile.exists()) {
            val backupFile = File("$dbPath.bak")
            if (backupFile.exists()) backupFile.delete()
            dbFile.renameTo(backupFile)
            logger.i { "Existing DB moved to ${backupFile.absolutePath}" }
        }
    }

    val jdbcUrl = if (useMemoryDb) "jdbc:sqlite::memory:" else "jdbc:sqlite:$dbPath"
    val driver = JdbcSqliteDriver(url = jdbcUrl)
    // Ensure schema exists on a brand-new DB before repository init (idempotent)
    runCatching { SeforimDb.Schema.create(driver) }
    val repository = SeforimRepository(dbPath, driver)

    try {
        val generator = DatabaseGenerator(
            sourceDirectory = Paths.get(sourceDir),
            repository = repository,
            acronymDbPath = acronymDbPath,
            textIndex = null,
            lookupIndex = null
        )
        generator.generateLinesOnly()
        if (useMemoryDb) {
            // Persist in-memory DB to disk using VACUUM INTO (target must not exist)
            runCatching {
                val outFile = File(persistDbPath)
                outFile.parentFile?.mkdirs()
                if (outFile.exists()) {
                    val backup = File(persistDbPath + ".bak")
                    if (backup.exists()) backup.delete()
                    if (!outFile.renameTo(backup)) {
                        // If rename fails, delete to allow VACUUM INTO
                        outFile.delete()
                    }
                    logger.i { "Existing DB moved to ${backup.absolutePath}" }
                }
                val escaped = persistDbPath.replace("'", "''")
                logger.i { "Persisting in-memory DB to $persistDbPath via VACUUM INTO..." }
                repository.executeRawQuery("VACUUM INTO '$escaped'")
                logger.i { "In-memory DB persisted to $persistDbPath" }
            }.onFailure { e ->
                logger.e(e) { "Failed to persist in-memory DB to $persistDbPath" }
                throw e
            }
        }
        logger.i { "Phase 1 completed successfully. DB at ${if (useMemoryDb) persistDbPath else dbPath}" }
    } catch (e: Exception) {
        logger.e(e) { "Error during phase 1 generation" }
        throw e
    } finally {
        repository.close()
    }
}
</file>

<file path="generator/src/jvmMain/kotlin/io/github/kdroidfilter/seforimlibrary/generator/GenerateLinks.kt">
package io.github.kdroidfilter.seforimlibrary.generator

import app.cash.sqldelight.driver.jdbc.sqlite.JdbcSqliteDriver
import app.cash.sqldelight.db.SqlCursor
import app.cash.sqldelight.db.QueryResult
import co.touchlab.kermit.Logger
import co.touchlab.kermit.Severity
import io.github.kdroidfilter.seforimlibrary.dao.repository.SeforimRepository
import kotlinx.coroutines.runBlocking
import java.nio.file.Paths

/**
 * Phase 2 entry point: process links only (requires that books/lines already exist).
 *
 * Usage:
 *   ./gradlew -p SeforimLibrary :generator:generateLinks -PseforimDb=/path/to.db -PsourceDir=/path/to/otzaria
 */
fun main(args: Array<String>) = runBlocking {
    Logger.setMinSeverity(Severity.Info)
    val logger = Logger.withTag("GenerateLinks")

    val dbPath = args.getOrNull(0)
        ?: System.getProperty("seforimDb")
        ?: System.getenv("SEFORIM_DB")
        ?: Paths.get("build", "seforim.db").toString()
    val useMemoryDb = (System.getProperty("inMemoryDb") == "true") || dbPath == ":memory:"
    val persistDbPath = System.getProperty("persistDb")
        ?: System.getenv("SEFORIM_DB_OUT")
        ?: Paths.get("build", "seforim.db").toString()
    val sourceDir = args.getOrNull(1)
        ?: System.getProperty("sourceDir")
        ?: System.getenv("OTZARIA_SOURCE_DIR")
        ?: OtzariaFetcher.ensureLocalSource(logger).toString()

    val jdbcUrl = if (useMemoryDb) "jdbc:sqlite::memory:" else "jdbc:sqlite:$dbPath"
    val driver = JdbcSqliteDriver(url = jdbcUrl)
    val repository = SeforimRepository(dbPath, driver)

    try {
        // If using in-memory DB, seed it from base DB on disk if provided
        if (useMemoryDb) {
            val baseDb = System.getProperty("baseDb")
                ?: System.getenv("SEFORIM_DB_BASE")
                ?: Paths.get("build", "seforim.db").toString()
            val baseFile = java.io.File(baseDb)
            if (baseFile.exists()) {
                logger.i { "Seeding in-memory DB from base file: $baseDb" }
                runCatching {
                    repository.executeRawQuery("PRAGMA foreign_keys=OFF")
                    val escaped = baseDb.replace("'", "''")
                    repository.executeRawQuery("ATTACH DATABASE '$escaped' AS disk")
                    // Load all table names from attached DB
                    val tables = driver.executeQuery(null,
                        "SELECT name FROM disk.sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%'",
                        { c: SqlCursor ->
                            val list = mutableListOf<String>()
                            while (c.next().value) {
                                c.getString(0)?.let { list.add(it) }
                            }
                            QueryResult.Value(list)
                        }, 0
                    ).value
                    // Copy data for each table into main
                    for (t in tables) {
                        val tn = t
                        repository.executeRawQuery("DELETE FROM \"$tn\"")
                        repository.executeRawQuery("INSERT INTO \"$tn\" SELECT * FROM disk.\"$tn\"")
                    }
                    repository.executeRawQuery("DETACH DATABASE disk")
                    repository.executeRawQuery("PRAGMA foreign_keys=ON")
                    logger.i { "Seeding completed. Imported ${'$'}{tables.size} tables." }
                }.onFailure { e ->
                    logger.e(e) { "Failed to seed in-memory DB from $baseDb. Links may not be processed." }
                }
            } else {
                logger.w { "Base DB not found at $baseDb; running with empty in-memory DB" }
            }
        }

        val generator = DatabaseGenerator(
            sourceDirectory = Paths.get(sourceDir),
            repository = repository,
            acronymDbPath = null,
            textIndex = null,
            lookupIndex = null
        )
        generator.generateLinksOnly()
        if (useMemoryDb) {
            // Persist in-memory DB to disk using VACUUM INTO (target must not exist)
            runCatching {
                val outFile = java.io.File(persistDbPath)
                outFile.parentFile?.mkdirs()
                if (outFile.exists()) {
                    // No backup required: remove existing file to allow VACUUM INTO
                    val deleted = runCatching { java.nio.file.Files.deleteIfExists(outFile.toPath()) }.getOrDefault(false)
                    if (!deleted) {
                        throw IllegalStateException("Cannot remove existing DB at ${outFile.absolutePath} before persisting")
                    }
                    logger.i { "Removed existing DB at ${outFile.absolutePath}" }
                }
                val escaped = persistDbPath.replace("'", "''")
                logger.i { "Persisting in-memory DB to $persistDbPath via VACUUM INTO..." }
                repository.executeRawQuery("VACUUM INTO '$escaped'")
                logger.i { "In-memory DB persisted to $persistDbPath" }
            }.onFailure { e ->
                logger.e(e) { "Failed to persist in-memory DB to $persistDbPath" }
                throw e
            }
        }
        logger.i { "Phase 2 completed successfully. Links processed. DB at ${if (useMemoryDb) persistDbPath else dbPath}" }
    } catch (e: Exception) {
        logger.e(e) { "Error during phase 2 (links)" }
        throw e
    } finally {
        repository.close()
    }
}
</file>

<file path="generator/src/jvmMain/kotlin/io/github/kdroidfilter/seforimlibrary/generator/lucene/LuceneLookupIndexWriter.kt">
package io.github.kdroidfilter.seforimlibrary.generator.lucene

import org.apache.lucene.analysis.Analyzer
import org.apache.lucene.analysis.standard.StandardAnalyzer
import org.apache.lucene.document.*
import org.apache.lucene.index.IndexWriter
import org.apache.lucene.index.IndexWriterConfig
import org.apache.lucene.store.FSDirectory
import java.nio.file.Path

class LuceneLookupIndexWriter(indexDir: Path, analyzer: Analyzer = StandardAnalyzer()) : LookupIndexWriter {
    companion object F {
        const val FIELD_TYPE = "type"
        const val TYPE_BOOK = "book"
        const val TYPE_TOC = "toc"

        const val FIELD_BOOK_ID = "book_id"
        const val FIELD_CATEGORY_ID = "category_id"
        const val FIELD_BOOK_TITLE = "book_title" // stored
        const val FIELD_Q = "q" // analyzed text for lookup (title/acronyms/toc)

        const val FIELD_TOC_ID = "toc_id"
        const val FIELD_TOC_TEXT = "toc_text" // stored
        const val FIELD_TOC_LEVEL = "toc_level"
    }

    private val dir = FSDirectory.open(indexDir)
    private val writer: IndexWriter

    init {
        val cfg = IndexWriterConfig(analyzer)
        writer = IndexWriter(dir, cfg)
    }

    override fun addBook(bookId: Long, categoryId: Long, displayTitle: String, terms: Collection<String>) {
        val doc = Document().apply {
            add(StringField(FIELD_TYPE, TYPE_BOOK, Field.Store.NO))
            add(StoredField(FIELD_BOOK_ID, bookId))
            add(IntPoint(FIELD_BOOK_ID, bookId.toInt()))
            add(StoredField(FIELD_CATEGORY_ID, categoryId))
            add(IntPoint(FIELD_CATEGORY_ID, categoryId.toInt()))
            add(StoredField(FIELD_BOOK_TITLE, displayTitle))
            // Index all terms into a single analyzed field for prefix queries
            terms.forEach { t -> add(TextField(FIELD_Q, t, Field.Store.NO)) }
        }
        writer.addDocument(doc)
    }

    override fun addToc(
        tocId: Long,
        bookId: Long,
        categoryId: Long,
        bookTitle: String,
        text: String,
        level: Int
    ) {
        val doc = Document().apply {
            add(StringField(FIELD_TYPE, TYPE_TOC, Field.Store.NO))
            add(StoredField(FIELD_TOC_ID, tocId))
            add(IntPoint(FIELD_TOC_ID, tocId.toInt()))
            add(StoredField(FIELD_BOOK_ID, bookId))
            add(IntPoint(FIELD_BOOK_ID, bookId.toInt()))
            add(StoredField(FIELD_CATEGORY_ID, categoryId))
            add(IntPoint(FIELD_CATEGORY_ID, categoryId.toInt()))
            add(StoredField(FIELD_BOOK_TITLE, bookTitle))
            add(StoredField(FIELD_TOC_TEXT, text))
            add(StoredField(FIELD_TOC_LEVEL, level))
            add(TextField(FIELD_Q, text, Field.Store.NO))
        }
        writer.addDocument(doc)
    }

    override fun commit() {
        writer.commit()
    }

    override fun close() {
        writer.close(); dir.close()
    }
}
</file>

<file path="generator/src/jvmMain/kotlin/io/github/kdroidfilter/seforimlibrary/generator/lucene/LuceneTextIndexWriter.kt">
package io.github.kdroidfilter.seforimlibrary.generator.lucene

import org.apache.lucene.analysis.Analyzer
import org.apache.lucene.analysis.standard.StandardAnalyzer
import org.apache.lucene.document.Document
import org.apache.lucene.document.Field
import org.apache.lucene.document.IntPoint
import org.apache.lucene.document.StoredField
import org.apache.lucene.document.StringField
import org.apache.lucene.document.TextField
import org.apache.lucene.index.IndexWriter
import org.apache.lucene.index.IndexWriterConfig
import org.apache.lucene.store.FSDirectory
import java.nio.file.Path

/**
 * Lucene-backed implementation of [TextIndexWriter].
 * Stores two kinds of documents in the same index:
 *  - type=line: searchable book line (text field analyzed) + stored metadata
 *  - type=book_title: terms for title/acronym suggestions (analyzed field 'title')
 */
class LuceneTextIndexWriter(
    indexDir: Path,
    analyzer: Analyzer = StandardAnalyzer(),
    private val indexHebrewField: Boolean = false,
    private val indexPrimaryText: Boolean = true
) : TextIndexWriter {
    companion object Fields {
        const val FIELD_TYPE = "type"
        const val TYPE_LINE = "line"
        const val TYPE_BOOK_TITLE = "book_title"

        const val FIELD_BOOK_ID = "book_id"
        const val FIELD_CATEGORY_ID = "category_id"
        const val FIELD_BOOK_TITLE = "book_title"
        const val FIELD_LINE_ID = "line_id"
        const val FIELD_LINE_INDEX = "line_index"
        const val FIELD_TEXT = "text"
        const val FIELD_TEXT_RAW = "text_raw"
        const val FIELD_TEXT_HE = "text_he"
        const val FIELD_TEXT_NG4 = "text_ng4"
        const val FIELD_TITLE = "title" // analyzed suggestion term
    }

    private val dir = FSDirectory.open(indexDir)
    private val writer: IndexWriter

    init {
        val cfg = IndexWriterConfig(analyzer)
        writer = IndexWriter(dir, cfg)
    }

    override fun addLine(
        bookId: Long,
        bookTitle: String,
        categoryId: Long,
        lineId: Long,
        lineIndex: Int,
        normalizedText: String,
        rawPlainText: String?,
        normalizedTextHebrew: String?
    ) {
        val doc = Document().apply {
            add(StringField(FIELD_TYPE, TYPE_LINE, Field.Store.NO))

            add(StoredField(FIELD_BOOK_ID, bookId))
            add(IntPoint(FIELD_BOOK_ID, bookId.toInt()))
            add(StoredField(FIELD_CATEGORY_ID, categoryId))
            add(IntPoint(FIELD_CATEGORY_ID, categoryId.toInt()))
            add(StoredField(FIELD_BOOK_TITLE, bookTitle))

            add(StoredField(FIELD_LINE_ID, lineId))
            add(IntPoint(FIELD_LINE_ID, lineId.toInt()))
            add(StoredField(FIELD_LINE_INDEX, lineIndex))
            add(IntPoint(FIELD_LINE_INDEX, lineIndex))

            if (indexPrimaryText) {
                add(TextField(FIELD_TEXT, normalizedText, Field.Store.NO))
            }
            // Optional secondary text field
            val hebText = normalizedTextHebrew ?: if (indexHebrewField) normalizedText else null
            hebText?.let { add(TextField(FIELD_TEXT_HE, it, Field.Store.NO)) }
            // Index 4-gram tokens for substring search (per-field analyzer applies NGram filter)
            add(TextField(FIELD_TEXT_NG4, normalizedText, Field.Store.NO))
            rawPlainText?.let { add(StoredField(FIELD_TEXT_RAW, it)) }
        }
        writer.addDocument(doc)
    }

    override fun addBookTitleTerm(bookId: Long, categoryId: Long, displayTitle: String, term: String) {
        val doc = Document().apply {
            add(StringField(FIELD_TYPE, TYPE_BOOK_TITLE, Field.Store.NO))
            add(StoredField(FIELD_BOOK_ID, bookId))
            add(IntPoint(FIELD_BOOK_ID, bookId.toInt()))
            add(StoredField(FIELD_CATEGORY_ID, categoryId))
            add(IntPoint(FIELD_CATEGORY_ID, categoryId.toInt()))
            add(StoredField(FIELD_BOOK_TITLE, displayTitle))
            add(TextField(FIELD_TITLE, term, Field.Store.NO))
        }
        writer.addDocument(doc)
    }

    override fun commit() {
        writer.commit()
    }

    override fun close() {
        writer.close()
        dir.close()
    }
}
</file>

<file path="generator/src/jvmMain/kotlin/io/github/kdroidfilter/seforimlibrary/generator/OtzariaFetcher.kt">
package io.github.kdroidfilter.seforimlibrary.generator

import co.touchlab.kermit.Logger
import java.io.BufferedInputStream
import java.io.FileOutputStream
import java.net.URI
import java.net.http.HttpClient
import java.net.http.HttpRequest
import java.net.http.HttpResponse
import java.nio.file.Files
import java.nio.file.Path
import java.nio.file.Paths
import java.util.Comparator
import java.util.zip.ZipEntry
import java.util.zip.ZipInputStream

object OtzariaFetcher {
    private const val LATEST_API = "https://api.github.com/repos/Y-PLONI/otzaria-library/releases/latest"

    /** Ensure otzaria source is available locally under build/otzaria/source (relative to CWD). */
    fun ensureLocalSource(logger: Logger): Path {
        val destRoot = Paths.get("build", "otzaria", "source")
        if (Files.isDirectory(destRoot) && Files.list(destRoot).use { it.findAny().isPresent }) {
            val root = findSourceRoot(destRoot)
            removeUnwantedFolder(root, logger)
            logger.i { "Using existing otzaria source at ${root.toAbsolutePath()}" }
            return root
        }
        Files.createDirectories(destRoot)
        val zipPath = destRoot.parent.resolve("otzaria.zip")
        downloadLatestZip(zipPath, logger)
        extractZip(zipPath, destRoot, logger)
        val root = findSourceRoot(destRoot)
        removeUnwantedFolder(root, logger)
        return root
    }

    private fun findSourceRoot(extractRoot: Path): Path {
        // If this folder already looks like the source (contains metadata.json and ◊ê◊ï◊¶◊®◊ô◊ê), return it
        val meta = extractRoot.resolve("metadata.json")
        val libDir = extractRoot.resolve("◊ê◊ï◊¶◊®◊ô◊ê")
        if (Files.exists(meta) && Files.isRegularFile(meta) && Files.isDirectory(libDir)) return extractRoot

        // Otherwise, check first-level subdirectories for the expected layout
        Files.newDirectoryStream(extractRoot).use { ds ->
            for (p in ds) {
                if (Files.isDirectory(p)) {
                    val m = p.resolve("metadata.json")
                    val l = p.resolve("◊ê◊ï◊¶◊®◊ô◊ê")
                    if (Files.exists(m) && Files.isRegularFile(m) && Files.isDirectory(l)) return p
                }
            }
        }
        return extractRoot
    }

    private fun downloadLatestZip(outZip: Path, logger: Logger) {
        val client = HttpClient.newBuilder()
            .version(HttpClient.Version.HTTP_2)
            .followRedirects(HttpClient.Redirect.NORMAL)
            .build()
        val token = System.getenv("GITHUB_TOKEN") ?: System.getenv("GH_TOKEN")
        val req = HttpRequest.newBuilder(URI(LATEST_API))
            .header("Accept", "application/vnd.github+json")
            .header("User-Agent", "SeforimLibrary-OtzariaFetcher/1.0")
            .apply {
                if (!token.isNullOrBlank()) header("Authorization", "Bearer $token")
            }
            .build()
        val res = client.send(req, HttpResponse.BodyHandlers.ofString())
        if (res.statusCode() !in 200..299) {
            throw IllegalStateException("GitHub API error: HTTP ${res.statusCode()}\n${res.body()}")
        }
        val body = res.body()
        val regex = Regex(""""browser_download_url"\s*:\s*"([^"]+\.zip)"""")
        val zipUrl = regex.findAll(body).map { it.groupValues[1] }.firstOrNull()
            ?: throw IllegalStateException("No .zip asset found in latest otzaria-library release")
        logger.i { "Downloading otzaria from $zipUrl" }

        val zipReq = HttpRequest.newBuilder(URI(zipUrl))
            .header("Accept", "application/octet-stream")
            .header("User-Agent", "SeforimLibrary-OtzariaFetcher/1.0")
            .apply {
                if (!token.isNullOrBlank()) header("Authorization", "Bearer $token")
            }
            .build()
        val zipRes = client.send(zipReq, HttpResponse.BodyHandlers.ofInputStream())
        if (zipRes.statusCode() !in 200..299) {
            throw IllegalStateException("Failed to download otzaria zip: HTTP ${zipRes.statusCode()}")
        }
        Files.createDirectories(outZip.parent)
        // Progress-aware copy with percentage and speed
        val contentLength = zipRes.headers().firstValue("Content-Length").orElse(null)?.toLongOrNull() ?: -1L
        if (contentLength > 0) {
            val totalMb = contentLength.toDouble() / (1024 * 1024)
            logger.i { "Download size: ${"%.1f".format(totalMb)} MB" }
        }

        zipRes.body().use { input ->
            Files.newOutputStream(outZip).use { output ->
                val buffer = ByteArray(1 shl 20) // 1 MiB
                var downloaded = 0L
                var lastLoggedBytes = 0L
                var lastLogTime = System.nanoTime()
                var nextPctLog = 0
                val startTime = lastLogTime

                while (true) {
                    val read = input.read(buffer)
                    if (read <= 0) break
                    output.write(buffer, 0, read)
                    downloaded += read

                    val now = System.nanoTime()
                    val elapsedSince = (now - lastLogTime) / 1_000_000_000.0
                    val overallSec = (now - startTime) / 1_000_000_000.0

                    val pct = if (contentLength > 0) ((downloaded * 100.0) / contentLength).toInt().coerceIn(0, 100) else -1
                    val shouldLogPct = contentLength > 0 && pct >= nextPctLog
                    val shouldLogTime = elapsedSince >= 1.0
                    if (shouldLogPct || shouldLogTime) {
                        val deltaBytes = downloaded - lastLoggedBytes
                        val speed = if (elapsedSince > 0) deltaBytes / elapsedSince else 0.0 // bytes/sec
                        val speedMb = speed / (1024 * 1024)
                        val downloadedMb = downloaded.toDouble() / (1024 * 1024)
                        val totalMb = if (contentLength > 0) contentLength.toDouble() / (1024 * 1024) else -1.0

                        val msg = buildString {
                            append("Downloading otzaria: ")
                            if (pct >= 0) append("$pct% ")
                            append("@ ${"%.2f".format(speedMb)} MB/s ")
                            append("(${"%.1f".format(downloadedMb)}")
                            if (totalMb > 0) append("/${"%.1f".format(totalMb)}")
                            append(" MB)")
                        }
                        logger.i { msg }
                        lastLoggedBytes = downloaded
                        lastLogTime = now
                        if (contentLength > 0) nextPctLog = ((pct / 5) + 1) * 5 // log every 5%
                    }
                }
            }
        }
        logger.i { "Saved otzaria zip to ${outZip.toAbsolutePath()}" }
    }

    private fun extractZip(zipFile: Path, destinationDir: Path, logger: Logger) {
        logger.i { "Extracting otzaria to ${destinationDir.toAbsolutePath()}" }
        ZipInputStream(BufferedInputStream(Files.newInputStream(zipFile))).use { zis ->
            var entry: ZipEntry? = zis.nextEntry
            while (entry != null) {
                val newPath = destinationDir.resolve(entry.name).normalize()
                if (entry.isDirectory) {
                    Files.createDirectories(newPath)
                } else {
                    Files.createDirectories(newPath.parent)
                    FileOutputStream(newPath.toFile()).use { fos ->
                        // Increase buffer to speed up extraction of large entries
                        zis.copyTo(fos, 1 shl 20) // 1 MiB buffer
                    }
                }
                zis.closeEntry()
                entry = zis.nextEntry
            }
        }
        logger.i { "Extraction complete." }
    }

    private fun removeUnwantedFolder(root: Path, logger: Logger) {
        val base = root.resolve("◊ê◊ï◊¶◊®◊ô◊ê")
        val namesToRemove = loadOtzariaFoldersToRemove(logger)
        for (name in namesToRemove) {
            val trimmed = name.trim()
            if (trimmed.isEmpty()) continue
            val dir = base.resolve(trimmed)
            if (Files.exists(dir)) {
                runCatching {
                    Files.walk(dir)
                        .sorted(Comparator.reverseOrder())
                        .forEach { Files.deleteIfExists(it) }
                    logger.i { "Removed unwanted folder: ${dir.toAbsolutePath()}" }
                }.onFailure { e ->
                    logger.w(e) { "Failed removing unwanted folder at ${dir.toAbsolutePath()}" }
                }
            }
        }
    }

    private fun loadOtzariaFoldersToRemove(logger: Logger): List<String> {
        // Use only the resource file (no hardcoded fallback)
        return try {
            val resourceNames = listOf("otzaria-folder-to-remove.txt", "/otzaria-folder-to-remove.txt")
            val cl = Thread.currentThread().contextClassLoader
            val stream = resourceNames.asSequence()
                .mapNotNull { name -> cl?.getResourceAsStream(name) ?: this::class.java.getResourceAsStream(name) }
                .firstOrNull()
            if (stream == null) {
                logger.i { "No otzaria-folder-to-remove.txt resource found; no folders will be removed" }
                return emptyList()
            }
            stream.bufferedReader(Charsets.UTF_8).use { br ->
                br.lineSequence()
                    .map { it.trim() }
                    .filter { it.isNotEmpty() && !it.startsWith("#") }
                    .toList()
            }
        } catch (e: Exception) {
            logger.w(e) { "Failed to load otzaria-folder-to-remove.txt; no folders will be removed" }
            emptyList()
        }
    }
}
</file>

<file path="generator/src/jvmMain/kotlin/io/github/kdroidfilter/seforimlibrary/generator/PackageArtifacts.kt">
package io.github.kdroidfilter.seforimlibrary.generator

import co.touchlab.kermit.Logger
import co.touchlab.kermit.Severity
import com.github.luben.zstd.ZstdOutputStream
import org.apache.commons.compress.archivers.tar.TarArchiveEntry
import org.apache.commons.compress.archivers.tar.TarArchiveOutputStream
import java.io.BufferedOutputStream
import java.io.BufferedInputStream
import java.io.IOException
import java.nio.file.Files
import java.nio.file.Path
import java.nio.file.Paths
import java.time.Instant
import java.util.Date
import kotlin.io.path.exists
import kotlin.system.exitProcess

/**
 * Package artifacts with Zstandard (zstd):
 *  - Compress the SQLite DB (seforim.db) directly to a single .zst file (no tar)
 *  - Archive Lucene indexes into a .tar and compress it with zstd (.tar.zst)
 *
 * Usage:
 *   ./gradlew -p SeforimLibrary :generator:packageArtifacts \
 *     -PseforimDb=/path/to/seforim.db \
 *     [-PdbOutput=/path/to/seforim.db.zst] \
 *     [-PindexesOutput=/path/to/lucene_indexes.tar.zst] \
 *     [-PzstdLevel=19]
 *
 * Env alternatives:
 *   SEFORIM_DB, OUTPUT_DB_ZST, OUTPUT_INDEXES_TAR_ZST, ZSTD_LEVEL, ZSTD_WORKERS
 *   (legacy: OUTPUT_TAR_ZST or -Poutput maps to indexesOutput for compatibility)
 *
 * Defaults:
 *   DB path from -PseforimDb, env SEFORIM_DB, or generator/build/seforim.db
 *   DB .zst to generator/build/package/seforim.db.zst
 *   Indexes .tar.zst to generator/build/package/lucene_indexes.tar.zst
 */
fun main(args: Array<String>) {
    Logger.setMinSeverity(Severity.Info)
    val logger = Logger.withTag("PackageArtifacts")

    // Resolve DB path
    val dbPathStr = args.getOrNull(0)
        ?: System.getProperty("seforimDb")
        ?: System.getenv("SEFORIM_DB")
        ?: Paths.get("build", "seforim.db").toString()
    val dbPath = Paths.get(dbPathStr)
    if (!dbPath.exists()) {
        logger.e { "DB not found at $dbPath" }
        exitProcess(1)
    }

    // Resolve index directories next to the DB
    val textIndexDir: Path = if (dbPathStr.endsWith(".db")) Paths.get("$dbPathStr.lucene") else Paths.get("$dbPathStr.luceneindex")
    val lookupIndexDir: Path = if (dbPathStr.endsWith(".db")) Paths.get("$dbPathStr.lookup.lucene") else Paths.get("$dbPathStr.lookupindex")

    if (!textIndexDir.toFile().isDirectory) {
        logger.w { "Lucene text index directory missing: $textIndexDir (will skip)" }
    }
    if (!lookupIndexDir.toFile().isDirectory) {
        logger.w { "Lucene lookup index directory missing: $lookupIndexDir (will skip)" }
    }

    // Output: single bundle tar.zst
    val legacyOutput = System.getProperty("output") ?: System.getenv("OUTPUT_TAR_ZST")
    val bundleOutputStr = System.getProperty("bundleOutput")
        ?: System.getenv("OUTPUT_BUNDLE_TAR_ZST")
        ?: legacyOutput
        ?: Paths.get("build", "package", "seforim_bundle.tar.zst").toString()
    val bundleOutputPath = Paths.get(bundleOutputStr)
    Files.createDirectories(bundleOutputPath.parent)

    // Compression level (default ultra 22)
    val zstdLevel = (
        System.getProperty("zstdLevel")
            ?: System.getenv("ZSTD_LEVEL")
            ?: "22"
        ).toIntOrNull()?.coerceIn(1, 22) ?: 22

    // Workers (threads). Default: all available processors (like zstd -T0)
    val workers = (
        System.getProperty("zstdWorkers")
            ?: System.getenv("ZSTD_WORKERS")
            ?: "0"
    ).toIntOrNull()?.let { if (it <= 0) Runtime.getRuntime().availableProcessors() else it }
        ?: Runtime.getRuntime().availableProcessors()

    // Split part size (~1.9 GiB by default)
    val defaultSplitSize = (1.9 * 1024.0 * 1024.0 * 1024.0).toLong()
    val splitPartBytes = (
        System.getProperty("splitPartBytes")
            ?: System.getenv("SPLIT_PART_BYTES")
            ?: defaultSplitSize.toString()
        ).toLongOrNull()?.takeIf { it > 0 } ?: defaultSplitSize

    logger.i {
        "Packaging into single bundle:\n" +
            " - DB: $dbPath\n" +
            " - Text index: $textIndexDir\n" +
            " - Lookup index: $lookupIndexDir\n" +
            " -> Bundle .tar.zst: $bundleOutputPath\n" +
            " (zstd level $zstdLevel, workers $workers, split ${humanSize(splitPartBytes)})"
    }

    try {
        // Tar + zstd the three artifacts into a single bundle
        Files.newOutputStream(bundleOutputPath).use { fos ->
            BufferedOutputStream(fos, 1 shl 20).use { bos ->
                ZstdOutputStream(bos, zstdLevel).use { zstd ->
                    runCatching { zstd.setWorkers(workers) }
                        .onFailure { logger.w(it) { "zstd setWorkers($workers) failed; continuing single-threaded" } }
                    TarArchiveOutputStream(zstd).use { tar ->
                        tar.setLongFileMode(TarArchiveOutputStream.LONGFILE_POSIX)
                        tar.setBigNumberMode(TarArchiveOutputStream.BIGNUMBER_POSIX)

                        val haveText = textIndexDir.toFile().isDirectory
                        val haveLookup = lookupIndexDir.toFile().isDirectory

                        if (haveLookup) {
                            addDirectoryToTar(tar, lookupIndexDir, lookupIndexDir.fileName.toString(), logger)
                        } else {
                            logger.w { "Lucene lookup index directory missing: $lookupIndexDir (skipped)" }
                        }
                        if (haveText) {
                            addDirectoryToTar(tar, textIndexDir, textIndexDir.fileName.toString(), logger)
                        } else {
                            logger.w { "Lucene text index directory missing: $textIndexDir (skipped)" }
                        }

                        // Add the database file itself
                        addFileToTar(tar, dbPath, dbPath.fileName.toString(), logger)
                        tar.finish()
                    }
                }
            }
        }

        val bundleSizeMb = Files.size(bundleOutputPath).toDouble() / (1024 * 1024)
        logger.i { "Bundle written: $bundleOutputPath (${"%.2f".format(bundleSizeMb)} MB)" }
        println(bundleOutputPath.toAbsolutePath().toString())

        // Split the bundle into parts of ~1.9 GiB (or configured size)
        val partCount = splitFile(bundleOutputPath, splitPartBytes, logger)
        if (partCount > 1) {
            logger.i { "Bundle split into $partCount parts of up to ${humanSize(splitPartBytes)} each" }
        } else {
            logger.i { "Bundle size below split threshold; no split files created" }
        }
    } catch (e: Exception) {
        logger.e(e) { "Failed to package artifacts" }
        exitProcess(1)
    }
}

private fun addDirectoryToTar(tar: TarArchiveOutputStream, dir: Path, entryName: String, logger: Logger) {
    val normalized = entryName.trimEnd('/')
    val dirEntry = TarArchiveEntry("$normalized/")
    dirEntry.modTime = Date.from(Instant.now())
    try {
        tar.putArchiveEntry(dirEntry)
        tar.closeArchiveEntry()
    } catch (e: IOException) {
        logger.w(e) { "Skipping directory entry $normalized/ due to error" }
        return
    }

    Files.list(dir).use { stream ->
        stream.forEach { child ->
            val childName = "$normalized/${child.fileName}"
            if (Files.isDirectory(child)) {
                addDirectoryToTar(tar, child, childName, logger)
            } else {
                addFileToTar(tar, child, childName, logger)
            }
        }
    }
}

private fun addFileToTar(tar: TarArchiveOutputStream, file: Path, entryName: String, logger: Logger) {
    val f = file.toFile()
    if (!f.exists() || !f.isFile) {
        logger.w { "Skipping missing file: $file" }
        return
    }
    val entry = TarArchiveEntry(f, entryName)
    // Ensure size is set for some JVMs
    entry.size = f.length()
    entry.modTime = Date(f.lastModified())
    tar.putArchiveEntry(entry)
    val declared = entry.size
    Files.newInputStream(file).use { input ->
        val buffer = ByteArray(1 shl 20)
        var remaining = declared
        while (remaining > 0) {
            val toRead = if (remaining > buffer.size) buffer.size else remaining.toInt()
            val read = input.read(buffer, 0, toRead)
            if (read <= 0) break
            tar.write(buffer, 0, read)
            remaining -= read
        }
    }
    tar.closeArchiveEntry()
}

private fun splitFile(source: Path, partSizeBytes: Long, logger: Logger): Int {
    val size = try { Files.size(source) } catch (e: IOException) { 0L }
    if (size <= partSizeBytes || size <= 0L) return 1

    val parent = source.parent ?: Paths.get(".")
    val baseName = source.fileName.toString()

    val buffer = ByteArray(8 * 1024 * 1024) // 8 MiB
    var index = 1
    var bytesInPart = 0L
    var currentOut: BufferedOutputStream? = null

    fun openNext(): BufferedOutputStream {
        val suffix = String.format(".part%02d", index)
        val outPath = parent.resolve(baseName + suffix)
        val bos = BufferedOutputStream(Files.newOutputStream(outPath), buffer.size)
        logger.i { "Writing part $index -> ${outPath.toAbsolutePath()}" }
        return bos
    }

    BufferedInputStream(Files.newInputStream(source), buffer.size).use { input ->
        currentOut = openNext()
        while (true) {
            val remainingInPart = partSizeBytes - bytesInPart
            val toRead = if (remainingInPart < buffer.size) remainingInPart.toInt() else buffer.size
            val read = input.read(buffer, 0, toRead)
            if (read <= 0) break
            currentOut!!.write(buffer, 0, read)
            bytesInPart += read
            if (bytesInPart >= partSizeBytes) {
                currentOut!!.flush()
                currentOut!!.close()
                index += 1
                bytesInPart = 0
                currentOut = openNext()
            }
        }
    }
    currentOut?.flush()
    currentOut?.close()
    return index
}

private fun humanSize(bytes: Long): String {
    val kb = 1024.0
    val mb = kb * 1024
    val gb = mb * 1024
    return when {
        bytes >= gb -> String.format("%.2f GiB", bytes / gb)
        bytes >= mb -> String.format("%.2f MiB", bytes / mb)
        bytes >= kb -> String.format("%.2f KiB", bytes / kb)
        else -> "$bytes B"
    }
}
</file>

<file path="gradle.properties">
#Gradle
org.gradle.jvmargs=-Xmx12G
org.gradle.caching=true
org.gradle.configuration-cache=true
org.gradle.daemon=true
org.gradle.parallel=true

#Kotlin
kotlin.code.style=official
kotlin.daemon.jvmargs=-Xmx12G
kotlin.native.binary.gc=cms
kotlin.incremental.wasm=true

#Android
android.useAndroidX=true
android.nonTransitiveRClass=true
</file>

<file path="gradle/libs.versions.toml">
[versions]

kotlin = "2.2.20"
agp = "8.12.3"
luceneCore = "10.3.1"
luceneAnalysisCommon = "10.3.1"
luceneQueryparser = "10.3.1"
luceneHighlighter = "10.3.1"
maven-publish = "0.34.0"
kotlinx-coroutines = "1.10.2"
kotlinx-serialization = "1.9.0"
kotlinx-datetime = "0.7.1"
kermit = "2.0.8"
sqlDelight = "2.1.0"
compose = "1.9.1"
androidx-activityCompose = "1.11.0"

[libraries]

kotlinx-coroutines-core = { module = "org.jetbrains.kotlinx:kotlinx-coroutines-core", version.ref = "kotlinx-coroutines" }
kotlinx-coroutines-android = { module = "org.jetbrains.kotlinx:kotlinx-coroutines-android", version.ref = "kotlinx-coroutines" }
kotlinx-coroutines-swing = { module = "org.jetbrains.kotlinx:kotlinx-coroutines-swing", version.ref = "kotlinx-coroutines" }
kotlinx-coroutines-test = { module = "org.jetbrains.kotlinx:kotlinx-coroutines-test", version.ref = "kotlinx-coroutines" }
kotlinx-serialization-json = { module = "org.jetbrains.kotlinx:kotlinx-serialization-json", version.ref = "kotlinx-serialization" }
kotlinx-datetime = { module = "org.jetbrains.kotlinx:kotlinx-datetime", version.ref = "kotlinx-datetime" }
kermit = { module = "co.touchlab:kermit", version.ref = "kermit" }
lucene-highlighter = { module = "org.apache.lucene:lucene-highlighter", version.ref = "luceneHighlighter" }
lucene-queryparser = { module = "org.apache.lucene:lucene-queryparser", version.ref = "luceneQueryparser" }
lucene-analysis-common = { module = "org.apache.lucene:lucene-analysis-common", version.ref = "luceneAnalysisCommon" }
lucene-core = { module = "org.apache.lucene:lucene-core", version.ref = "luceneCore" }
sqlDelight-driver-sqlite = { module = "app.cash.sqldelight:sqlite-driver", version.ref = "sqlDelight" }
sqlDelight-driver-android = { module = "app.cash.sqldelight:android-driver", version.ref = "sqlDelight" }
sqlDelight-driver-native = { module = "app.cash.sqldelight:native-driver", version.ref = "sqlDelight" }
sqlDelight-driver-js = { module = "app.cash.sqldelight:web-worker-driver", version.ref = "sqlDelight" }
androidx-activityCompose = { module = "androidx.activity:activity-compose", version.ref = "androidx-activityCompose" }

[plugins]

multiplatform = { id = "org.jetbrains.kotlin.multiplatform", version.ref = "kotlin" }
android-library = { id = "com.android.library", version.ref = "agp" }
maven-publish = { id = "com.vanniktech.maven.publish", version.ref = "maven-publish" }
kotlinx-serialization = { id = "org.jetbrains.kotlin.plugin.serialization", version.ref = "kotlin" }
sqlDelight = { id = "app.cash.sqldelight", version.ref = "sqlDelight" }
compose = { id = "org.jetbrains.compose", version.ref = "compose" }
compose-compiler = { id = "org.jetbrains.kotlin.plugin.compose", version.ref = "kotlin" }
android-application = { id = "com.android.application", version.ref = "agp" }
</file>

<file path="gradle/wrapper/gradle-wrapper.properties">
distributionBase=GRADLE_USER_HOME
distributionPath=wrapper/dists
distributionUrl=https\://services.gradle.org/distributions/gradle-8.14.2-bin.zip
networkTimeout=10000
validateDistributionUrl=true
zipStoreBase=GRADLE_USER_HOME
zipStorePath=wrapper/dists
</file>

<file path="gradlew">
#!/bin/sh

#
# Copyright ¬© 2015-2021 the original authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

##############################################################################
#
#   Gradle start up script for POSIX generated by Gradle.
#
#   Important for running:
#
#   (1) You need a POSIX-compliant shell to run this script. If your /bin/sh is
#       noncompliant, but you have some other compliant shell such as ksh or
#       bash, then to run this script, type that shell name before the whole
#       command line, like:
#
#           ksh Gradle
#
#       Busybox and similar reduced shells will NOT work, because this script
#       requires all of these POSIX shell features:
#         * functions;
#         * expansions ¬´$var¬ª, ¬´${var}¬ª, ¬´${var:-default}¬ª, ¬´${var+SET}¬ª,
#           ¬´${var#prefix}¬ª, ¬´${var%suffix}¬ª, and ¬´$( cmd )¬ª;
#         * compound commands having a testable exit status, especially ¬´case¬ª;
#         * various built-in commands including ¬´command¬ª, ¬´set¬ª, and ¬´ulimit¬ª.
#
#   Important for patching:
#
#   (2) This script targets any POSIX shell, so it avoids extensions provided
#       by Bash, Ksh, etc; in particular arrays are avoided.
#
#       The "traditional" practice of packing multiple parameters into a
#       space-separated string is a well documented source of bugs and security
#       problems, so this is (mostly) avoided, by progressively accumulating
#       options in "$@", and eventually passing that to Java.
#
#       Where the inherited environment variables (DEFAULT_JVM_OPTS, JAVA_OPTS,
#       and GRADLE_OPTS) rely on word-splitting, this is performed explicitly;
#       see the in-line comments for details.
#
#       There are tweaks for specific operating systems such as AIX, CygWin,
#       Darwin, MinGW, and NonStop.
#
#   (3) This script is generated from the Groovy template
#       https://github.com/gradle/gradle/blob/HEAD/subprojects/plugins/src/main/resources/org/gradle/api/internal/plugins/unixStartScript.txt
#       within the Gradle project.
#
#       You can find Gradle at https://github.com/gradle/gradle/.
#
##############################################################################

# Attempt to set APP_HOME

# Resolve links: $0 may be a link
app_path=$0

# Need this for daisy-chained symlinks.
while
    APP_HOME=${app_path%"${app_path##*/}"}  # leaves a trailing /; empty if no leading path
    [ -h "$app_path" ]
do
    ls=$( ls -ld "$app_path" )
    link=${ls#*' -> '}
    case $link in             #(
      /*)   app_path=$link ;; #(
      *)    app_path=$APP_HOME$link ;;
    esac
done

# This is normally unused
# shellcheck disable=SC2034
APP_BASE_NAME=${0##*/}
# Discard cd standard output in case $CDPATH is set (https://github.com/gradle/gradle/issues/25036)
APP_HOME=$( cd "${APP_HOME:-./}" > /dev/null && pwd -P ) || exit

# Use the maximum available, or set MAX_FD != -1 to use that value.
MAX_FD=maximum

warn () {
    echo "$*"
} >&2

die () {
    echo
    echo "$*"
    echo
    exit 1
} >&2

# OS specific support (must be 'true' or 'false').
cygwin=false
msys=false
darwin=false
nonstop=false
case "$( uname )" in                #(
  CYGWIN* )         cygwin=true  ;; #(
  Darwin* )         darwin=true  ;; #(
  MSYS* | MINGW* )  msys=true    ;; #(
  NONSTOP* )        nonstop=true ;;
esac

CLASSPATH=$APP_HOME/gradle/wrapper/gradle-wrapper.jar


# Determine the Java command to use to start the JVM.
if [ -n "$JAVA_HOME" ] ; then
    if [ -x "$JAVA_HOME/jre/sh/java" ] ; then
        # IBM's JDK on AIX uses strange locations for the executables
        JAVACMD=$JAVA_HOME/jre/sh/java
    else
        JAVACMD=$JAVA_HOME/bin/java
    fi
    if [ ! -x "$JAVACMD" ] ; then
        die "ERROR: JAVA_HOME is set to an invalid directory: $JAVA_HOME

Please set the JAVA_HOME variable in your environment to match the
location of your Java installation."
    fi
else
    JAVACMD=java
    if ! command -v java >/dev/null 2>&1
    then
        die "ERROR: JAVA_HOME is not set and no 'java' command could be found in your PATH.

Please set the JAVA_HOME variable in your environment to match the
location of your Java installation."
    fi
fi

# Increase the maximum file descriptors if we can.
if ! "$cygwin" && ! "$darwin" && ! "$nonstop" ; then
    case $MAX_FD in #(
      max*)
        # In POSIX sh, ulimit -H is undefined. That's why the result is checked to see if it worked.
        # shellcheck disable=SC2039,SC3045
        MAX_FD=$( ulimit -H -n ) ||
            warn "Could not query maximum file descriptor limit"
    esac
    case $MAX_FD in  #(
      '' | soft) :;; #(
      *)
        # In POSIX sh, ulimit -n is undefined. That's why the result is checked to see if it worked.
        # shellcheck disable=SC2039,SC3045
        ulimit -n "$MAX_FD" ||
            warn "Could not set maximum file descriptor limit to $MAX_FD"
    esac
fi

# Collect all arguments for the java command, stacking in reverse order:
#   * args from the command line
#   * the main class name
#   * -classpath
#   * -D...appname settings
#   * --module-path (only if needed)
#   * DEFAULT_JVM_OPTS, JAVA_OPTS, and GRADLE_OPTS environment variables.

# For Cygwin or MSYS, switch paths to Windows format before running java
if "$cygwin" || "$msys" ; then
    APP_HOME=$( cygpath --path --mixed "$APP_HOME" )
    CLASSPATH=$( cygpath --path --mixed "$CLASSPATH" )

    JAVACMD=$( cygpath --unix "$JAVACMD" )

    # Now convert the arguments - kludge to limit ourselves to /bin/sh
    for arg do
        if
            case $arg in                                #(
              -*)   false ;;                            # don't mess with options #(
              /?*)  t=${arg#/} t=/${t%%/*}              # looks like a POSIX filepath
                    [ -e "$t" ] ;;                      #(
              *)    false ;;
            esac
        then
            arg=$( cygpath --path --ignore --mixed "$arg" )
        fi
        # Roll the args list around exactly as many times as the number of
        # args, so each arg winds up back in the position where it started, but
        # possibly modified.
        #
        # NB: a `for` loop captures its iteration list before it begins, so
        # changing the positional parameters here affects neither the number of
        # iterations, nor the values presented in `arg`.
        shift                   # remove old arg
        set -- "$@" "$arg"      # push replacement arg
    done
fi


# Add default JVM options here. You can also use JAVA_OPTS and GRADLE_OPTS to pass JVM options to this script.
DEFAULT_JVM_OPTS='"-Xmx64m" "-Xms64m"'

# Collect all arguments for the java command:
#   * DEFAULT_JVM_OPTS, JAVA_OPTS, JAVA_OPTS, and optsEnvironmentVar are not allowed to contain shell fragments,
#     and any embedded shellness will be escaped.
#   * For example: A user cannot expect ${Hostname} to be expanded, as it is an environment variable and will be
#     treated as '${Hostname}' itself on the command line.

set -- \
        "-Dorg.gradle.appname=$APP_BASE_NAME" \
        -classpath "$CLASSPATH" \
        org.gradle.wrapper.GradleWrapperMain \
        "$@"

# Stop when "xargs" is not available.
if ! command -v xargs >/dev/null 2>&1
then
    die "xargs is not available"
fi

# Use "xargs" to parse quoted args.
#
# With -n1 it outputs one arg per line, with the quotes and backslashes removed.
#
# In Bash we could simply go:
#
#   readarray ARGS < <( xargs -n1 <<<"$var" ) &&
#   set -- "${ARGS[@]}" "$@"
#
# but POSIX shell has neither arrays nor command substitution, so instead we
# post-process each arg (as a line of input to sed) to backslash-escape any
# character that might be a shell metacharacter, then use eval to reverse
# that process (while maintaining the separation between arguments), and wrap
# the whole thing up as a single "set" statement.
#
# This will of course break if any of these variables contains a newline or
# an unmatched quote.
#

eval "set -- $(
        printf '%s\n' "$DEFAULT_JVM_OPTS $JAVA_OPTS $GRADLE_OPTS" |
        xargs -n1 |
        sed ' s~[^-[:alnum:]+,./:=@_]~\\&~g; ' |
        tr '\n' ' '
    )" '"$@"'

exec "$JAVACMD" "$@"
</file>

<file path="gradlew.bat">
@rem
@rem Copyright 2015 the original author or authors.
@rem
@rem Licensed under the Apache License, Version 2.0 (the "License");
@rem you may not use this file except in compliance with the License.
@rem You may obtain a copy of the License at
@rem
@rem      https://www.apache.org/licenses/LICENSE-2.0
@rem
@rem Unless required by applicable law or agreed to in writing, software
@rem distributed under the License is distributed on an "AS IS" BASIS,
@rem WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
@rem See the License for the specific language governing permissions and
@rem limitations under the License.
@rem

@if "%DEBUG%"=="" @echo off
@rem ##########################################################################
@rem
@rem  Gradle startup script for Windows
@rem
@rem ##########################################################################

@rem Set local scope for the variables with windows NT shell
if "%OS%"=="Windows_NT" setlocal

set DIRNAME=%~dp0
if "%DIRNAME%"=="" set DIRNAME=.
@rem This is normally unused
set APP_BASE_NAME=%~n0
set APP_HOME=%DIRNAME%

@rem Resolve any "." and ".." in APP_HOME to make it shorter.
for %%i in ("%APP_HOME%") do set APP_HOME=%%~fi

@rem Add default JVM options here. You can also use JAVA_OPTS and GRADLE_OPTS to pass JVM options to this script.
set DEFAULT_JVM_OPTS="-Xmx64m" "-Xms64m"

@rem Find java.exe
if defined JAVA_HOME goto findJavaFromJavaHome

set JAVA_EXE=java.exe
%JAVA_EXE% -version >NUL 2>&1
if %ERRORLEVEL% equ 0 goto execute

echo. 1>&2
echo ERROR: JAVA_HOME is not set and no 'java' command could be found in your PATH. 1>&2
echo. 1>&2
echo Please set the JAVA_HOME variable in your environment to match the 1>&2
echo location of your Java installation. 1>&2

goto fail

:findJavaFromJavaHome
set JAVA_HOME=%JAVA_HOME:"=%
set JAVA_EXE=%JAVA_HOME%/bin/java.exe

if exist "%JAVA_EXE%" goto execute

echo. 1>&2
echo ERROR: JAVA_HOME is set to an invalid directory: %JAVA_HOME% 1>&2
echo. 1>&2
echo Please set the JAVA_HOME variable in your environment to match the 1>&2
echo location of your Java installation. 1>&2

goto fail

:execute
@rem Setup the command line

set CLASSPATH=%APP_HOME%\gradle\wrapper\gradle-wrapper.jar


@rem Execute Gradle
"%JAVA_EXE%" %DEFAULT_JVM_OPTS% %JAVA_OPTS% %GRADLE_OPTS% "-Dorg.gradle.appname=%APP_BASE_NAME%" -classpath "%CLASSPATH%" org.gradle.wrapper.GradleWrapperMain %*

:end
@rem End local scope for the variables with windows NT shell
if %ERRORLEVEL% equ 0 goto mainEnd

:fail
rem Set variable GRADLE_EXIT_CONSOLE if you need the _script_ return code instead of
rem the _cmd.exe /c_ return code!
set EXIT_CODE=%ERRORLEVEL%
if %EXIT_CODE% equ 0 set EXIT_CODE=1
if not ""=="%GRADLE_EXIT_CONSOLE%" exit %EXIT_CODE%
exit /b %EXIT_CODE%

:mainEnd
if "%OS%"=="Windows_NT" endlocal

:omega
</file>

<file path="README.MD">
# SeforimLibrary

A Kotlin Multiplatform library for converting and accessing the Otzaria database in SQLite format with FTS5 full-text search capabilities.

## Overview

SeforimLibrary is a comprehensive solution for working with Jewish religious texts from the Otzaria database. The project converts the original Otzaria database into a modern SQLite database with full-text search capabilities using FTS5, making it efficient to search through large volumes of text.

The library is structured as a set of modules that can be imported via Maven:

- **core**: Contains data models representing entities like books, authors, categories, and lines of text
- **dao**: Provides database access objects and repositories for interacting with the SQLite database
- **generator**: Handles the conversion of the original Otzaria database to SQLite format

## Features

- Convert Otzaria database to SQLite format
- Efficient full-text search using SQLite's FTS5
- Hierarchical category and book organization
- Table of contents navigation for books
- Support for links between related texts
- Comprehensive data model for Jewish religious texts

## Run Sample App

- Desktop JVM: `./gradlew :sample:composeApp:run`
- Android: `open project in Android Studio and run the sample app`


## Requirements

- JDK 11 or higher
- Kotlin 1.9.0 or higher
- SQLite 3.35.0 or higher (for FTS5 support)

## Usage

### Initializing the Database

```kotlin
// Initialize the database
val dbPath = "path/to/your/database.db"
val driver = JdbcSqliteDriver(url = "jdbc:sqlite:$dbPath")
val repository = SeforimRepository(dbPath, driver)
```

### Searching for Text

```kotlin
// Search in all books
val searchResults = repository.search("your search query", limit = 20, offset = 0)

// Search in a specific book
val bookSearchResults = repository.searchInBook(bookId, "your search query")

// Search by author
val authorSearchResults = repository.searchByAuthor("author name", "your search query")
```

### Browsing Categories and Books

```kotlin
// Get root categories
val rootCategories = repository.getRootCategories()

// Get subcategories
val subcategories = repository.getCategoryChildren(parentId)

// Get books in a category
val books = repository.getBooksByCategory(categoryId)
```

### Reading Book Content

```kotlin
// Get book details
val book = repository.getBook(bookId)

// Get lines of text
val lines = repository.getLines(bookId, startIndex, endIndex)

// Get table of contents
val toc = repository.getBookToc(bookId)
```

## Database Generation

To convert the original Otzaria database to SQLite format:

```kotlin
// Initialize repository
val repository = SeforimRepository(dbPath, driver)

// Create generator with source directory
val sourcePath = Path("/path/to/otzaria_source")
val generator = DatabaseGenerator(sourcePath, repository)

// Generate the database
generator.generate()
```

## Project Structure

- **core**: Contains data models and extensions
  - `models`: Data classes representing entities in the database
  - `extensions`: Utility extensions for working with the models

- **dao**: Database access layer
  - `repository`: Repository classes for accessing the database
  - `extensions`: Extensions for converting between database and model objects
  - `sqldelight`: SQL queries and database schema

- **generator**: Database generation tools
  - `DatabaseGenerator`: Main class for converting Otzaria data to SQLite
  - `Main`: Entry point for running the generator as a standalone application
</file>

<file path="sample/composeApp/build.gradle.kts">
import org.jetbrains.compose.desktop.application.dsl.TargetFormat

plugins {
    alias(libs.plugins.multiplatform)
    alias(libs.plugins.compose.compiler)
    alias(libs.plugins.compose)
    alias(libs.plugins.android.application)
}

kotlin {
    jvmToolchain(21)
    jvm()
    androidTarget()

    sourceSets {
        commonMain.dependencies {
            implementation(compose.runtime)
            implementation(compose.foundation)
            implementation(compose.material3)
            implementation(compose.materialIconsExtended)
            implementation(compose.components.resources)

            implementation(libs.kermit)
            implementation(project(":core"))
            implementation(project(":dao"))
            implementation("com.mohamedrejeb.richeditor:richeditor-compose:1.0.0-rc13")
            implementation("io.github.vinceglb:filekit-core:0.10.0-beta04")
            implementation("io.github.vinceglb:filekit-dialogs:0.10.0-beta04")
            implementation("io.github.vinceglb:filekit-dialogs-compose:0.10.0-beta04")
            implementation("androidx.sqlite:sqlite:2.5.0-alpha01")
            implementation("androidx.sqlite:sqlite-bundled:2.5.0-alpha01")
            implementation("com.eygraber:sqldelight-androidx-driver:0.0.13")

        }


        jvmMain.dependencies {
            implementation(compose.desktop.currentOs)
            implementation("app.cash.sqldelight:sqlite-driver:2.1.0")
            implementation("app.cash.sqldelight:jdbc-driver:2.1.0")
        }

        androidMain.dependencies {
            implementation("app.cash.sqldelight:android-driver:2.1.0")
            implementation("androidx.activity:activity-compose:1.8.2")
            implementation("androidx.appcompat:appcompat:1.7.1")

        }

    }
}

android {
    namespace = "sample.app"
    compileSdk = 35

    defaultConfig {
        minSdk = 24
        targetSdk = 34
        versionCode = 1
        versionName = "1.0.0"
    }

    buildTypes {
        release {
            isMinifyEnabled = false
        }
    }
}

compose.desktop {
    application {
        mainClass = "MainKt"

        nativeDistributions {
            modules("java.sql", "jdk.security.auth")
            targetFormats(TargetFormat.Dmg, TargetFormat.Msi, TargetFormat.Deb)
            packageName = "sample"
            packageVersion = "1.0.0"
        }
    }
}
</file>

<file path="sample/composeApp/src/androidMain/AndroidManifest.xml">
<?xml version="1.0" encoding="utf-8"?>
<manifest xmlns:android="http://schemas.android.com/apk/res/android">

    <application
            android:icon="@android:mipmap/sym_def_app_icon"
            android:label="sample"
            android:theme="@android:style/Theme.Material.NoActionBar">
        <activity
            android:name=".AppActivity"
            android:configChanges="orientation|screenSize|screenLayout|keyboardHidden"
            android:launchMode="singleInstance"
            android:windowSoftInputMode="adjustPan"
            android:exported="true">
            <intent-filter>
                <action android:name="android.intent.action.MAIN" />
                <category android:name="android.intent.category.LAUNCHER" />
            </intent-filter>
        </activity>
    </application>

</manifest>
</file>

<file path="sample/composeApp/src/androidMain/kotlin/sample/app/DatabaseUtils.kt">
package sample.app

import androidx.compose.runtime.Composable
import androidx.compose.runtime.remember
import app.cash.sqldelight.db.SqlDriver
import app.cash.sqldelight.driver.android.AndroidSqliteDriver
import io.github.kdroidfilter.seforimlibrary.dao.repository.SeforimRepository
import android.content.Context
import androidx.compose.ui.platform.LocalContext
import io.github.kdroidfilter.seforimlibrary.db.SeforimDb
// Import the androidx.sqlite classes
import androidx.sqlite.*

// Android implementation of database path
@Composable
actual fun getDatabasePath(): String {
    // For Android, we'll use the app's internal storage
    return "otzaria.db"
}

// Android implementation of repository
@Composable
actual fun getRepository(): SeforimRepository {
    val dbPath = getDatabasePath()
    val context = LocalContext.current

    // Create a custom SqlDriver that uses BundledSQLiteDriver
    val driver: SqlDriver = remember {

        AndroidSqliteDriver(SeforimDb.Schema, context, dbPath)


    }

    return remember(driver) {
        SeforimRepository(dbPath, driver)
    }
}

// Empty implementation for Android - we don't show the database selection button on mobile
@Composable
actual fun DatabaseSelectionButtonIfAvailable() {
    // No-op on Android
}
</file>

<file path="sample/composeApp/src/androidMain/kotlin/sample/app/main.kt">
package sample.app

import android.os.Bundle
import androidx.activity.ComponentActivity
import androidx.activity.compose.setContent
import androidx.activity.enableEdgeToEdge

class AppActivity : ComponentActivity() {
    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        enableEdgeToEdge()
        setContent { App() }
    }
}
</file>

<file path="sample/composeApp/src/commonMain/kotlin/sample/app/App.kt">
package sample.app

import androidx.compose.foundation.background
import androidx.compose.foundation.layout.*
import androidx.compose.material.icons.Icons
import androidx.compose.material.icons.filled.Search
import androidx.compose.material3.*
import androidx.compose.runtime.*
import androidx.compose.ui.Alignment
import androidx.compose.ui.Modifier
import androidx.compose.ui.text.font.FontWeight
import androidx.compose.ui.unit.dp
import androidx.compose.ui.unit.sp
import co.touchlab.kermit.Logger
import io.github.kdroidfilter.seforimlibrary.core.models.Book
import io.github.kdroidfilter.seforimlibrary.core.models.Category
import io.github.kdroidfilter.seforimlibrary.core.models.Line
import io.github.kdroidfilter.seforimlibrary.core.models.TocEntry
import io.github.kdroidfilter.seforimlibrary.dao.repository.CommentaryWithText
import io.github.kdroidfilter.seforimlibrary.dao.repository.CommentatorInfo
import io.github.kdroidfilter.seforimlibrary.dao.repository.SeforimRepository
import kotlinx.coroutines.async
import kotlinx.coroutines.launch

@Composable
expect fun getDatabasePath(): String

@Composable
expect fun getRepository(): SeforimRepository

@Composable
expect fun DatabaseSelectionButtonIfAvailable()

data class BookState(
    val book: Book? = null,
    val lines: List<Line> = emptyList(),
    val commentaries: List<CommentaryWithText> = emptyList(),
    val toc: List<TocEntry> = emptyList(),
    val selectedLine: Line? = null,
    val isLoading: Boolean = false,
    val isTocLoading: Boolean = false
)

data class PopupState(
    val show: Boolean = false,
    val book: Book? = null,
    val lines: List<Line> = emptyList(),
    val commentaries: List<CommentaryWithText> = emptyList(),
    val commentators: List<CommentatorInfo> = emptyList(),
    val selectedLine: Line? = null
)

@Composable
fun App() {
    Logger.setMinSeverity(co.touchlab.kermit.Severity.Error)
    val repository = getRepository()
    val scope = rememberCoroutineScope()

    // Category tree state
    var rootCategories by remember { mutableStateOf<List<Category>>(emptyList()) }
    var selectedCategory by remember { mutableStateOf<Category?>(null) }
    var expandedCategories by remember { mutableStateOf(setOf<Long>()) }
    var categoryChildren by remember { mutableStateOf<Map<Long, List<Category>>>(emptyMap()) }
    var booksInCategory by remember { mutableStateOf<Set<Book>>(emptySet()) }

    // Book state
    var bookState by remember { mutableStateOf(BookState()) }

    // TOC state
    var expandedTocEntries by remember { mutableStateOf(setOf<Long>()) }
    var tocChildren by remember { mutableStateOf<Map<Long, List<TocEntry>>>(emptyMap()) }

    // Popup states
    var bookPopup by remember { mutableStateOf(PopupState()) }
    var showSearchPopup by remember { mutableStateOf(false) }

    // Load root categories on startup
    LaunchedEffect(repository) {
        rootCategories = repository.getRootCategories()
    }

    // Helper functions
    fun getAllDescendantIds(entryId: Long, childrenMap: Map<Long, List<TocEntry>>): Set<Long> {
        val result = mutableSetOf<Long>()
        childrenMap[entryId]?.forEach { child ->
            result.add(child.id)
            result.addAll(getAllDescendantIds(child.id, childrenMap))
        }
        return result
    }

    fun loadBook(book: Book) {
        bookState = bookState.copy(
            book = book,
            selectedLine = null,
            isLoading = true,
            isTocLoading = true
        )

        scope.launch {
            try {
                // Load book data in parallel
                val linesDeferred = async { repository.getLines(book.id, 0, 30) }
                val tocDeferred = async {
                    repository.getBookRootToc(book.id).ifEmpty {
                        repository.getBookToc(book.id)
                    }
                }

                val lines = linesDeferred.await()
                val toc = tocDeferred.await()

                // Load commentaries for first 5 lines
                val commentaries = if (lines.isNotEmpty()) {
                    repository.getCommentariesForLines(lines.take(5).map { it.id })
                } else emptyList()

                bookState = bookState.copy(
                    lines = lines,
                    commentaries = commentaries,
                    toc = toc,
                    isLoading = false,
                    isTocLoading = false
                )

                // Auto-expand first TOC entry if exists
                if (toc.isNotEmpty()) {
                    val firstEntry = toc.first()
                    expandedTocEntries = setOf(firstEntry.id)
                    val children = repository.getTocChildren(firstEntry.id)
                    tocChildren = mapOf(firstEntry.id to children)
                }
            } catch (e: Exception) {
                bookState = bookState.copy(isLoading = false, isTocLoading = false)
                Logger.e { "Error loading book: ${e.message}" }
            }
        }
    }

    fun selectLine(line: Line) {
        bookState = bookState.copy(selectedLine = line)
        scope.launch {
            bookState = bookState.copy(
                commentaries = repository.getCommentariesForLines(listOf(line.id))
            )
        }
    }

    fun loadPopupBook(commentary: CommentaryWithText) {
        scope.launch {
            val targetBook = repository.getBook(commentary.link.targetBookId)
            if (targetBook != null) {
                val targetLine = repository.getLine(commentary.link.targetLineId)

                val (lines, selectedLine) = if (targetLine != null) {
                    val startIndex = maxOf(0, targetLine.lineIndex - 25)
                    val endIndex = targetLine.lineIndex + 25
                    repository.getLines(targetBook.id, startIndex, endIndex) to targetLine
                } else {
                    repository.getLines(targetBook.id, 0, 100) to null
                }

                val commentaries = if (lines.isNotEmpty()) {
                    repository.getCommentariesForLines(lines.map { it.id })
                } else emptyList()

                val commentators = repository.getAvailableCommentators(targetBook.id)

                bookPopup = PopupState(
                    show = true,
                    book = targetBook,
                    lines = lines,
                    commentaries = commentaries,
                    commentators = commentators,
                    selectedLine = selectedLine
                )
            }
        }
    }

    AppTheme {
        Row(modifier = Modifier.fillMaxSize()) {
            // Column 1: Book tree
            Box(
                modifier = Modifier
                    .weight(0.25f)
                    .fillMaxHeight()
                    .background(MaterialTheme.colorScheme.surface)
                    .padding(8.dp)
            ) {
                CategoryBookTree(
                    rootCategories = rootCategories,
                    expandedCategories = expandedCategories,
                    categoryChildren = categoryChildren,
                    booksInCategory = booksInCategory,
                    selectedCategory = selectedCategory,
                    selectedBook = bookState.book,
                    onCategoryClick = { category ->
                        selectedCategory = category

                        if (expandedCategories.contains(category.id)) {
                            expandedCategories -= category.id
                        } else {
                            expandedCategories += category.id

                            scope.launch {
                                try {
                                    val childrenDeferred = async {
                                        if (!categoryChildren.containsKey(category.id)) {
                                            repository.getCategoryChildren(category.id)
                                        } else emptyList()
                                    }
                                    val booksDeferred = async { repository.getBooksByCategory(category.id) }

                                    val children = childrenDeferred.await()
                                    val books = booksDeferred.await()

                                    if (children.isNotEmpty()) {
                                        categoryChildren += category.id to children
                                    }
                                    if (books.isNotEmpty()) {
                                        booksInCategory += books
                                    }
                                } catch (e: Exception) {
                                    Logger.e { "Error loading category: ${e.message}" }
                                }
                            }
                        }
                    },
                    onBookClick = ::loadBook
                )
            }

            // Column 2: TOC
            Box(
                modifier = Modifier
                    .weight(0.20f)
                    .fillMaxHeight()
                    .background(MaterialTheme.colorScheme.surface.copy(alpha = 0.7f))
                    .padding(8.dp)
            ) {
                if (bookState.book != null) {
                    Column {
                        Text(
                            text = "◊™◊ï◊õ◊ü ◊¢◊†◊ô◊ô◊†◊ô◊ù", // Table of Contents
                            fontWeight = FontWeight.Bold,
                            fontSize = 16.sp,
                            modifier = Modifier.padding(bottom = 8.dp)
                        )

                        if (bookState.isTocLoading) {
                            Box(modifier = Modifier.fillMaxSize(), contentAlignment = Alignment.Center) {
                                Column(horizontalAlignment = Alignment.CenterHorizontally) {
                                    CircularProgressIndicator(modifier = Modifier.size(24.dp))
                                    Spacer(modifier = Modifier.height(4.dp))
                                    Text("◊ò◊ï◊¢◊ü ◊™◊ï◊õ◊ü ◊¢◊†◊ô◊ô◊†◊ô◊ù...", fontSize = 12.sp) // Loading table of contents...
                                }
                            }
                        } else {
                            TocView(
                                tocEntries = bookState.toc,
                                expandedEntries = expandedTocEntries,
                                childrenMap = tocChildren,
                                onEntryClick = { tocEntry ->
                                    tocEntry.lineId?.let { lineId ->
                                        scope.launch {
                                            val line = repository.getLine(lineId)
                                            if (line != null) {
                                                if (!bookState.lines.any { it.id == lineId }) {
                                                    val startIndex = maxOf(0, line.lineIndex - 25)
                                                    val endIndex = line.lineIndex + 25
                                                    bookState = bookState.copy(
                                                        lines = repository.getLines(bookState.book!!.id, startIndex, endIndex)
                                                    )
                                                }
                                                selectLine(line)
                                            }
                                        }
                                    }
                                },
                                onEntryExpand = { tocEntry ->
                                    val isExpanded = expandedTocEntries.contains(tocEntry.id)

                                    if (isExpanded) {
                                        val descendants = getAllDescendantIds(tocEntry.id, tocChildren)
                                        expandedTocEntries = expandedTocEntries - tocEntry.id - descendants
                                    } else {
                                        expandedTocEntries += tocEntry.id

                                        if (!tocChildren.containsKey(tocEntry.id)) {
                                            scope.launch {
                                                val children = repository.getTocChildren(tocEntry.id)
                                                tocChildren += tocEntry.id to children

                                                // Recursively check for grandchildren
                                                suspend fun loadChildrenRecursively(entries: List<TocEntry>) {
                                                    entries.forEach { entry ->
                                                        if (!tocChildren.containsKey(entry.id)) {
                                                            val entryChildren = repository.getTocChildren(entry.id)
                                                            tocChildren += entry.id to entryChildren
                                                            if (entryChildren.isNotEmpty()) {
                                                                loadChildrenRecursively(entryChildren)
                                                            }
                                                        }
                                                    }
                                                }

                                                if (children.isNotEmpty()) {
                                                    loadChildrenRecursively(children)
                                                }
                                            }
                                        }
                                    }
                                }
                            )
                        }
                    }
                } else {
                    Box(modifier = Modifier.fillMaxSize(), contentAlignment = Alignment.Center) {
                        Text("◊ë◊ó◊® ◊°◊§◊® ◊õ◊ì◊ô ◊ú◊¶◊§◊ï◊™ ◊ë◊™◊ï◊õ◊ü ◊î◊¢◊†◊ô◊ô◊†◊ô◊ù ◊©◊ú◊ï") // Select a book to view its table of contents
                    }
                }
            }

            // Column 3: Book content and comments
            Column(
                modifier = Modifier
                    .weight(0.65f)
                    .fillMaxHeight()
                    .padding(8.dp)
            ) {
                if (bookState.book != null) {
                    val hasComments = bookState.selectedLine?.let { line ->
                        bookState.commentaries.any { it.link.sourceLineId == line.id }
                    } ?: false

                    // Book content
                    Box(
                        modifier = Modifier
                            .weight(if (hasComments) 0.5f else 1f)
                            .fillMaxWidth()
                    ) {
                        if (bookState.isLoading) {
                            Box(modifier = Modifier.fillMaxSize(), contentAlignment = Alignment.Center) {
                                Column(horizontalAlignment = Alignment.CenterHorizontally) {
                                    CircularProgressIndicator()
                                    Spacer(modifier = Modifier.height(8.dp))
                                    Text("◊ò◊ï◊¢◊ü ◊™◊ï◊õ◊ü ◊î◊°◊§◊®...") // Loading book content...
                                }
                            }
                        } else {
                            BookContentView(
                                book = bookState.book!!,
                                lines = bookState.lines,
                                selectedLine = bookState.selectedLine,
                                onLineSelected = ::selectLine
                            )
                        }
                    }

                    // Comments view (only if has comments)
                    if (hasComments) {
                        Box(
                            modifier = Modifier
                                .weight(0.5f)
                                .fillMaxWidth()
                                .background(MaterialTheme.colorScheme.surface.copy(alpha = 0.5f))
                        ) {
                            LineCommentsView(
                                selectedLine = bookState.selectedLine,
                                commentaries = bookState.commentaries,
                                onCommentClick = ::loadPopupBook
                            )
                        }
                    }
                }
            }
        }

        // Book popup
        if (bookPopup.show && bookPopup.book != null) {
            BookPopup(
                book = bookPopup.book!!,
                lines = bookPopup.lines,
                commentaries = bookPopup.commentaries,
                commentators = bookPopup.commentators,
                selectedLine = bookPopup.selectedLine,
                onDismiss = { bookPopup = PopupState() }
            )
        }

        // FAB for search and database
        Box(modifier = Modifier.fillMaxSize()) {
            Row(
                modifier = Modifier
                    .align(Alignment.TopEnd)
                    .padding(16.dp),
                horizontalArrangement = Arrangement.spacedBy(8.dp)
            ) {
                DatabaseSelectionButtonIfAvailable()
                IconButton(onClick = { showSearchPopup = true }) {
                    Icon(Icons.Default.Search, contentDescription = "Search")
                }
            }
        }

        // Search popup
        if (showSearchPopup) {
            SearchPopup(
                repository = repository,
                onDismiss = { showSearchPopup = false },
                onResultClick = { searchResult ->
                    scope.launch {
                        val book = repository.getBook(searchResult.bookId)
                        if (book != null) {
                            selectedCategory = repository.getCategory(book.categoryId)
                            loadBook(book)

                            val line = repository.getLine(searchResult.lineId)
                            if (line != null) {
                                val startIndex = maxOf(0, line.lineIndex - 5)
                                val endIndex = line.lineIndex + 5
                                bookState = bookState.copy(
                                    lines = repository.getLines(book.id, startIndex, endIndex)
                                )
                                selectLine(line)
                            }

                            showSearchPopup = false
                        }
                    }
                }
            )
        }
    }
}
</file>

<file path="sample/composeApp/src/commonMain/kotlin/sample/app/BookContentView.kt">
package sample.app

import androidx.compose.foundation.background
import androidx.compose.foundation.clickable
import androidx.compose.foundation.layout.*
import androidx.compose.foundation.lazy.LazyColumn
import androidx.compose.foundation.lazy.items
import androidx.compose.foundation.lazy.rememberLazyListState
import androidx.compose.material.icons.Icons
import androidx.compose.material.icons.automirrored.filled.KeyboardArrowRight
import androidx.compose.material.icons.filled.KeyboardArrowDown
import androidx.compose.material3.Icon
import androidx.compose.material3.MaterialTheme
import androidx.compose.material3.Text
import androidx.compose.runtime.*
import androidx.compose.ui.Alignment
import androidx.compose.ui.Modifier
import androidx.compose.ui.graphics.Color
import androidx.compose.ui.text.font.FontWeight
import androidx.compose.ui.unit.dp
import androidx.compose.ui.unit.sp
import com.mohamedrejeb.richeditor.model.rememberRichTextState
import com.mohamedrejeb.richeditor.ui.material.RichText
import io.github.kdroidfilter.seforimlibrary.core.models.Book
import io.github.kdroidfilter.seforimlibrary.core.models.Line
import io.github.kdroidfilter.seforimlibrary.core.models.TocEntry

@Composable
fun BookContentView(
    book: Book,
    lines: List<Line>,
    selectedLine: Line? = null,
    onLineSelected: (Line) -> Unit = {}
) {
    Column(modifier = Modifier.fillMaxSize()) {
        // Book title
        Text(
            text = book.title,
            fontWeight = FontWeight.Bold,
            fontSize = 20.sp,
            modifier = Modifier.padding(16.dp)
        )

        // Book content
        Box(modifier = Modifier.weight(1f)) {
            BookContent(
                lines = lines,
                selectedLine = selectedLine,
                onLineSelected = onLineSelected
            )
        }
    }
}

@Composable
fun BookContent(
    lines: List<Line>,
    selectedLine: Line? = null,
    onLineSelected: (Line) -> Unit = {}
) {
    if (lines.isEmpty()) {
        Box(
            modifier = Modifier.fillMaxSize(),
            contentAlignment = Alignment.Center
        ) {
            Text("◊ê◊ô◊ü ◊™◊ï◊õ◊ü ◊ñ◊û◊ô◊ü")
        }
    } else {
        // Create a LazyListState to control scrolling
        val listState = rememberLazyListState()

        // Keep track of the currently loaded lines
        val book = remember(lines) { lines.firstOrNull() }
        val bookId = remember(book) { book?.bookId ?: 0L }

        // Define the window size and offset for pagination
        val windowSize = 50 // Number of lines to display at once
        val loadOffset = 15 // Load more lines when this close to the edge

        // State to track the current window of lines
        var currentLines by remember(lines) { mutableStateOf(lines) }
        var startIndex by remember(lines) { mutableStateOf(lines.firstOrNull()?.lineIndex ?: 0) }
        var endIndex by remember(lines) { mutableStateOf((lines.lastOrNull()?.lineIndex ?: 0) + 1) }

        // Convert lines to LineWithUniqueKey objects
        var currentLinesWithKeys by remember(currentLines) { mutableStateOf(currentLines.withUniqueKeys()) }

        // Repository to load more lines
        val repository = getRepository()

        // Scroll to the selected line when it changes
        LaunchedEffect(selectedLine, lines) {
            if (selectedLine != null) {
                // Check if the selected line is in the current window
                val selectedIndex = currentLines.indexOfFirst { it.id == selectedLine.id }

                if (selectedIndex >= 0) {
                    // If the line is already in our current window, just scroll to it
                    listState.animateScrollToItem(selectedIndex)
                } else {
                    // If the line is not in our current window, we need to load it
                    // Load a window of lines centered around the selected line
                    val lineIndex = selectedLine.lineIndex
                    val newStartIndex = maxOf(0, lineIndex - windowSize / 2)
                    val newEndIndex = lineIndex + windowSize / 2

                    // Load the lines from the repository
                    val newLines = repository.getLines(bookId, newStartIndex, newEndIndex)
                    if (newLines.isNotEmpty()) {
                        // Update our current window
                        currentLines = newLines
                        startIndex = newStartIndex
                        endIndex = newEndIndex
                        // Update lines with unique keys
                        currentLinesWithKeys = currentLines.withUniqueKeys()

                        // Now find the index of the selected line in the new window and scroll to it
                        val newSelectedIndex = currentLines.indexOfFirst { it.id == selectedLine.id }
                        if (newSelectedIndex >= 0) {
                            listState.scrollToItem(newSelectedIndex)
                        }
                    }
                }
            }
        }

        // Load more lines when approaching the edges
        LaunchedEffect(listState.firstVisibleItemIndex) {
            // If we're close to the top, load more lines above
            if (listState.firstVisibleItemIndex < loadOffset && startIndex > 0) {
                val newStartIndex = maxOf(0, startIndex - windowSize / 2)
                val newLines = repository.getLines(bookId, newStartIndex, startIndex)
                if (newLines.isNotEmpty()) {
                    currentLines = newLines + currentLines
                    startIndex = newStartIndex
                    // Update lines with unique keys
                    currentLinesWithKeys = currentLines.withUniqueKeys()
                }
            }
        }

        LaunchedEffect(listState.layoutInfo.visibleItemsInfo.lastOrNull()?.index) {
            // If we're close to the bottom, load more lines below
            val lastVisibleIndex = listState.layoutInfo.visibleItemsInfo.lastOrNull()?.index ?: 0
            if (lastVisibleIndex >= currentLines.size - loadOffset) {
                val newEndIndex = endIndex + windowSize / 2
                val newLines = repository.getLines(bookId, endIndex, newEndIndex)
                if (newLines.isNotEmpty()) {
                    currentLines = currentLines + newLines
                    endIndex = newEndIndex
                    // Update lines with unique keys
                    currentLinesWithKeys = currentLines.withUniqueKeys()
                }
            }
        }

        // Limit the number of lines in memory to maintain efficiency
        LaunchedEffect(currentLines.size) {
            if (currentLines.size > windowSize * 3) {
                // If we have too many lines, trim from the opposite end of where we're viewing
                if (listState.firstVisibleItemIndex < currentLines.size / 2) {
                    // We're closer to the top, trim from the bottom
                    currentLines = currentLines.take(windowSize * 2)
                    endIndex = (currentLines.lastOrNull()?.lineIndex ?: 0) + 1
                } else {
                    // We're closer to the bottom, trim from the top
                    currentLines = currentLines.takeLast(windowSize * 2)
                    startIndex = currentLines.firstOrNull()?.lineIndex ?: 0
                }
                // Update lines with unique keys
                currentLinesWithKeys = currentLines.withUniqueKeys()
            }
        }

        LazyColumn(
            state = listState,
            modifier = Modifier.fillMaxSize().padding(16.dp)
        ) {
            items(
                items = currentLinesWithKeys,
                key = { it.uniqueKey } // Use the unique key for stable identity
            ) { lineWithKey ->
                val line = lineWithKey.line
                val isSelected = selectedLine?.id == line.id
                val state = rememberRichTextState()

                // Use LaunchedEffect to set HTML content only when line changes
                LaunchedEffect(line.id) {
                    state.setHtml(line.content)
                }

                RichText(
                    state = state,
                    modifier = Modifier
                        .fillMaxWidth()
                        .clickable { onLineSelected(line) }
                        .background(if (isSelected) MaterialTheme.colorScheme.primary.copy(alpha = 0.1f) else Color.Transparent)
                        .padding(vertical = 4.dp),
                )
            }
        }
    }
}

@Composable
fun TocView(
    tocEntries: List<TocEntry>,
    expandedEntries: Set<Long>,
    childrenMap: Map<Long, List<TocEntry>>,
    onEntryClick: (TocEntry) -> Unit,
    onEntryExpand: (TocEntry) -> Unit
) {
    if (tocEntries.isEmpty()) {
        Box(
            modifier = Modifier.fillMaxSize(),
            contentAlignment = Alignment.Center
        ) {
            Text("◊ê◊ô◊ü ◊™◊ï◊õ◊ü ◊¢◊†◊ô◊ô◊†◊ô◊ù ◊ñ◊û◊ô◊ü")
        }
    } else {
        LazyColumn(
            modifier = Modifier.fillMaxSize().padding(16.dp)
        ) {
            items(tocEntries) { entry ->
                TocEntryItem(
                    entry = entry,
                    level = 0,
                    isExpanded = expandedEntries.contains(entry.id),
                    childEntries = childrenMap[entry.id] ?: emptyList(),
                    expandedEntries = expandedEntries,
                    childrenMap = childrenMap,
                    onEntryClick = onEntryClick,
                    onEntryExpand = onEntryExpand
                )
            }
        }
    }
}

@Composable
fun TocEntryItem(
    entry: TocEntry,
    level: Int,
    isExpanded: Boolean,
    childEntries: List<TocEntry>,
    expandedEntries: Set<Long>,
    childrenMap: Map<Long, List<TocEntry>>,
    onEntryClick: (TocEntry) -> Unit,
    onEntryExpand: (TocEntry) -> Unit
) {
    // Check if we've already attempted to load children for this entry
    val hasCheckedForChildren = childrenMap.containsKey(entry.id)
    // If we've checked and the list is empty, then it truly has no children
    val hasNoChildren = hasCheckedForChildren && childEntries.isEmpty()

    Column {
        Row(
            modifier = Modifier
                .fillMaxWidth()
                .clickable { onEntryClick(entry) }
                .padding(start = (level * 16).dp, top = 4.dp, bottom = 4.dp),
            verticalAlignment = Alignment.CenterVertically
        ) {
            // Show expand/collapse icon unless we've confirmed the entry has no children
            if (!hasNoChildren) {
                Icon(
                    imageVector = if (isExpanded) Icons.Default.KeyboardArrowDown else Icons.AutoMirrored.Filled.KeyboardArrowRight,
                    contentDescription = if (isExpanded) "Collapse" else "Expand",
                    tint = MaterialTheme.colorScheme.onSurface.copy(alpha = 0.6f),
                    modifier = Modifier
                        .size(24.dp)
                        .clickable { onEntryExpand(entry) }
                )
            } else {
                Spacer(modifier = Modifier.width(24.dp))
            }

            // Entry text
            Text(
                text = entry.text,
                fontWeight = FontWeight.Normal,
                fontSize = 14.sp
            )
        }

        // Show children if expanded
        if (isExpanded && childEntries.isNotEmpty()) {
            childEntries.forEach { childEntry ->
                TocEntryItem(
                    entry = childEntry,
                    level = level + 1,
                    isExpanded = expandedEntries.contains(childEntry.id),
                    childEntries = childrenMap[childEntry.id] ?: emptyList(),
                    expandedEntries = expandedEntries,
                    childrenMap = childrenMap,
                    onEntryClick = onEntryClick,
                    onEntryExpand = onEntryExpand
                )
            }
        }
    }
}
</file>

<file path="sample/composeApp/src/commonMain/kotlin/sample/app/BookPopup.kt">
package sample.app

import androidx.compose.foundation.layout.*
import androidx.compose.material3.*
import androidx.compose.material.icons.Icons
import androidx.compose.material.icons.filled.Close
import androidx.compose.runtime.*
import androidx.compose.ui.Alignment
import androidx.compose.ui.Modifier
import androidx.compose.ui.unit.dp
import androidx.compose.ui.window.Dialog
import io.github.kdroidfilter.seforimlibrary.core.models.Book
import io.github.kdroidfilter.seforimlibrary.core.models.Line
import io.github.kdroidfilter.seforimlibrary.dao.repository.CommentaryWithText
import io.github.kdroidfilter.seforimlibrary.dao.repository.CommentatorInfo

/**
 * A popup dialog that displays a book's content.
 *
 * @param book The book to display
 * @param lines The lines of the book to display
 * @param commentaries Commentaries for the book
 * @param commentators Available commentators for the book
 * @param selectedLine The line to highlight in the book content
 * @param onDismiss Callback when the popup is dismissed
 */
@Composable
fun BookPopup(
    book: Book,
    lines: List<Line>,
    commentaries: List<CommentaryWithText>,
    commentators: List<CommentatorInfo>,
    selectedLine: Line? = null,
    onDismiss: () -> Unit
) {
    Dialog(onDismissRequest = onDismiss) {
        Surface(
            modifier = Modifier
                .fillMaxWidth(0.9f)
                .fillMaxHeight(0.9f),
            shape = MaterialTheme.shapes.medium
        ) {
            Column(modifier = Modifier.padding(16.dp)) {
                // Header with close button
                Row(
                    modifier = Modifier.fillMaxWidth(),
                    horizontalArrangement = Arrangement.SpaceBetween,
                    verticalAlignment = Alignment.CenterVertically
                ) {
                    Text(
                        text = book.title,
                        style = MaterialTheme.typography.bodySmall
                    )
                    IconButton(onClick = onDismiss) {
                        Icon(
                            imageVector = Icons.Default.Close,
                            contentDescription = "Close"
                        )
                    }
                }

                HorizontalDivider(
                    modifier = Modifier.padding(vertical = 8.dp),
                    thickness = DividerDefaults.Thickness,
                    color = DividerDefaults.color
                )

                // Book content
                Box(modifier = Modifier.weight(1f)) {
                    BookContent(
                        lines = lines,
                        selectedLine = selectedLine
                    )
                }
            }
        }
    }
}
</file>

<file path="sample/composeApp/src/commonMain/kotlin/sample/app/CategoryBookTree.kt">
package sample.app

import androidx.compose.foundation.clickable
import androidx.compose.foundation.layout.*
import androidx.compose.foundation.lazy.LazyColumn
import androidx.compose.foundation.lazy.items
import androidx.compose.material.icons.Icons
import androidx.compose.material.icons.automirrored.filled.KeyboardArrowRight
import androidx.compose.material.icons.filled.Book
import androidx.compose.material.icons.filled.Folder
import androidx.compose.material.icons.filled.KeyboardArrowDown
import androidx.compose.material3.Icon
import androidx.compose.material3.Text
import androidx.compose.runtime.Composable
import androidx.compose.runtime.LaunchedEffect
import androidx.compose.ui.Alignment
import androidx.compose.ui.Modifier
import androidx.compose.ui.graphics.Color
import androidx.compose.ui.text.font.FontWeight
import androidx.compose.ui.unit.dp
import androidx.compose.ui.unit.sp
import io.github.kdroidfilter.seforimlibrary.core.models.Book
import io.github.kdroidfilter.seforimlibrary.core.models.Category

@Composable
fun CategoryBookTree(
    rootCategories: List<Category>,
    expandedCategories: Set<Long>,
    categoryChildren: Map<Long, List<Category>>,
    booksInCategory: Set<Book>,
    selectedCategory: Category?,
    selectedBook: Book?,
    onCategoryClick: (Category) -> Unit,
    onBookClick: (Book) -> Unit
) {
    LazyColumn {
        items(rootCategories) { category ->
            CategoryTreeItem(
                category = category,
                level = 0,
                expandedCategories = expandedCategories,
                categoryChildren = categoryChildren,
                booksInCategory = booksInCategory,
                selectedCategory = selectedCategory,
                selectedBook = selectedBook,
                onCategoryClick = onCategoryClick,
                onBookClick = onBookClick,
                maxLevel = 25
            )
        }
    }
}

@Composable
fun CategoryTreeItem(
    category: Category,
    level: Int,
    expandedCategories: Set<Long>,
    categoryChildren: Map<Long, List<Category>>,
    booksInCategory: Set<Book>,
    selectedCategory: Category?,
    selectedBook: Book?,
    onCategoryClick: (Category) -> Unit,
    onBookClick: (Book) -> Unit,
    maxLevel: Int
) {
    val isExpanded = expandedCategories.contains(category.id)
    val isSelected = selectedCategory?.id == category.id

    // Display the category item
    CategoryItem(
        category = category,
        level = level,
        isExpanded = isExpanded,
        isSelected = isSelected,
        onClick = { onCategoryClick(category) }
    )

    // If expanded, show children and/or books
    if (isExpanded) {
        // Show books in this category
        // Filter books that belong to this category
        val booksInThisCategory = booksInCategory.filter { it.categoryId == category.id }
        booksInThisCategory.forEach { book ->
            BookItem(
                book = book,
                level = level + 1,
                isSelected = selectedBook?.id == book.id,
                onClick = { onBookClick(book) }
            )
        }

        // Show child categories if not at max depth
        if (level < maxLevel - 1) {
            val children = categoryChildren[category.id] ?: emptyList()
            children.forEach { childCategory ->
                CategoryTreeItem(
                    category = childCategory,
                    level = level + 1,
                    expandedCategories = expandedCategories,
                    categoryChildren = categoryChildren,
                    booksInCategory = booksInCategory,
                    selectedCategory = selectedCategory,
                    selectedBook = selectedBook,
                    onCategoryClick = onCategoryClick,
                    onBookClick = onBookClick,
                    maxLevel = maxLevel
                )
            }
        }
    }
}

@Composable
fun CategoryItem(
    category: Category,
    level: Int,
    isExpanded: Boolean,
    isSelected: Boolean,
    onClick: () -> Unit
) {
    // Use LaunchedEffect to ensure proper recomposition when category changes
    LaunchedEffect(category.id) {
        // No action needed, just trigger recomposition
    }

    Row(
        modifier = Modifier
            .fillMaxWidth()
            .clickable(onClick = onClick)
            .padding(start = (level * 16).dp, top = 4.dp, bottom = 4.dp),
        verticalAlignment = Alignment.CenterVertically
    ) {
        // Icon for expand/collapse
        Icon(
            imageVector = if (isExpanded) Icons.Default.KeyboardArrowDown else Icons.AutoMirrored.Filled.KeyboardArrowRight,
            contentDescription = if (isExpanded) "Collapse" else "Expand",
            tint = Color.Gray,
            modifier = Modifier.size(24.dp)
        )

        // Icon for folder
        Icon(
            imageVector = Icons.Default.Folder,
            contentDescription = "Folder",
            tint = if (isSelected) Color.Blue else Color.Gray,
            modifier = Modifier.size(24.dp)
        )

        Spacer(modifier = Modifier.width(8.dp))

        Text(
            text = category.title,
            fontWeight = if (isSelected) FontWeight.Bold else FontWeight.Normal,
            color = if (isSelected) Color.Blue else Color.Black
        )
    }
}

@Composable
fun BookItem(
    book: Book,
    level: Int,
    isSelected: Boolean,
    onClick: () -> Unit
) {
    // Use LaunchedEffect to ensure proper recomposition when book changes
    LaunchedEffect(book.id) {
        // No action needed, just trigger recomposition
    }

    Row(
        modifier = Modifier
            .fillMaxWidth()
            .clickable(onClick = onClick)
            .padding(start = (level * 16).dp, top = 4.dp, bottom = 4.dp),
        verticalAlignment = Alignment.CenterVertically
    ) {
        Spacer(modifier = Modifier.width(24.dp))

        // Icon for book
        Icon(
            imageVector = Icons.Default.Book,
            contentDescription = "Book",
            tint = if (isSelected) Color.Blue else Color.Gray,
            modifier = Modifier.size(24.dp)
        )

        Spacer(modifier = Modifier.width(8.dp))

        Text(
            text = book.title,
            fontWeight = if (isSelected) FontWeight.Bold else FontWeight.Normal,
            fontSize = 14.sp,
            color = if (isSelected) Color.Blue else Color.Black
        )
    }
}
</file>

<file path="sample/composeApp/src/commonMain/kotlin/sample/app/LineCommentsView.kt">
package sample.app

import androidx.compose.foundation.background
import androidx.compose.foundation.clickable
import androidx.compose.foundation.layout.*
import androidx.compose.foundation.lazy.LazyColumn
import androidx.compose.foundation.lazy.items
import androidx.compose.material3.*
import androidx.compose.runtime.*
import androidx.compose.ui.Alignment
import androidx.compose.ui.Modifier
import androidx.compose.ui.text.font.FontWeight
import androidx.compose.ui.unit.dp
import androidx.compose.ui.unit.sp
import io.github.kdroidfilter.seforimlibrary.core.models.ConnectionType
import io.github.kdroidfilter.seforimlibrary.core.models.Line
import io.github.kdroidfilter.seforimlibrary.dao.repository.CommentaryWithText

@Composable
fun LineCommentsView(
    selectedLine: Line?,
    commentaries: List<CommentaryWithText>,
    onCommentClick: (CommentaryWithText) -> Unit = {}
) {
    Column(modifier = Modifier.fillMaxSize().padding(16.dp)) {
        // Header
        Text(
            text = "◊§◊ô◊®◊ï◊©◊ô ◊©◊ï◊®◊î",
            fontWeight = FontWeight.Bold,
            fontSize = 16.sp,
            modifier = Modifier.padding(bottom = 8.dp)
        )

        if (selectedLine == null) {
            // No line selected
            Box(
                modifier = Modifier.fillMaxSize(),
                contentAlignment = Alignment.Center
            ) {
                Text("◊ë◊ó◊® ◊©◊ï◊®◊î ◊õ◊ì◊ô ◊ú◊¶◊§◊ï◊™ ◊ë◊§◊ô◊®◊ï◊©◊ô◊ù ◊©◊ú◊î")
            }
        } else {
            // Filter commentaries for the selected line
            val lineCommentaries = commentaries.filter { it.link.sourceLineId == selectedLine.id }

            if (lineCommentaries.isEmpty()) {
                Box(
                    modifier = Modifier.fillMaxWidth().weight(1f),
                    contentAlignment = Alignment.Center
                ) {
                    Text("◊ê◊ô◊ü ◊§◊ô◊®◊ï◊©◊ô◊ù ◊ñ◊û◊ô◊†◊ô◊ù ◊ú◊©◊ï◊®◊î ◊ñ◊ï")
                }
            } else {
                Text(
                    text = "◊§◊ô◊®◊ï◊©◊ô◊ù (${lineCommentaries.size}):",
                    fontWeight = FontWeight.Bold,
                    fontSize = 14.sp,
                    modifier = Modifier.padding(bottom = 8.dp)
                )

                // State for selected tab
                var selectedTabIndex by remember { mutableStateOf(0) }

                // Get all connection types present in the commentaries
                val connectionTypes = lineCommentaries
                    .map { it.link.connectionType }
                    .distinct()
                    .ifEmpty { listOf(ConnectionType.OTHER) } // Fallback if no types found

                // Add "ALL" as the first tab with Hebrew titles
                val connectionTypeNames = connectionTypes.map { 
                    when (it) {
                        ConnectionType.COMMENTARY -> "◊§◊ô◊®◊ï◊©"
                        ConnectionType.TARGUM -> "◊™◊®◊í◊ï◊ù"
                        ConnectionType.REFERENCE -> "◊î◊§◊†◊ô◊î"
                        ConnectionType.OTHER -> "◊ê◊ó◊®"
                    }
                }
                val tabTitles = listOf("◊î◊õ◊ú") + connectionTypeNames

                // Tab row
                TabRow(
                    selectedTabIndex = selectedTabIndex,
                    modifier = Modifier.fillMaxWidth()
                ) {
                    tabTitles.forEachIndexed { index, title ->
                        Tab(
                            selected = selectedTabIndex == index,
                            onClick = { selectedTabIndex = index },
                            text = { Text(title) }
                        )
                    }
                }

                Spacer(modifier = Modifier.height(8.dp))

                // Filter commentaries by selected connection type
                val filteredCommentaries = if (selectedTabIndex == 0) {
                    // "ALL" tab selected - show all commentaries
                    lineCommentaries
                } else {
                    // Filter by selected connection type
                    // Check if the index is within bounds
                    if (selectedTabIndex - 1 < connectionTypes.size) {
                        val selectedType = connectionTypes[selectedTabIndex - 1]
                        lineCommentaries.filter { it.link.connectionType == selectedType }
                    } else {
                        // Fallback to showing all commentaries if the index is out of bounds
                        lineCommentaries
                    }
                }

                // Group commentaries by book
                val commentariesByBook = filteredCommentaries.groupBy { it.targetBookTitle }

                LazyColumn(
                    modifier = Modifier.fillMaxWidth().weight(1f)
                ) {
                    commentariesByBook.forEach { (bookTitle, bookCommentaries) ->
                        item {
                            // Book header
                            Text(
                                text = bookTitle,
                                fontWeight = FontWeight.Bold,
                                fontSize = 16.sp,
                                modifier = Modifier
                                    .fillMaxWidth()
                                    .background(MaterialTheme.colorScheme.secondary.copy(alpha = 0.2f))
                                    .padding(8.dp)
                            )
                        }

                        items(bookCommentaries) { commentary ->
                            Column(
                                modifier = Modifier
                                    .fillMaxWidth()
                                    .clickable { onCommentClick(commentary) }
                                    .padding(vertical = 8.dp, horizontal = 16.dp)
                            ) {
                                Text(
                                    text = commentary.targetText,
                                    fontSize = 14.sp
                                )
                            }
                            HorizontalDivider(Modifier, 0.5.dp, MaterialTheme.colorScheme.onSurface.copy(alpha = 0.2f))
                        }
                    }
                }
            }
        }
    }
}
</file>

<file path="sample/composeApp/src/commonMain/kotlin/sample/app/LineWithUniqueKey.kt">
package sample.app

import io.github.kdroidfilter.seforimlibrary.core.models.Line
import kotlin.random.Random

/**
 * A wrapper class for Line that provides a unique key for use in LazyColumn.
 * This is used to ensure unique keys in LazyColumn even when the same Line object appears multiple times.
 */
data class LineWithUniqueKey(val line: Line) {
    // Generate a truly unique key for this line by combining its ID with a UUID-like string
    // This ensures uniqueness even if the same Line object appears multiple times
    val uniqueKey: String = "${line.id}_${System.nanoTime()}_${Random.nextInt()}"
    val content: String get() = line.content
}

/**
 * Extension function to convert a Line to a LineWithUniqueKey.
 */
fun Line.withUniqueKey(): LineWithUniqueKey = LineWithUniqueKey(this)

/**
 * Extension function to convert a list of Line objects to a list of LineWithUniqueKey objects.
 */
fun List<Line>.withUniqueKeys(): List<LineWithUniqueKey> = map { it.withUniqueKey() }
</file>

<file path="sample/composeApp/src/commonMain/kotlin/sample/app/SearchPopup.kt">
package sample.app

import androidx.compose.foundation.background
import androidx.compose.foundation.clickable
import androidx.compose.foundation.layout.*
import androidx.compose.foundation.lazy.LazyColumn
import androidx.compose.foundation.lazy.LazyRow
import androidx.compose.foundation.lazy.grid.GridCells
import androidx.compose.foundation.lazy.grid.LazyVerticalGrid
import androidx.compose.foundation.lazy.items
import androidx.compose.foundation.shape.RoundedCornerShape
import androidx.compose.material.icons.Icons
import androidx.compose.material.icons.filled.Close
import androidx.compose.material.icons.filled.Search
import androidx.compose.material3.*
import androidx.compose.runtime.*
import androidx.compose.ui.Alignment
import androidx.compose.ui.Modifier
import androidx.compose.ui.draw.clip
import androidx.compose.ui.graphics.Color
import androidx.compose.ui.input.key.Key
import androidx.compose.ui.input.key.key
import androidx.compose.ui.input.key.onKeyEvent
import androidx.compose.ui.text.font.FontWeight
import androidx.compose.ui.text.input.TextFieldValue
import androidx.compose.ui.unit.dp
import androidx.compose.ui.window.Dialog
import androidx.compose.ui.window.DialogProperties
import com.mohamedrejeb.richeditor.model.rememberRichTextState
import com.mohamedrejeb.richeditor.ui.material.RichText
import io.github.kdroidfilter.seforimlibrary.core.models.SearchResult
import io.github.kdroidfilter.seforimlibrary.dao.repository.SeforimRepository
import kotlinx.coroutines.launch

/**
 * Modern search dialog with filtering capabilities
 */
@Composable
fun SearchPopup(
    repository: SeforimRepository,
    onDismiss: () -> Unit,
    onResultClick: (SearchResult) -> Unit
) {
    var searchQuery by remember { mutableStateOf(TextFieldValue("")) }
    var searchResults by remember { mutableStateOf<List<SearchResult>>(emptyList()) }
    var isSearching by remember { mutableStateOf(false) }
    var resultLimit by remember { mutableStateOf(50f) }
    var unlimitedResults by remember { mutableStateOf(false) }
    var selectedBooks by remember { mutableStateOf(setOf<Long>()) }
    val scope = rememberCoroutineScope()

    // Extract unique books from results
    val uniqueBooks = remember(searchResults) {
        searchResults.map { it.bookId to it.bookTitle }.distinct()
    }

    // Filter results based on selected books
    val filteredResults = remember(searchResults, selectedBooks) {
        if (selectedBooks.isEmpty()) searchResults
        else searchResults.filter { it.bookId in selectedBooks }
    }

    fun performSearch() {
        if (searchQuery.text.isBlank()) return
        scope.launch {
            isSearching = true
            selectedBooks = emptySet()
            val limit = if (unlimitedResults) -1 else resultLimit.toInt()
            searchResults = repository.search(searchQuery.text, limit)
            isSearching = false
        }
    }

    Dialog(
        onDismissRequest = onDismiss,
        properties = DialogProperties(usePlatformDefaultWidth = false)
    ) {
        Surface(
            modifier = Modifier
                .fillMaxWidth(0.85f)
                .fillMaxHeight(0.9f),
            shape = RoundedCornerShape(24.dp),
            color = MaterialTheme.colorScheme.surface,
            shadowElevation = 8.dp
        ) {
            Column {
                // Modern header
                Surface(
                    modifier = Modifier.fillMaxWidth(),
                    color = MaterialTheme.colorScheme.surfaceVariant
                ) {
                    Row(
                        modifier = Modifier
                            .fillMaxWidth()
                            .padding(horizontal = 24.dp, vertical = 16.dp),
                        horizontalArrangement = Arrangement.SpaceBetween,
                        verticalAlignment = Alignment.CenterVertically
                    ) {
                        Text(
                            text = "◊ó◊ô◊§◊ï◊© ◊ë◊°◊§◊®◊ô◊ô◊î", // Search Library
                            style = MaterialTheme.typography.headlineSmall,
                            fontWeight = FontWeight.Medium
                        )

                        IconButton(
                            onClick = onDismiss,
                            modifier = Modifier
                                .clip(RoundedCornerShape(12.dp))
                                .background(MaterialTheme.colorScheme.surface.copy(alpha = 0.5f))
                                .size(40.dp)
                        ) {
                            Icon(
                                Icons.Default.Close,
                                contentDescription = "Close",
                                modifier = Modifier.size(20.dp)
                            )
                        }
                    }
                }

                Column(
                    modifier = Modifier
                        .fillMaxSize()
                        .padding(24.dp)
                ) {
                    // Search bar with modern styling
                    OutlinedTextField(
                        value = searchQuery,
                        onValueChange = { searchQuery = it },
                        modifier = Modifier
                            .fillMaxWidth()
                            .onKeyEvent {
                                if (it.key == Key.Enter) {
                                    performSearch()
                                    true
                                } else false
                            },
                        placeholder = { Text("◊î◊ñ◊ü ◊ò◊ß◊°◊ò ◊ú◊ó◊ô◊§◊ï◊©...") }, // Enter search text...
                        leadingIcon = {
                            Icon(
                                Icons.Default.Search,
                                contentDescription = null,
                                tint = MaterialTheme.colorScheme.onSurfaceVariant
                            )
                        },
                        trailingIcon = {
                            if (searchQuery.text.isNotEmpty()) {
                                IconButton(
                                    onClick = { performSearch() },
                                    enabled = !isSearching
                                ) {
                                    if (isSearching) {
                                        CircularProgressIndicator(
                                            modifier = Modifier.size(20.dp),
                                            strokeWidth = 2.dp
                                        )
                                    } else {
                                        Icon(
                                            Icons.Default.Search,
                                            contentDescription = "Search",
                                            tint = MaterialTheme.colorScheme.primary
                                        )
                                    }
                                }
                            }
                        },
                        shape = RoundedCornerShape(16.dp),
                        singleLine = true,
                        colors = OutlinedTextFieldDefaults.colors(
                            focusedBorderColor = MaterialTheme.colorScheme.primary,
                            unfocusedBorderColor = MaterialTheme.colorScheme.outline.copy(alpha = 0.5f)
                        )
                    )

                    // Results limit control
                    Row(
                        modifier = Modifier
                            .fillMaxWidth()
                            .padding(vertical = 16.dp),
                        verticalAlignment = Alignment.CenterVertically
                    ) {
                        Text(
                            text = "◊™◊ï◊¶◊ê◊ï◊™ ◊û◊ß◊°◊ô◊û◊ú◊ô◊ï◊™:", // Maximum results:
                            style = MaterialTheme.typography.bodyLarge,
                            color = MaterialTheme.colorScheme.onSurfaceVariant
                        )

                        Spacer(modifier = Modifier.weight(1f))

                        // Unlimited checkbox
                        Row(
                            verticalAlignment = Alignment.CenterVertically,
                            modifier = Modifier.padding(end = 16.dp)
                        ) {
                            Checkbox(
                                checked = unlimitedResults,
                                onCheckedChange = { unlimitedResults = it }
                            )
                            Spacer(modifier = Modifier.width(4.dp))
                            Text(
                                text = "◊ú◊ú◊ê ◊î◊í◊ë◊ú◊î", // Unlimited
                                style = MaterialTheme.typography.bodyMedium
                            )
                        }

                        // Limit value display
                        Surface(
                            shape = RoundedCornerShape(8.dp),
                            color = if (unlimitedResults)
                                MaterialTheme.colorScheme.surfaceVariant
                            else
                                MaterialTheme.colorScheme.primaryContainer,
                            modifier = Modifier.padding(horizontal = 8.dp)
                        ) {
                            Text(
                                text = if (unlimitedResults) "‚àû" else resultLimit.toInt().toString(),
                                modifier = Modifier.padding(horizontal = 16.dp, vertical = 4.dp),
                                color = if (unlimitedResults)
                                    MaterialTheme.colorScheme.onSurfaceVariant.copy(alpha = 0.5f)
                                else
                                    MaterialTheme.colorScheme.onPrimaryContainer,
                                fontWeight = FontWeight.Medium
                            )
                        }

                        // Slider (disabled when unlimited)
                        Slider(
                            value = resultLimit,
                            onValueChange = { resultLimit = it },
                            valueRange = 10f..1000f,
                            steps = 98,
                            modifier = Modifier.width(200.dp),
                            enabled = !unlimitedResults,
                            colors = SliderDefaults.colors(
                                thumbColor = MaterialTheme.colorScheme.primary,
                                activeTrackColor = MaterialTheme.colorScheme.primary,
                                disabledThumbColor = MaterialTheme.colorScheme.onSurfaceVariant.copy(alpha = 0.3f),
                                disabledActiveTrackColor = MaterialTheme.colorScheme.onSurfaceVariant.copy(alpha = 0.3f)
                            )
                        )
                    }

                    // Book filters as chips
                    if (uniqueBooks.isNotEmpty()) {
                        Column {
                            Text(
                                text = "◊°◊†◊ü ◊ú◊§◊ô ◊°◊§◊®:", // Filter by book:
                                style = MaterialTheme.typography.titleMedium,
                                modifier = Modifier.padding(bottom = 8.dp)
                            )

                            LazyVerticalGrid(
                                columns = GridCells.Adaptive(minSize = 150.dp),
                                verticalArrangement = Arrangement.spacedBy(8.dp),
                                horizontalArrangement = Arrangement.spacedBy(8.dp),
                                modifier = Modifier
                                    .fillMaxWidth()
                                    .height(120.dp)
                            ) {
                                items(uniqueBooks.size) { index ->
                                    val (bookId, bookTitle) = uniqueBooks[index]
                                    FilterChip(
                                        selected = bookId in selectedBooks,
                                        onClick = {
                                            selectedBooks = if (bookId in selectedBooks) {
                                                selectedBooks - bookId
                                            } else {
                                                selectedBooks + bookId
                                            }
                                        },
                                        label = {
                                            Text(
                                                bookTitle,
                                                maxLines = 1,
                                                style = MaterialTheme.typography.bodyMedium
                                            )
                                        },
                                        colors = FilterChipDefaults.filterChipColors(
                                            selectedContainerColor = MaterialTheme.colorScheme.primaryContainer
                                        )
                                    )
                                }
                            }
                        }

                        Spacer(modifier = Modifier.height(16.dp))
                    }

                    // Results area
                    Surface(
                        modifier = Modifier.fillMaxSize(),
                        shape = RoundedCornerShape(16.dp),
                        color = MaterialTheme.colorScheme.surfaceVariant.copy(alpha = 0.3f)
                    ) {
                        when {
                            isSearching -> {
                                Box(
                                    modifier = Modifier.fillMaxSize(),
                                    contentAlignment = Alignment.Center
                                ) {
                                    Column(
                                        horizontalAlignment = Alignment.CenterHorizontally,
                                        verticalArrangement = Arrangement.spacedBy(16.dp)
                                    ) {
                                        CircularProgressIndicator()
                                        Text(
                                            "◊û◊ó◊§◊©...", // Searching...
                                            style = MaterialTheme.typography.bodyLarge
                                        )
                                        if (unlimitedResults) {
                                            Text(
                                                "◊ó◊ô◊§◊ï◊© ◊ú◊ú◊ê ◊î◊í◊ë◊ú◊î ◊¢◊©◊ï◊ô ◊ú◊ß◊ó◊™ ◊ñ◊û◊ü ◊®◊ë", // Unlimited search may take a long time
                                                style = MaterialTheme.typography.bodySmall,
                                                color = MaterialTheme.colorScheme.onSurfaceVariant.copy(alpha = 0.7f)
                                            )
                                        }
                                    }
                                }
                            }

                            searchQuery.text.isBlank() -> {
                                Box(
                                    modifier = Modifier.fillMaxSize(),
                                    contentAlignment = Alignment.Center
                                ) {
                                    Text(
                                        "◊î◊ñ◊ü ◊ò◊ß◊°◊ò ◊õ◊ì◊ô ◊ú◊î◊™◊ó◊ô◊ú ◊ó◊ô◊§◊ï◊©", // Enter text to start searching
                                        style = MaterialTheme.typography.bodyLarge,
                                        color = MaterialTheme.colorScheme.onSurfaceVariant
                                    )
                                }
                            }

                            filteredResults.isEmpty() -> {
                                Box(
                                    modifier = Modifier.fillMaxSize(),
                                    contentAlignment = Alignment.Center
                                ) {
                                    Column(
                                        horizontalAlignment = Alignment.CenterHorizontally,
                                        verticalArrangement = Arrangement.spacedBy(8.dp)
                                    ) {
                                        Text(
                                            "◊ú◊ê ◊†◊û◊¶◊ê◊ï ◊™◊ï◊¶◊ê◊ï◊™", // No results found
                                            style = MaterialTheme.typography.headlineSmall,
                                            color = MaterialTheme.colorScheme.onSurfaceVariant
                                        )
                                        if (selectedBooks.isNotEmpty() && searchResults.isNotEmpty()) {
                                            Text(
                                                "◊†◊°◊î ◊ú◊©◊†◊ï◊™ ◊ê◊™ ◊î◊°◊ô◊†◊ï◊ü", // Try changing the filter
                                                style = MaterialTheme.typography.bodyMedium,
                                                color = MaterialTheme.colorScheme.onSurfaceVariant.copy(alpha = 0.7f)
                                            )
                                        }
                                    }
                                }
                            }

                            else -> {
                                LazyColumn(
                                    contentPadding = PaddingValues(16.dp),
                                    verticalArrangement = Arrangement.spacedBy(12.dp)
                                ) {
                                    // Results count header
                                    item {
                                        Row(
                                            modifier = Modifier
                                                .fillMaxWidth()
                                                .padding(bottom = 8.dp),
                                            horizontalArrangement = Arrangement.SpaceBetween,
                                            verticalAlignment = Alignment.CenterVertically
                                        ) {
                                            Text(
                                                text = "${filteredResults.size} ◊™◊ï◊¶◊ê◊ï◊™ ◊†◊û◊¶◊ê◊ï", // X results found
                                                style = MaterialTheme.typography.titleSmall,
                                                color = MaterialTheme.colorScheme.onSurfaceVariant
                                            )
                                            if (selectedBooks.isNotEmpty() && filteredResults.size != searchResults.size) {
                                                Text(
                                                    text = "(${searchResults.size} ◊°◊î◊¥◊õ)", // (X total)
                                                    style = MaterialTheme.typography.bodySmall,
                                                    color = MaterialTheme.colorScheme.onSurfaceVariant.copy(alpha = 0.7f)
                                                )
                                            }
                                        }
                                    }

                                    items(filteredResults) { result ->
                                        SearchResultCard(
                                            result = result,
                                            onClick = { onResultClick(result) }
                                        )
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }
    }
}

/**
 * Modern search result card
 */
@Composable
private fun SearchResultCard(
    result: SearchResult,
    onClick: () -> Unit
) {
    Card(
        modifier = Modifier
            .fillMaxWidth()
            .clickable(onClick = onClick),
        shape = RoundedCornerShape(12.dp),
        colors = CardDefaults.cardColors(
            containerColor = MaterialTheme.colorScheme.surface
        ),
        elevation = CardDefaults.cardElevation(defaultElevation = 2.dp)
    ) {
        Row(
            modifier = Modifier
                .fillMaxWidth()
                .padding(16.dp)
        ) {
            // Book info and content
            Column(modifier = Modifier.weight(1f)) {
                Text(
                    text = result.bookTitle,
                    style = MaterialTheme.typography.titleMedium,
                    fontWeight = FontWeight.Medium,
                    color = MaterialTheme.colorScheme.primary
                )

                Spacer(modifier = Modifier.height(8.dp))

                // Rich text snippet
                val richTextState = rememberRichTextState()
                LaunchedEffect(result.snippet) {
                    richTextState.setHtml(result.snippet)
                }

                RichText(
                    state = richTextState,
                    modifier = Modifier.fillMaxWidth(),
                    style = MaterialTheme.typography.bodyMedium.copy(
                        color = MaterialTheme.colorScheme.onSurfaceVariant
                    )
                )
            }

            // Line number badge
            Surface(
                modifier = Modifier
                    .align(Alignment.Top)
                    .padding(start = 16.dp),
                shape = RoundedCornerShape(8.dp),
                color = MaterialTheme.colorScheme.secondaryContainer
            ) {
                Text(
                    text = "◊©◊ï◊®◊î ${result.lineIndex + 1}", // Line X
                    modifier = Modifier.padding(horizontal = 12.dp, vertical = 6.dp),
                    style = MaterialTheme.typography.labelMedium,
                    color = MaterialTheme.colorScheme.onSecondaryContainer
                )
            }
        }
    }
}
</file>

<file path="sample/composeApp/src/commonMain/kotlin/sample/app/Theme.kt">
package sample.app

import androidx.compose.material3.MaterialTheme
import androidx.compose.material3.lightColorScheme
import androidx.compose.runtime.Composable
import androidx.compose.ui.graphics.Color

private val MonochromeColorScheme = lightColorScheme(
    primary = Color(0xFF333333),
    onPrimary = Color.White,
    primaryContainer = Color(0xFF555555),
    onPrimaryContainer = Color.White,
    secondary = Color(0xFF666666),
    onSecondary = Color.White,
    secondaryContainer = Color(0xFF888888),
    onSecondaryContainer = Color.White,
    tertiary = Color(0xFF666666),
    onTertiary = Color.White,
    tertiaryContainer = Color(0xFF888888),
    onTertiaryContainer = Color.White,
    error = Color(0xFF555555),
    onError = Color.White,
    errorContainer = Color(0xFF555555),
    onErrorContainer = Color.White,
    background = Color.White,
    onBackground = Color(0xFF333333),
    surface = Color(0xFFF5F5F5),
    onSurface = Color(0xFF333333),
    surfaceVariant = Color(0xFFEEEEEE),
    onSurfaceVariant = Color(0xFF333333),
    outline = Color(0xFF888888)
)


@Composable
fun AppTheme(content: @Composable () -> Unit) {
    MaterialTheme(
        colorScheme = MonochromeColorScheme,
        typography = notoFont(),
        content = content
    )
}
</file>

<file path="sample/composeApp/src/commonMain/kotlin/sample/app/Type.kt">
package sample.app

import androidx.compose.material3.MaterialTheme
import androidx.compose.material3.Typography
import androidx.compose.runtime.Composable
import org.jetbrains.compose.resources.Font
import seforimlibrary.sample.composeapp.generated.resources.Res
import seforimlibrary.sample.composeapp.generated.resources.noto


@Composable
fun notoFont() = Typography(
    displayLarge = MaterialTheme.typography.displayLarge.copy(fontFamily = androidx.compose.ui.text.font.FontFamily(
        Font(
            Res.font.noto
        )
    )
    ),
    displayMedium = MaterialTheme.typography.displayMedium.copy(fontFamily = androidx.compose.ui.text.font.FontFamily(
        Font(Res.font.noto)
    )
    ),
    displaySmall = MaterialTheme.typography.displaySmall.copy(fontFamily = androidx.compose.ui.text.font.FontFamily(
        Font(
            Res.font.noto
        )
    )
    ),
    headlineLarge = MaterialTheme.typography.headlineLarge.copy(fontFamily = androidx.compose.ui.text.font.FontFamily(
        Font(Res.font.noto)
    )
    ),
    headlineMedium = MaterialTheme.typography.headlineMedium.copy(fontFamily = androidx.compose.ui.text.font.FontFamily(
        Font(Res.font.noto)
    )
    ),
    headlineSmall = MaterialTheme.typography.headlineSmall.copy(fontFamily = androidx.compose.ui.text.font.FontFamily(
        Font(Res.font.noto)
    )
    ),
    titleLarge = MaterialTheme.typography.titleLarge.copy(fontFamily = androidx.compose.ui.text.font.FontFamily(Font(Res.font.noto))),
    titleMedium = MaterialTheme.typography.titleMedium.copy(fontFamily = androidx.compose.ui.text.font.FontFamily(
        Font(
            Res.font.noto
        )
    )
    ),
    titleSmall = MaterialTheme.typography.titleSmall.copy(fontFamily = androidx.compose.ui.text.font.FontFamily(Font(Res.font.noto))),
    bodyLarge = MaterialTheme.typography.bodyLarge.copy(fontFamily = androidx.compose.ui.text.font.FontFamily(Font(Res.font.noto))),
    bodyMedium = MaterialTheme.typography.bodyMedium.copy(fontFamily = androidx.compose.ui.text.font.FontFamily(Font(Res.font.noto))),
    bodySmall = MaterialTheme.typography.bodySmall.copy(fontFamily = androidx.compose.ui.text.font.FontFamily(Font(Res.font.noto))),
    labelLarge = MaterialTheme.typography.labelLarge.copy(fontFamily = androidx.compose.ui.text.font.FontFamily(Font(Res.font.noto))),
    labelMedium = MaterialTheme.typography.labelMedium.copy(fontFamily = androidx.compose.ui.text.font.FontFamily(
        Font(
            Res.font.noto
        )
    )
    ),
    labelSmall = MaterialTheme.typography.labelSmall.copy(fontFamily = androidx.compose.ui.text.font.FontFamily(Font(Res.font.noto))),
)
</file>

<file path="sample/composeApp/src/jvmMain/kotlin/sample/app/DatabaseUtils.kt">
package sample.app

import androidx.compose.foundation.layout.Arrangement
import androidx.compose.foundation.layout.Column
import androidx.compose.foundation.layout.Row
import androidx.compose.foundation.layout.Spacer
import androidx.compose.foundation.layout.fillMaxWidth
import androidx.compose.foundation.layout.height
import androidx.compose.foundation.layout.padding
import androidx.compose.material.AlertDialog
import androidx.compose.material.Button
import androidx.compose.material.Icon
import androidx.compose.material.IconButton
import androidx.compose.material.Text
import androidx.compose.material.icons.Icons
import androidx.compose.material.icons.filled.FolderOpen
import androidx.compose.runtime.Composable
import androidx.compose.runtime.LaunchedEffect
import androidx.compose.runtime.getValue
import androidx.compose.runtime.mutableStateOf
import androidx.compose.runtime.remember
import androidx.compose.runtime.rememberCoroutineScope
import androidx.compose.runtime.setValue
import androidx.compose.ui.Alignment
import androidx.compose.ui.Modifier
import androidx.compose.ui.unit.dp
import app.cash.sqldelight.db.SqlDriver
import app.cash.sqldelight.driver.jdbc.sqlite.JdbcSqliteDriver
import io.github.kdroidfilter.seforimlibrary.dao.repository.SeforimRepository
import io.github.vinceglb.filekit.FileKit
import io.github.vinceglb.filekit.dialogs.FileKitType
import io.github.vinceglb.filekit.dialogs.openFilePicker
import io.github.vinceglb.filekit.path
import kotlinx.coroutines.launch
import java.io.File
import java.util.prefs.Preferences

// Preferences key for storing the database path
private const val PREF_DB_PATH = "database_path"

// Get preferences for storing the database path
private val prefs = Preferences.userNodeForPackage(SeforimRepository::class.java)

// Composable to show database selection dialog
@Composable
fun DatabaseSelectionDialog(
    currentPath: String,
    onPathSelected: (String) -> Unit,
    onDismiss: () -> Unit
) {
    val coroutineScope = rememberCoroutineScope()

    AlertDialog(
        onDismissRequest = onDismiss,
        title = { Text("Select Database File") },
        text = { 
            Column {
                Text("Please select the database file for the application.")
                Spacer(modifier = Modifier.height(8.dp))
                Text("Current path: ${if (currentPath.isEmpty()) "Not set" else currentPath}")
            }
        },
        buttons = {
            Row(
                modifier = Modifier.fillMaxWidth().padding(8.dp),
                horizontalArrangement = Arrangement.End
            ) {
                Button(
                    onClick = {
                        // Use FileKit to select a database file
                        coroutineScope.launch {
                            val file = FileKit.openFilePicker() // Use default type to allow all files
                            if (file != null) {
                                onPathSelected(file.path)
                            }
                            onDismiss()
                        }
                    }
                ) {
                    Text("Select File")
                }

                Button(
                    onClick = onDismiss,
                    modifier = Modifier.padding(start = 8.dp)
                ) {
                    Text("Cancel")
                }
            }
        }
    )
}

// Composable to show database selection button
@Composable
fun DatabaseSelectionButton(onClick: () -> Unit) {
    IconButton(onClick = onClick) {
        Icon(Icons.Default.FolderOpen, contentDescription = "Select Database File")
    }
}

// Global state for dialog visibility
private val showDatabaseDialogState = mutableStateOf(false)

// Function to show the database selection dialog
fun showDatabaseSelectionDialog() {
    showDatabaseDialogState.value = true
}

@Composable
actual fun getDatabasePath(): String {
    // State to hold the database path
    var dbPath by remember { mutableStateOf(prefs.get(PREF_DB_PATH, "")) }

    // State to control the dialog visibility
    var showDialog by remember { showDatabaseDialogState }

    // Show dialog if path is not set
    LaunchedEffect(Unit) {
        if (dbPath.isEmpty() || !File(dbPath).exists()) {
            showDialog = true
        }
    }

    // Dialog to select database file
    if (showDialog) {
        DatabaseSelectionDialog(
            currentPath = dbPath,
            onPathSelected = { newPath ->
                dbPath = newPath
                // Save the path to preferences
                prefs.put(PREF_DB_PATH, dbPath)
            },
            onDismiss = { showDialog = false }
        )
    }

    return dbPath
}

@Composable
actual fun getRepository(): SeforimRepository {
    val dbPath = getDatabasePath()
    val driver: SqlDriver = remember(dbPath) {
        // Use the SQLite driver for desktop
        JdbcSqliteDriver("jdbc:sqlite:$dbPath")
    }

    return remember(driver) {
        SeforimRepository(dbPath, driver)
    }
}

@Composable
actual fun DatabaseSelectionButtonIfAvailable() {
    DatabaseSelectionButton(onClick = { showDatabaseSelectionDialog() })
}
</file>

<file path="sample/composeApp/src/jvmMain/kotlin/sample/app/main.kt">
import androidx.compose.runtime.CompositionLocalProvider
import androidx.compose.ui.platform.LocalDensity
import androidx.compose.ui.unit.Density
import androidx.compose.ui.unit.dp
import androidx.compose.ui.window.Window
import androidx.compose.ui.window.application
import androidx.compose.ui.window.rememberWindowState
import sample.app.App
import java.awt.Dimension
import java.util.Locale

fun main() {
    Locale.setDefault(Locale.Builder().setLanguage("he").setRegion("IL").build())
    application {
        Window(
            title = "sample",
            state = rememberWindowState(width = 1280.dp, height = 720.dp),
            onCloseRequest = ::exitApplication,
        ) {
            window.minimumSize = Dimension(350, 600)
            CompositionLocalProvider(LocalDensity provides Density(density = 1f, fontScale = 1.0f)) {
                App()
            }
        }
    }
}
</file>

<file path="settings.gradle.kts">
rootProject.name = "SeforimLibrary"

pluginManagement {
    repositories {
        google {
            content { 
              	includeGroupByRegex("com\\.android.*")
              	includeGroupByRegex("com\\.google.*")
              	includeGroupByRegex("androidx.*")
              	includeGroupByRegex("android.*")
            }
        }
        gradlePluginPortal()
        mavenCentral()
    }
}

dependencyResolutionManagement {
    repositories {
        google {
            content { 
              	includeGroupByRegex("com\\.android.*")
              	includeGroupByRegex("com\\.google.*")
              	includeGroupByRegex("androidx.*")
              	includeGroupByRegex("android.*")
            }
        }
        mavenCentral()
    }
}
include(":core")
include(":dao")
include(":generator")
include(":sample:composeApp")
</file>

</files>
